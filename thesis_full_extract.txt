[P8][Figures] باسمه تعالی
[P10][Title Page] دانشگاه صنعتی مالک‌اشتر
[P11][Title Page] مجتمع دانشگاهی برق و کامپیوتر
[P13][Title Page] پايان‌نامه دوره کارشناسي ارشد رشته مهندسي کامپیوتر
[P14][Title Page Names] عنوان
[P15][Title Page Names] بهبود تشخيص حملات تزريق پایگاه‌داده غیررابطه‌ای مبتني بر يادگيري ماشين
[P17][Title Page Names] توسط: اميرحسين قاسمي
[P18][Title Page Names] استاد راهنما: آقاي دكتر علي هادوي
[P19][Title Page Names] استاد (اساتید) مشاور
[P21][Title Page Names] 1 خرداد ماه 1403
[P24][Figures] باسمه تعالی
[P26][Title Page] دانشگاه صنعتی مالک‌اشتر
[P27][Title Page] مجتمع دانشگاهی برق و کامپیوتر
[P29][Title Page] پایاننامه دوره کارشناسی ارشد رشتهی مهندسی کامپیوتر گرایش رايانش امن
[P30][Title Page] با عنوان
[P31][Title Page] بهبود تشخيص حملات تزريق پایگاه‌داده غیررابطه‌ای مبتني بر يادگيري ماشين
[P32][Title Page] در تاریخ -/-/- توسط کمیتهی تخصصی زیر، موردبررسی قرار گرفت و با نمرهی ................... و درجهی ................... به تصویب رسید.
[P38][Normal] تعیین سطح طبقه‌بندی پایان‌نامه
[P39][Normal] عنوان پایان‌نامه: بهبود تشخيص حملات تزريق پایگاه‌داده غیررابطه‌ای مبتني بر يادگيري ماشين
[P40][Normal] نام و نام خانوادگی استاد راهنما: دکتر علي هادوي
[P42][Normal] "تبصره: باتوجه‌به طبقه دار بودن پایان‌نامه، تا تاریخ ................ این پایان‌نامه، فقط با نظر این واحد دانشگاهی، در اختیار متقاضی قرار گیرد."
[P44][Normal] تأیید صحت و اصالت نتایج پایان‌نامه
[P45][Normal] اینجانب اميرحسين قاسمي به شماره دانشجویی 4011417038 دانشجوی رشته مهندسی كامپيوتر گرایش رايانش امن مقطع تحصیلی کارشناسی‌ارشد تأیید می‌نمایم که کلیه نتایج این پایان‌نامه حاصل کار اینجانب و بدون دخل‌وتصرف است و موارد نسخه‌برداری شده از آثار دیگران را با ذکر کامل مشخصات منبع آورده‌ام.
[P46][Normal] در صورت اثبات خلاف مندرجات فوق، به تشخیص دانشگاه مطابق با ضوابط و مقررات حاکم (قانون حمایت از حقوق مؤلفان و قانون ترجمه و تکثیر کتب و نشریات و آثار صوتی، ضوابط و مقررات آموزشی، پژوهشی و انضباطی ...) با این‌جانب رفتار خواهد شد و حق هرگونه اعتراض در خصوص احقاق حقوق مکتسب و تعیین تخلف و مجازات را از خویش صلب می‌نمایم. در ضمن، مسئولیت هرگونه پاسخگویی به اشخاص اعم از حقیقی و مراجع ذی‌صلاح (اعم از اداری و قضایی) به عهده این‌جانب خواهد بود و دانشگاه هیچ‌گونه مسئولیتی دراین‌خصوص نخواهد داشت.
[P47][Heading_centered] فهرست مطالب
[P48][TOC_Table] عنوان	صفحه
[P51][Heading_centered] فهرست جدول‌ها
[P52][TOC_Table] عنوان	صفحه
[P53][table of figures] جدول 2- 1: انواع دیتا بیس ها	31
[P54][table of figures] جدول 2- 2: مقایسه مقالات [42], [43], [44]	52
[P55][table of figures] جدول 2- 3: مقایسه مقالات [42], [43], [44] از دیدگاه محتلف	52
[P56][table of figures] جدول 2- 4: ویژگی‌های انتخاب‌شده	53
[P58][table of figures] جدول 3- 1: پارامترهای رگرسیون خطی	71
[P59][table of figures] جدول 3- 2: پارامترهای درخت تصمیم	71
[P60][table of figures] جدول 3- 3: پارامترهای Gradient Boosting	71
[P61][table of figures] جدول 3- 4: پارامترهای نزدیکترین همسایه	71
[P62][table of figures] جدول 3- 5: پارامترهای درخت تصادفی	72
[P63][table of figures] جدول 3- 6: پارامترهای XGBoost	72
[P64][table of figures] جدول 3- 7:  پارامترهای LightGBM	72
[P65][table of figures] جدول 3- 8:پارامترهای Extra Trees	73
[P66][table of figures] جدول 3- 9: پارامترهای Support Vector Machine	73
[P67][table of figures] جدول 3- 10: پارامترهای AdaBoost	73
[P68][table of figures] جدول 3- 11: پارامترهای Voting Ensemble	74
[P69][table of figures] جدول 3- 12: پارامترهای Estimators داخل Voting Ensemble	74
[P70][table of figures] جدول 3- 13:پارامترهای Stacking Ensemble	74
[P71][table of figures] جدول 3- 14:  پارامترهای Estimators داخل Stacking Ensemble	74
[P73][table of figures] جدول 4- 1: معیارهای ارزیابی	85
[P74][table of figures] جدول 4- 2: تحلیل مقایسه‌ای دیتاست ها	87
[P75][table of figures] جدول 4- 3:  خلاصه نتایج اعتبارسنجی متقاطع 10-فولدی روی دیتاست اصلی	95
[P76][table of figures] جدول 4- 4: نتایج آزمون نهایی مدل‌ها روی دیتاست اصلی	96
[P77][table of figures] جدول 4- 5: چهار مؤلفه (TN, FP, FN, TP) برای هر مدل	97
[P78][table of figures] جدول 4- 6: خلاصه ماتریس درهم‌ریختگی مدل‌ها روی Syn-2000 (Test = 400)	99
[P79][table of figures] جدول 4- 7: نتایج عملکرد مدل‌ها روی Syn-2000 (Test)	101
[P80][table of figures] جدول 4- 8: خلاصه ماتریس‌های درهم‌ریختگی مدل‌ها روی Syn-2000 (Seed=All Real-400) در مجموعه آزمون	103
[P81][table of figures] جدول 4- 9: نتایج عملکرد مدل‌ها روی Syn-2000 (Seed=All Real-400) در مجموعه آزمون	104
[P82][table of figures] جدول 4- 10: جدول تجمیعی «بهترین مدل هر سناریو» بر اساس نتایج آزمون - معیار انتخاب  بهترین مدل : Accuracy و F1(macro) به‌عنوان شاخص عملکرد کلی، و FN/FP به‌عنوان شاخص‌های ریسک امنیتی/هشدار کاذب.	106
[P84][Heading_centered] فهرست شکل‌ها
[P85][TOC_Table] عنوان	صفحه
[P86][table of figures] شکل2- 1محبوبيت در بين 500شركت برتر جهان[27]	28
[P87][table of figures] شکل2- 2: مدل مفهومی یادگیری ماشین[46]	54
[P88][table of figures] شکل2- 3: نمونه کوئری در منگو دیبی	56
[P89][table of figures] شکل2- 4: مدل نمونه برای ورودی کاربر مورد نظر حمله[47]	56
[P90][table of figures] شکل2- 5: فلوچارت کد جاوا اسکریپت برای محدود کردن ورودی[29]	57
[P92][table of figures] شکل 3- 1: مدل مفهومی جزییات دیتا ست ها	60
[P93][table of figures] شکل 3- 2: مدل مفهومی جزییات پیاده سازی مدل پیشنهادی	61
[P95][table of figures] شکل 4- 1: ماتریس درهم ریختگی مدلها	98
[P96][table of figures] شکل 4- 2: کنفیوژن ماتریس مدلها با 2000 دیتا مصنوعی	100
[P98][Heading_centered] فهرست نمادها
[P99][TOC_Table] عنوان	علامت اختصاري
[P103][Heading_centered] کوته‌نوشت‌ها
[P109][Heading_centered] چکيده
[P110][NewParagraph] تزریق در پایگاه‌داده‌های غیررابطه‌ای‎‎‌‌ یکی از آسیب‌پذیری‌های مهم در برنامه‌های وب است که معمولاً در اثر اعتبارسنجی نامناسب ورودی و ساخت پرس‌وجوهای پویا با داده کاربر رخ می‌دهد و می‌تواند به دور زدن احراز هویت، استخراج/تغییر داده و سایر پیامدهای امنیتی منجر شود. با توجه به گسترش استفاده از پایگاه‌داده‌های غیررابطه‌ای و افزایش سطح حملات متن‌محور و مبتنی بر کوئری، نیاز به راهکارهای داده‌محور برای تشخیص این حملات بیش از گذشته احساس می‌شود.
[P111][NewParagraph] هدف این پایان‌نامه ارائه یک رویکرد داده‌محور برای تشخیص دقیق‌تر حملات تزریق در پایگاه‌داده‌های غیررابطه‌ای و هم‌زمان کاهش هشدارهای کاذب است؛ به‌گونه‌ای که محدودیت رایج در این حوزه یعنی کمبود داده‌های واقعی و برچسب‌دار نیز تا حد امکان برطرف شود. در همین راستا، علاوه بر استفاده از داده واقعی (Real-400)، دو مجموعه‌داده مصنوعی Syn-2000 با بهره‌گیری از مدل زبانی بزرگ GPT-5.2 تولید شد: (1) سناریوی Seed=50% Real و (2) سناریوی Seed=All Real-400. استفاده از LLMها در تولید داده مصنوعیِ وظیفه‌محور، در پژوهش‌های جدید به‌عنوان رویکردی مؤثر برای افزایش پوشش داده و تقویت آموزش مدل‌ها مطرح شده است.
[P112][NewParagraph] در مرحله مدل‌سازی، چندین الگوریتم یادگیری ماشین (از جمله رگرسیون خطی، درخت تصادفی، XGBoost، LightGBM، نزدیکترین همسایه و روش‌های ترکیبی مبتنی بر Voting و Stacking) آموزش داده شدند و عملکرد آن‌ها با رویکرد ارزیابی منظم و حفظ توزیع کلاس‌ها (مانند Stratified K-Fold) سنجیده شد. نتایج آزمایش‌ها نشان داد «بهترین مدل» با تغییر سناریوی داده ثابت نمی‌ماند: در Real-400 مدل درخت تصادفی بهترین عملکرد کلی را داشت؛ در Syn-2000 (Seed=50%) مدل نزدیکترین همسایه بیشترین کارایی را نشان داد؛ و در Syn-2000 (Seed=100%)  مدل LightGBM  بهترین توازن را در شاخص‌های کلی و کنترل خطاها ارائه کرد. همچنین مشاهده شد که در برخی سناریوها، روش‌های ترکیبی می‌توانند نرخ خطای از دست‌رفتن حمله (FN) را کاهش دهند، هرچند ممکن است با افزایش هشدار کاذب (FP) همراه شوند؛ بنابراین انتخاب نهایی مدل باید متناسب با سیاست عملیاتی سامانه (FN-محور یا FP-محور) انجام گیرد.
[P113][NewParagraph] به‌طور کلی، این پژوهش نشان می‌دهد تقویت داده با تولید مصنوعی مبتنی بر GPT-5.2 می‌تواند به بهبود معنادار عملکرد مدل‌های تشخیص تزریق NoSQL کمک کند و در کنار آن، تحلیل همزمان FP و FN تصویری عملیاتی از ریسک امنیتی ارائه می‌دهد. همچنین نتایج حاکی از آن است که مدل‌های تقویتی مبتنی بر درخت تصمیم مانند LightGBM—که برای کارایی و یادگیری روابط غیرخطی طراحی شده‌اند—در سناریوهای داده غنی‌تر، ظرفیت بالایی برای تشخیص دقیق‌تر دارند.
[P114][NewParagraph] کلیدواژه‌ها: تزریق NoSQL، پایگاه‌داده‌های غیررابطه‌ای، داده مصنوعی، مدل‌های زبان بزرگ (GPT-5.2)، یادگیری ماشین، یادگیری گروهی، تشخیص حمله، کاهش هشدار کاذب، مجموعه‌داده ، یادگیری ماشینی
[P117][Heading 1] فصل اول -مقدمه
[P118][Heading 2] 1-1 بيان مسئله
[P119][Heading 3] 1-1-1 مسئله و اهداف اصلي تحقيق:
[P120][Normal] با گسترش روزافزون استفاده از سیستم‌های مبتنی بر وب و پایگاه‌های داده، امنیت اطلاعات و جلوگیری از نفوذ و حملات به این سیستم‌ها از اهمیت ویژه‌ای برخوردار شده است. حملات تزریق داده، ازجمله حملات تزریق پایگاه‌داده رابطه‌ای، به‌عنوان یکی از متداول‌ترین روش‌های سوءاستفاده از آسیب‌پذیری‌های پایگاه‌های داده مطرح هستند. برای مقابله با این نوع حملات، پژوهشگران به تکنیک‌های یادگیری ماشینی روی آورده‌اند. استفاده از این تکنیک‌ها برای شناسایی و جلوگیری از حملات تزریق پایگاه‌داده رابطه‌ای در پژوهش‌های متعددی گزارش شده است و نتایج امیدوارکننده‌ای نیز ارائه داده‌اند.
[P121][Normal] بااین‌حال، ظهور پایگاه‌های داده پایگاه‌داده غیررابطه‌ای به دلیل قابلیت مقیاس‌پذیری بالا، انعطاف‌پذیری در مدل داده و توانایی مدیریت حجم عظیمی از داده‌ها، باعث گسترش کاربردهای آن در زمینه‌های مختلف شده است. با افزایش استفاده از این نوع پایگاه‌ها، حملات تزریق پایگاه‌داده غیررابطه‌ای به‌عنوان یک چالش امنیتی نوظهور شناخته شده‌اند. برخلاف حملات تزریق پایگاه‌داده رابطه‌ای که بر ساختار جدولی و زبان پرس‌وجوی استاندارد ( پایگاه‌داده رابطه‌ای) متکی هستند، حملات تزریق پایگاه‌داده غیررابطه‌ای از ضعف‌های موجود در ساختارهای غیر جدولی و زبان‌های پرس‌وجوی خاص این نوع پایگاه‌ها سوءاستفاده می‌کنند.
[P122][Normal] علی‌رغم اهمیت فزاینده موضوع، پژوهش‌های کمتری به شناسایی و مقابله با حملات تزریق پایگاه‌داده غیررابطه‌ای  پرداخته‌اند. به همین دلیل، توسعه رویکردهای مبتنی بر یادگیری ماشینی برای تشخیص حملات تزریق پایگاه‌داده غیررابطه‌ای به یک نیاز ضروری تبدیل شده است. این تحقیق بر آن است تا با ارائه روش‌هایی نوین، به مقابله با این چالش بپردازد.
[P123][Normal] یکی از چالش‌های اصلی در اجرای این پژوهش، فقدان مجموعه‌دادگان مناسب و کافی برای آموزش و ارزیابی مدل‌های یادگیری ماشینی است. بسیاری از پژوهش‌های گذشته در زمینه حملات تزریق پایگاه‌داده رابطه‌ای، از مجموعه‌دادگان عمومی و موجود بهره برده‌اند، اما در زمینه حملات پایگاه‌داده غیررابطه‌ای چنین مجموعه‌دادگان استانداردی وجود ندارد. این امر فرایند ارزیابی دقیق و قابل‌اعتماد مدل‌ها را دشوار می‌سازد.
[P124][Normal] برای غلبه بر این چالش، یکی از روش‌های پیشرفته تولید داده‌های مصنوعی و متنوع، استفاده از مدل‌های زبان بزرگ  است. این مدل‌ها، باتکیه‌بر معماری‌های عمیق و مبتنی بر ترانسفورمر، قادر به تولید داده‌هایی با شباهت بالا به داده‌های واقعی هستند. استفاده از مدل‌های زبان بزرگ  امکان تولید داده‌های متنی و ساختاریافته را باکیفیت بالا فراهم می‌کند، به‌گونه‌ای که داده‌های تولیدشده قابلیت استفاده به‌عنوان مجموعه‌دادگان آموزشی برای مدل‌های یادگیری ماشینی را دارند. این رویکرد، علاوه بر دقت بالا، انعطاف‌پذیری بیشتری در تطبیق با انواع سناریوها و کاربردها ارائه می‌دهد و می‌تواند جایگزینی مؤثر برای روش‌های سنتی مانند شبکه‌های مولد متخاصم باشد.
[P125][Heading 2] 1-2 تشريح و بيان موضوع:
[P126][Normal] این پژوهش شامل طراحی و ارزیابی یک سیستم یادگیری گروهی است که از مدل‌های مختلف مانند رگرسیون لجستیک، جنگل تصادفی و XGBoost تشکیل شده است. این مدل‌ها با ترکیب قدرت یادگیری فردی خود، دقت شناسایی حملات را بهبود می‌بخشند. دستاوردهای مورد انتظار این پژوهش شامل ارائه روشی نوین برای شناسایی حملات تزریق پایگاه‌داده غیررابطه‌ای، ایجاد مجموعه‌دادگان جامع و متنوع، و بهبود دقت مدل‌های یادگیری ماشینی در محیط‌های واقعی است.
[P127][Normal] مفاهیم کلیدی این پژوهش شامل شناسایی و مقابله با حملات تزریق پایگاه‌داده غیررابطه‌ای است که از نقاط ضعف این نوع پایگاه‌ها سوءاستفاده می‌کنند. این حملات معمولاً از طریق ارسال درخواست‌های مخرب و دست‌کاری پرس‌وجوها انجام می‌گیرند. همچنین، تحلیل و طراحی مجموعه‌دادگان شامل داده‌های اولیه و داده‌های مصنوعی تولیدشده با مدل‌های زبان بزرگ، یکی از محورهای اصلی پژوهش است. در این راستا، به‌جای استفاده از شبکه‌های مولد متخاصم، از مدل‌های زبان بهره گرفته می‌شود که توانایی تولید داده‌های متنی و ساختاریافته باکیفیت بالا را دارند.
[P128][Normal] این پژوهش با هدف ارائه راهکاری جامع برای تشخیص حملات تزریق پایگاه‌داده غیررابطه‌ای طراحی شده است. برای دست‌یابی به این هدف، مجموعه‌داده‌های اولیه به‌صورت دستی تحلیل و برچسب‌گذاری می‌شوند تا کیفیت داده‌های پایه تضمین گردد. سپس از مدل‌های زبان بزرگ برای تولید داده‌های مصنوعی متنوع و واقعی‌تر استفاده می‌شود که به غنی‌سازی مجموعه‌دادگان کمک می‌کند. در مرحله بعد، تکنیک‌های مختلف یادگیری ماشینی برای ارزیابی و دسته‌بندی داده‌های موجود و مصنوعی به‌کار گرفته می‌شوند.
[P129][Normal] مفاهیم کلیدی این پژوهش شامل شناسایی و مقابله با حملات تزریق پایگاه‌داده غیررابطه‌ای است که از نقاط ضعف این نوع پایگاه‌ها سوءاستفاده می‌کنند. این حملات معمولاً از طریق ارسال درخواست‌های مخرب و دست‌کاری پرس‌وجوها انجام می‌گیرند. همچنین، تحلیل و طراحی مجموعه‌دادگان شامل داده‌های اولیه و داده‌های مصنوعی تولیدشده با مدل‌های زبان بزرگ، یکی از محورهای اصلی پژوهش است. در این راستا، به‌جای استفاده از شبکه‌های مولد متخاصم، از مدل‌های زبان بهره گرفته می‌شود که توانایی تولید داده‌های متنی و ساختاریافته باکیفیت بالا را دارند.
[P130][Normal] پیش‌فرض‌ها
[P131][Normal] به‌منظور گسترش مجموعه‌دادگان و تأمین داده‌های متنوع و واقعی‌تر، از مدل‌های زبان بزرگ (مدل‌های زبان بزرگ) استفاده خواهد شد. این مدل‌ها قادرند داده‌هایی باکیفیت بالا و شباهت زیاد به داده‌های واقعی تولید کنند که می‌تواند به غنی‌سازی مجموعه‌دادگان کمک کند.
[P132][Normal] برای ارزیابی و دسته‌بندی داده‌های موجود و مصنوعی، از تکنیک‌های مختلف یادگیری ماشینی استفاده خواهد شد. این تکنیک‌ها شامل روش‌های نظارت‌شدن  و احتمالی ترکیبی برای شناسایی داده‌های مخرب هستند.
[P133][Normal] بر اساس رویکرد معرفی‌شده، مفاهیم و موضوعات کلیدی زیر در این پژوهش بررسی می‌شوند:
[P134][Normal] شناسایی و مقابله با حملات تزریق پایگاه‌داده غیررابطه‌ای، که از نقاط ضعف پایگاه‌داده‌های غیررابطه‌ای استفاده می‌کنند، به‌عنوان هدف اصلی تحقیق بررسی می‌شود. این حملات معمولاً از طریق ارسال درخواست‌های مخرب و دست‌کاری پرس‌وجوها به‌منظور سوءاستفاده از اطلاعات پایگاه‌داده انجام می‌گیرد.
[P135][Normal] تحلیل و طراحی مجموعه‌دادگان، شامل داده‌های اولیه و داده‌های مصنوعی تولیدشده با مدل‌های زبان بزرگ، یکی از محورهای پژوهش است. این مرحله شامل بررسی کیفیت داده‌ها، شناسایی ویژگی‌های مهم، و طراحی مجموعه‌دادگان قابل‌اعتماد برای مدل‌های یادگیری ماشینی است.
[P136][Normal] به‌منظور افزایش تنوع و حجم مجموعه‌دادگان، از مدل‌های تولید داده‌های مصنوعی استفاده خواهد شد. در این پژوهش به‌جای استفاده از شبکه‌های مولد متخاصم، از مدل‌های زبان بهره گرفته می‌شود که توانایی تولید داده‌های متنی و ساختاریافته باکیفیت بالا را دارند.
[P137][Normal] پژوهش شامل طراحی و ارزیابی یک سیستم یادگیری گروهی خواهد بود که از مدل‌های مختلف مانند رگرسیون خطی، درخت تصادفی، و XGBoost تشکیل شده است. این مدل‌ها با ترکیب قدرت یادگیری فردی خود، دقت شناسایی حملات را بهبود می‌بخشند.
[P138][Normal] ارائه روشی نوین برای شناسایی حملات تزریق پایگاه‌داده غیررابطه‌ای:
[P139][Normal] ایجاد مجموعه‌دادگان جامع و متنوع:
[P140][Normal] بهبود دقت مدل‌های یادگیری ماشینی:
[P141][Heading 2] 1-3 ضرورت انجام تحقيق
[P142][Normal] در زمینه حملات تزریق پایگاه‌داده غیررابطه‌ای، این ضرورت دوچندان می‌شود. این حملات به دلیل ساختار غیرمتعارف پایگاه‌داده‌های NoSQL و روش‌های خاص تزریق، از چالش‌های نوظهور امنیت سایبری به شمار می‌روند. شناسایی و پیشگیری از این حملات مستلزم دسترسی به داده‌هایی است که سناریوهای حمله را به طور دقیق شبیه‌سازی کنند.
[P143][Normal] ۱- نیازهای بازار کار: تقاضای روزافزون برای متخصصان توانمند در مدیریت پایگاه‌داده‌های غیررابطه‌ای و مقابله با حملات سایبری، از صنایع وب و نرم‌افزار فراتر رفته و به حوزه‌های خرده‌فروشی، بهداشت و دولتی گسترش یافته است.
[P144][Normal] ۳- گسترش خدمات آنلاین: افزایش وابستگی به خدمات آنلاین مبتنی بر پایگاه‌داده‌های NoSQL، نیاز به ایمن‌سازی این سیستم‌ها را به یک ضرورت جهانی تبدیل کرده است.
[P145][Normal] این پژوهش با تمرکز بر مدل‌های پیشرفته یادگیری ماشینی و مهندسی ویژگی هدفمند، گامی مؤثر در افزایش امنیت سایبری و مقابله با تهدیدات نوظهور در پایگاه‌داده‌های غیررابطه‌ای خواهد بود.
[P147][Normal] در زمینه حملات تزریق پایگاه‌داده غیررابطه‌ای، این ضرورت دوچندان می‌شود. این حملات به دلیل ساختار غیرمتعارف پایگاه‌داده‌های NoSQL و روش‌های خاص تزریق، از چالش‌های نوظهور امنیت سایبری به شمار می‌روند. شناسایی و پیشگیری از این حملات مستلزم دسترسی به داده‌هایی است که سناریوهای حمله را به طور دقیق شبیه‌سازی کنند.
[P148][Normal] ۱- نیازهای بازار کار: تقاضای روزافزون برای متخصصان توانمند در مدیریت پایگاه‌داده‌های غیررابطه‌ای و مقابله با حملات سایبری، از صنایع وب و نرم‌افزار فراتر رفته و به حوزه‌های خرده‌فروشی، بهداشت و دولتی گسترش یافته است. همچنین استفاده از این پایگاه‌داده‌ها در بازارهای مبتنی بر اینترنت اشیا و سامانه‌های اجتماعی سایبر فیزیکی، چالش‌های امنیتی جدیدی را مطرح کرده است.
[P149][Normal] ۳- گسترش خدمات آنلاین: با دسترسی بیش از ۹۱ درصد جمعیت ایران و ۶۷.۹ درصد جمعیت جهان به اینترنت، افزایش وابستگی به خدمات آنلاین مبتنی بر پایگاه‌داده‌های NoSQL، نیاز به ایمن‌سازی این سیستم‌ها را به یک ضرورت جهانی تبدیل کرده است. پایگاه‌داده‌های نرم‌افزارهای وب به هدف اصلی دسترسی‌های غیرمجاز تبدیل شده‌اند.
[P150][Normal] این پژوهش با تمرکز بر مدل‌های پیشرفته یادگیری ماشینی و مهندسی ویژگی هدفمند، گامی مؤثر در افزایش امنیت سایبری و مقابله با تهدیدات نوظهور در پایگاه‌داده‌های غیررابطه‌ای خواهد بود.
[P152][Normal] هدف اصلی این پژوهش، ارائه رویکردی جامع و نوین برای مقابله با تهدیدات امنیتی مرتبط با حملات تزریق پایگاه‌داده غیررابطه‌ای است. این هدف با طراحی و توسعه یک سیستم مبتنی بر یادگیری ماشینی، باقابلیت تشخیص دقیق و کارآمد بارهای مخرب  و تمایز آن‌ها از بارهای قانونی، دنبال می‌شود.
[P153][Normal] ۱. ایجاد و استفاده از یک مجموعه‌داده جامع و متنوع:
[P154][Normal] یکی از چالش‌های اساسی در حوزه تشخیص حملات تزریق پایگاه‌داده غیررابطه‌ای، فقدان مجموعه‌داده‌های استاندارد و جامع است. برای رفع این نقیصه، پژوهش حاضر بر تولید و بهره‌گیری از دو نوع مجموعه‌داده تمرکز دارد:
[P155][Normal] مجموعه‌داده اولیه: این مجموعه‌داده شامل نمونه‌های واقعی و برچسب‌گذاری‌شده از حملات تزریق MongoDB است که به‌صورت دستی جمع‌آوری و برچسب‌گذاری شده‌اند.
[P156][Normal] مجموعه‌داده مصنوعی: با استفاده از مدل‌های زبان بزرگ (GPT)، مجموعه‌داده‌ای مصنوعی تولید شده است که امکان شبیه‌سازی دقیق سناریوهای متنوع حملات تزریق پایگاه‌داده غیررابطه‌ای را فراهم می‌کند. این داده‌های مصنوعی با حفظ ویژگی‌های ساختاری و رفتاری داده‌های واقعی، تنوع و حجم مجموعه‌داده را به طور قابل‌توجهی افزایش می‌دهند.
[P157][Normal] استفاده از مدل‌های زبان بزرگ در تولید داده‌های مصنوعی، مزایای متعددی از جمله کاهش وابستگی به داده‌های واقعی محدود، افزایش تنوع سناریوهای حمله، و امکان تولید داده‌های برچسب‌گذاری‌شده با دقت بالا را به همراه دارد.
[P158][Normal] ۲. مهندسی ویژگی دستی و استخراج ویژگی‌های مؤثر:
[P159][Normal] شناسایی و استخراج ویژگی‌های کلیدی از داده‌های ورودی، یکی از گام‌های حیاتی در بهبود عملکرد مدل‌های یادگیری ماشینی است. در این پژوهش، فرایند مهندسی ویژگی به‌صورت دستی و با تمرکز بر ویژگی‌های خاص حملات تزریق پایگاه‌داده غیررابطه‌ای انجام شده است. این ویژگی‌ها شامل موارد زیر می‌باشند:
[P160][Normal] ویژگی‌های ساختاری: شناسایی الگوهای ساختاری در پرس‌وجوهای مخرب، مانند وجود عملگرهای خاص MongoDB (نظیر $ne، $where، $regex، $in)
[P161][Normal] ویژگی‌های رفتاری: تحلیل رفتار پرس‌وجوها از جمله طول کوئری، تعداد و نوع کاراکترهای خاص، و الگوهای غیرعادی در ساختار ورودی
[P162][Normal] ویژگی‌های محتوایی: بررسی محتوای بارهای داده (payloads) و شناسایی الگوهای مخرب در آن‌ها
[P163][Normal] فرایند مهندسی ویژگی در چندین مرحله انجام شده است:
[P164][Normal] ابتدا با الهام از تحقیقات پیشین در حوزه تزریق SQL (مانند کار رومانی)، ویژگی‌هایی استخراج شدند که متأسفانه برای حملات NoSQL کارایی مطلوبی نداشتند.
[P165][Normal] سپس مهندسی ویژگی دستی و خاص برای MongoDB انجام شد که نتایج بهتری را به همراه داشت.
[P166][Normal] در نهایت، ویژگی‌های استخراج‌شده بهینه‌سازی و تنظیم شدند تا حداکثر دقت در تشخیص حملات حاصل شود.
[P167][Normal] ۳. طراحی، پیاده‌سازی و بهینه‌سازی مدل‌های یادگیری ماشینی:
[P168][Normal] در این پژوهش، طیف گسترده‌ای از الگوریتم‌های یادگیری ماشینی برای تشخیص حملات تزریق پایگاه‌داده غیررابطه‌ای مورد بررسی و پیاده‌سازی قرار گرفته‌اند. مدل‌های استفاده‌شده عبارتند از:
[P169][Normal] رگرسیون خطی (رگرسیون لجستیک): به‌عنوان یک مدل پایه و ساده برای طبقه‌بندی دودویی (حمله/غیرحمله)
[P170][Normal] درخت تصمیم (درخت تصمیم): برای شناسایی الگوهای تصمیم‌گیری در داده‌ها
[P171][Normal] درخت تصادفی (جنگل تصادفی): یک مدل گروهی مبتنی بر ترکیب چندین درخت تصمیم
[P172][Normal] XGBoost: الگوریتم پیشرفته Gradient Boosting که کارایی بالایی در مسائل طبقه‌بندی دارد
[P173][Normal] Gradient Boosting (گرادیان بوستینگ): برای بهبود تدریجی عملکرد مدل از طریق یادگیری از خطاهای مراحل قبل
[P174][Normal] نزدیکترین همسایه (KNN - کا نزدیکترین همسایه): برای طبقه‌بندی مبتنی بر شباهت
[P175][Normal] Ensemble Model (مدل گروهی): ترکیب چندین مدل (شامل رگرسیون خطی، درخت تصادفی و XGBoost) برای بهره‌گیری از نقاط قوت هر یک و افزایش دقت کلی سیستم
[P176][Normal] برای هر یک از این مدل‌ها، فرایند بهینه‌سازی شامل موارد زیر انجام شده است:
[P177][Normal] تنظیم هایپرپارامترها: استفاده از تکنیک‌های Grid Search و Cross-Validation برای یافتن بهترین مقادیر پارامترها
[P178][Normal] اعتبارسنجی متقابل: استفاده از روش‌های اعتبارسنجی متقابل (K-Fold Cross-Validation) برای جلوگیری از بیش‌برازش (Overfitting) و اطمینان از قابلیت تعمیم‌پذیری مدل‌ها
[P179][Normal] بهینه‌سازی معماری مدل گروهی: تنظیم وزن‌ها و روش ترکیب مدل‌های فردی در سیستم Ensemble
[P180][Normal] ۴. ارزیابی جامع رویکرد پیشنهادی از منظر امنیت، دقت و کارایی:
[P181][Normal] رویکرد پیشنهادی از چندین منظر مختلف مورد ارزیابی و تحلیل قرار گرفته است:
[P182][Normal] الف) از منظر دقت و صحت:
[P183][Normal] Accuracy (دقت کلی): نسبت تشخیص‌های صحیح به کل نمونه‌ها
[P184][Normal] Precision (دقت مثبت): نسبت تشخیص‌های مثبت صحیح به کل تشخیص‌های مثبت
[P185][Normal] Recall (بازخوانی): نسبت تشخیص‌های مثبت صحیح به کل نمونه‌های مثبت واقعی
[P186][Normal] F1-Score: میانگین هارمونیک Precision و Recall
[P187][Normal] Confusion Matrix (ماتریس درهم‌ریختگی): تحلیل دقیق انواع خطاها (False Positive و False Negative)
[P188][Normal] ب) از منظر امنیت:
[P189][Normal] توانایی مدل در شناسایی دقیق حملات تزریق پایگاه‌داده غیررابطه‌ای و جلوگیری از نفوذ مخرب
[P190][Normal] کاهش نرخ مثبت کاذب (False Positive Rate) برای جلوگیری از ایجاد هشدارهای غیرضروری
[P191][Normal] کاهش نرخ منفی کاذب (False Negative Rate) برای اطمینان از عدم فرار حملات واقعی
[P192][Normal] ج) از منظر کارایی:
[P193][Normal] زمان پردازش و سرعت تشخیص حملات در سناریوهای واقعی
[P194][Normal] منابع محاسباتی موردنیاز (حافظه و پردازنده) برای اجرای مدل
[P195][Normal] قابلیت مقیاس‌پذیری (Scalability) در محیط‌های با حجم بالای داده
[P196][Normal] ۵. مقایسه تطبیقی با روش‌های موجود و تحلیل عملکرد:
[P197][Normal] یکی از اهداف کلیدی این پژوهش، مقایسه دقیق و جامع رویکرد پیشنهادی با روش‌های موجود در زمینه شناسایی حملات تزریق پایگاه‌داده غیررابطه‌ای است. این مقایسه شامل موارد زیر می‌شود:
[P198][Normal] مقایسه مجموعه‌داده‌ها: تحلیل مقایسه‌ای دقیق بین مجموعه‌داده اصلی و مجموعه‌داده مصنوعی تولیدشده توسط GPT از نظر توزیع، تنوع، و کیفیت داده‌ها
[P199][Normal] مقایسه عملکرد مدل‌ها: ارزیابی عملکرد مدل‌های مختلف یادگیری ماشینی بر روی هر دو مجموعه‌داده (اصلی و مصنوعی)
[P200][Normal] تحلیل ماتریس همبستگی: بررسی همبستگی بین ویژگی‌ها در هر دو مجموعه‌داده برای اطمینان از حفظ روابط میان ویژگی‌ها در داده‌های مصنوعی
[P201][Normal] آزمایش Cross-Dataset: استفاده از داده‌های مصنوعی برای آموزش و داده‌های اصلی برای تست (و بالعکس) برای ارزیابی قابلیت تعمیم‌پذیری مدل‌ها
[P202][Normal] مقایسه با پژوهش‌های پیشین: مقایسه نتایج با کارهای قبلی در حوزه تشخیص تزریق SQL و NoSQL
[P203][Normal] معیارهای مقایسه شامل:
[P204][Normal] صحت و دقت تشخیص (Accuracy, Precision, Recall,  F1-Score)
[P205][Normal] نرخ مثبت کاذب و منفی کاذب
[P206][Normal] زمان آموزش و تست مدل‌ها
[P207][Normal] پیچیدگی محاسباتی
[P208][Normal] قابلیت تعمیم‌پذیری و استحکام (Robustness) در برابر انواع مختلف حملات
[P209][Normal] پژوهش حاضر و رویکرد اجرایی
[P210][Normal] پژوهش حاضر بر استفاده از مدل‌های یادگیری ماشینی متکی است که با استفاده از مجموعه‌داده‌های تولیدشده توسط مدل‌های زبان بزرگ (GPT) آموزش داده می‌شوند. این مجموعه‌داده‌ها شامل داده‌های مصنوعی با ویژگی‌هایی شبیه به داده‌های واقعی هستند و نقش کلیدی در بهبود عملکرد مدل‌ها ایفا می‌کنند.
[P211][Normal] فرایند اجرایی پژوهش به‌صورت زیر است:
[P212][Normal] ۱. جمع‌آوری و برچسب‌گذاری داده‌های اولیه: ایجاد مجموعه‌داده پایه از نمونه‌های واقعی حملات و درخواست‌های عادی
[P213][Normal] ۲. مهندسی ویژگی دستی: استخراج ویژگی‌های مؤثر و خاص برای تشخیص حملات NoSQL
[P214][Normal] ۳. تولید داده‌های مصنوعی با GPT: استفاده از مدل‌های زبان بزرگ برای تولید داده‌های متنوع و برچسب‌گذاری‌شده
[P215][Normal] ۴. آموزش مدل‌های مختلف یادگیری ماشینی: پیاده‌سازی و آموزش شش مدل فردی و یک مدل گروهی
[P216][Normal] 5. ارزیابی و مقایسه: ارزیابی جامع عملکرد مدل‌ها بر روی مجموعه‌داده‌های مختلف و مقایسه نتایج
[P217][Normal] تنظیم دقیق پارامترهای مدل و استفاده از تکنیک‌های پیشرفته نظیر یادگیری گروهی (Ensemble Learning)، منجر به بهبود قابل‌توجه در دقت تشخیص حملات و کاهش نرخ هشدارهای کاذب می‌شود.
[P218][Heading 2] 1-6 نوآوري پژوهش
[P220][Normal] در این پژوهش، با استفاده از مدل‌های زبان بزرگ برای تولید داده‌های مصنوعی مرتبط با حملات MongoDB، یک مجموعه‌داده جامع و متنوع ایجاد شده است. همچنین، یک سیستم یادگیری گروهی طراحی شده که از ترکیب چندین مدل یادگیری ماشینی برای بهبود دقت تشخیص استفاده می‌کند. این رویکرد جامع، خلأ موجود در پژوهش‌های امنیت سایبری را پر کرده و گامی مهم در راستای ارتقای امنیت پایگاه‌داده‌های غیررابطه‌ای برداشته است.
[P221][Normal] نوآوری اصلی این پژوهش در تمرکز بر حملات تزریق پایگاه‌داده غیررابطه‌ای است که به‌دلیل تفاوت‌های ساختاری اساسی با پایگاه‌داده‌های رابطه‌ای، نیازمند رویکردهای امنیتی متفاوت و پیچیده‌تری هستند. برخلاف پایگاه‌داده‌های رابطه‌ای که از ساختار جدولی و زبان پرس‌وجوی استاندارد SQL استفاده می‌کنند، پایگاه‌داده‌های غیررابطه‌ای مانند MongoDB از ساختارهای غیرجدولی و زبان‌های پرس‌وجوی خاص خود بهره می‌برند. این تفاوت‌ها باعث می‌شود که حملات تزریق در این نوع پایگاه‌ها از الگوهای پیچیده‌تر و غیرمعمول‌تری استفاده کنند که شناسایی آن‌ها با روش‌های سنتی مبتنی بر SQL دشوار است.
[P222][NewParagraph] فصل پنجم: جمع‌بندی و کارهای آتی
[P224][Normal] در این فصل به بررسی مفاهیم بنیادی و پژوهش‌های مرتبط با این موضوع اختصاص دارد. ابتدا نقاط ضعف و چالش‌های امنیتی مرتبط با حملات تزریق داده در محیط‌های پایگاه‌داده غیررابطه‌ای بررسی می‌شود. سپس، مبانی یادگیری ماشینی، الگوریتم‌های مرتبط، و کاربردهای آن‌ها در امنیت سایبری موردبحث قرار می‌گیرد. در ادامه، مدل‌های زبان بزرگ  به‌عنوان رویکردی نوین برای تولید داده‌های مصنوعی معرفی و با روش‌های سنتی مانند شبکه‌های مولد متخاصم  مقایسه می‌شوند. همچنین، تحقیقات پیشین در زمینه تشخیص حملات تزریق پایگاه‌داده رابطه‌ای  و پایگاه‌داده غیررابطه‌ای مرور شده و دستاوردهای کلیدی آن‌ها تحلیل می‌شود. درنهایت، محدودیت‌های پژوهش‌های پیشین و نقاط تمایز رویکرد پیشنهادی این پژوهش نسبت به آن‌ها بیان می‌گردد.
[P225][Heading 3] 2-1-1 شناخت پایگاه‌داده‌های غیررابطه‌ای
[P226][Normal] پايگاه‌داده Mongodb به دليل فراگيرتر بودن در توسعه نرم‌افزارها هدف اصلي پياده‌سازي ماست. ازآنجايي‌که مجموعه‌داده عمدتاً از طريق خراش دادن وب و داده‌هاي افزوده به دست مي‌آيد، هدف خاص آموزش مدلي متناسب با پايگاه‌داده MongoDB را برآورده مي‌کند. ترکيب مجموعه‌داده براي دستيابي به اهداف موردنظر در اين مقاله کافي است.MongoDB محبوب‌ترين پایگاه‌داده غیررابطه‌ای است که در بين 500 سازمان برتر جهان مورد پذيرش قابل‌توجهي قرار گرفته است .
[P228][NewParagraph] MONGODB امکانات CURD را فراهم می‌کند و سیستم پایگاه‌داده امکان جستجو و ویرایش اطلاعات موجود در آن را برای کاربران فراهم می‌کند. تزریق مخرب می‌تواند منجر به مشکلات امنیتی جدی شود و هکرها می‌توانند کدهای مخرب را با تزریق به ورودی اجرا کنند تا به اطلاعات پایگاه‌داده دسترسی پیدا کنند.
[P229][Normal] MongoDB ارائه‌دهنده مقیاس‌پذیری بالا، کارایی عالی و امکانات موردنیاز برای مقیاس‌پذیری است. این پایگاه‌داده از فرمت‌های JSON و BSON پشتیبانی می‌کند و توانایی مدیریت میلیون‌ها یا حتی میلیاردها رکورد را دارا است. از "فهرست‏گذاری بر روي رشته‏ها" و شی‌ء گذاری پشتیبانی می‌کند و به‌صورت زمان واقعی عمل می‌کند. همچنین زبان پرس‌وجو MongoDB به نام Mongo است.
[P230][Normal] يادگيري ماشيني كه بر پايه جبر خطي است، داراي تنوع زيادي بوده که مي‌توان در بسياري از حوزه‌ها از آن استفاده کرد، اما براي بهره‏بردن از معماري‌هاي حوزه خاصي مانند واحد پردازش تنسور گوگل محدود است. همچنين، رشد تقاضا براي محاسبات یادگیری ماشین از قانون مور فراتر رفته و نياز است کارشناسان یادگیری ماشین و معماران رايانه براي طراحي سامانه‌هاي محاسباتي موردنياز براي ارائه امکانات یادگیری ماشین به يکديگر کمک کنند. براين‌اساس مي‏توان پيشنهادها و هشدارهايي به معماران رايانه در مورد تحولات يادگيري ماشين ارائه داد.
[P231][Normal] يک مدل يادگيري ماشين عملکرد حداکثري خواهد داشت اگر داده‌هاي آن از نظر كيفي و كمي حد مناسبي داشته باشند. درحالي‌که پژوهشگران بر روي بهبود کيفيت مدل‌ها (مانند جستجوي معماري عصبي و انتخاب خودکار ويژگي) تمرکز داشته‌اند، تلاش‌هاي محدودي براي بهبود کيفيت داده‌ها انجام شده است. يکي از نيازهاي حياتي پيش از استفاده از مجموعه‌داده براي هر كاري، درک مجموعه‌داده آن حوزه است و عدم انجام اين کار ممکن است منجر به تجزيه‌وتحليل نادرست و تصميم‌گيري‌هاي ناقص شود.
[P232][Normal] [منتقل‌شده از فصل ۱]
[P233][Normal] طبق يافته‌هاي قبلي مي‏دانيم كه امروزه حملات تزريق از خطرسازترين حملات محسوب مي‌شوند، تحقيقات زيادي در حوزه پايگاه‌داده‌هاي ساخت‌يافته صورت پذيرفته است، كه مي‏توان با تعميم اين كارها به پايگاه‌داده‌هاي ديگر اين مسئله را از ابعاد جديدي مورد بررسي قرارداد.
[P234][Heading 3] 1-2-3 بررسي اهميت پايگاه‏داده‏هاي غيررابطه‏اي
[P235][Heading 3] 2-1-2 بررسی نقاط ضعف و چالش‌های امنیتی مرتبط با حملات تزریق داده در محیط‌های  پایگاه‌داده غیررابطه‌ای
[P236][NewParagraph] یکی از مهم‌ترین ویژگی‌های پایگاه‌داده‌های غیررابطه‌ای، ساختار منعطف آن‌ها است که برخلاف پایگاه‌داده‌های رابطه‌ای  پایگاه‌داده رابطه‌ای، از مدل‌های داده متنوعی مانند مستند محور، گرافی، کلید - مقدار و جدولی پشتیبانی می‌کند. این انعطاف‌پذیری اگرچه مزایای قابل‌توجهی دارد، اما به دلیل نبود یک استاندارد امنیتی جامع، بستری برای سوءاستفاده مهاجمان فراهم می‌کند. بسیاری از پایگاه‌داده‌های غیررابطه‌ای بدون کنترل دسترسی قوی یا ابزارهای احراز هویت اولیه عرضه می‌شوند که می‌تواند منجر به نفوذ و تزریق داده‌های مخرب شود.
[P237][NewParagraph] بسیاری از پایگاه‌داده‌های غیررابطه‌ای از سیاست‌های کنترل دسترسی ساده یا ناکافی استفاده می‌کنند. این موضوع، به‌ویژه در مواردی که سیستم‌ها برای کارایی بیشتر بهینه شده‌اند، می‌تواند منجر به دسترسی غیرمجاز به داده‌های حساس شود. برای مثال، در برخی از پایگاه‌داده‌های غیررابطه‌ای، احراز هویت به‌صورت پیش‌فرض غیرفعال است یا تنظیمات امنیتی به طور کامل به توسعه‌دهندگان واگذار می‌شود.
[P238][NewParagraph] اگرچه پایگاه‌داده‌های غیررابطه‌ای به‌طورکلی برای مقیاس‌پذیری طراحی شده‌اند، اما تضمین امنیت در مقیاس بالا یک چالش اساسی است. با افزایش تعداد گره‌ها و حجم داده‌ها، مدیریت امنیت به‌صورت یکپارچه دشوارتر می‌شود و ممکن است نقاط ضعف جدیدی در سیستم ایجاد کند.
[P239][NewParagraph] پایگاه‌داده‌های غیررابطه‌ای به دلیل توانایی مدیریت داده‌های غیرساختاریافته، به طور گسترده در اینترنت اشیا  استفاده می‌شوند. اما ترکیب حجم بالای داده‌های تولیدشده در اینترنت اشیا  و نبود سیاست‌های امنیتی قوی در پایگاه‌داده‌های غیررابطه‌ای، یک نقطه‌ضعف عمده ایجاد می‌کند. مهاجمان می‌توانند از این ضعف‌ها برای حملات تزریق و دسترسی غیرمجاز به داده‌های حساس دستگاه‌های اینترنت اشیا  استفاده کنند.
[P240][Normal] فصل پنجم شامل جمع‌بندی و کارهای آتی است. در این فصل، دستاوردهای اصلی پژوهش، مرور نوآوری‌ها، بیان محدودیت‌ها و ارائه پیشنهادهای مشخص برای توسعه و پژوهش‌های آینده ارائه می‌شود.
[P241][Normal] فصل چهارم به تحلیل نتایج و بحث اختصاص دارد. در این فصل، مراحل آماده‌سازی داده‌ها، اجرای مدل‌ها و نحوه ارزیابی بیان می‌شود. سپس عملکرد مدل‌ها با معیارهایی مانند دقت، شاخص‌های خطا، و معیارهای زمانی و کارایی مقایسه و تحلیل می‌گردد. همچنین، تفسیر یافته‌ها، مقایسه با پیشینه پژوهش، بررسی نقاط قوت و محدودیت‌ها، و تحلیل اثر داده‌های مصنوعی و انتخاب مدل‌ها بر عملکرد و تعمیم‌پذیری ارائه می‌شود.
[P242][Normal] فصل سوم روش پیشنهادی را تشریح می‌کند. این فصل شامل چارچوب کلی پژوهش، فرایند تولید داده مصنوعی مبتنی بر مدل‌های زبان بزرگ، معرفی مدل‌های یادگیری ماشین و مدل‌های گروهی به‌کاررفته و منطق انتخاب آن‌ها، تنظیمات کلیدی و پارامترها، و معماری پیاده‌سازی سیستم پیشنهادی است.
[P243][Normal] فصل دوم به بررسی مبانی نظری و پیشینه پژوهش اختصاص دارد. در این فصل، مفاهیم پایه مرتبط با حملات تزریق در پایگاه‌داده‌های غیررابطه‌ای، کاربردهای یادگیری ماشین در امنیت، و رویکردهای تولید داده مصنوعی با مدل‌های زبان بزرگ در مقایسه با روش‌های سنتی مرور می‌شوند. همچنین، شکاف‌های پژوهشی و تمایزات رویکرد پیشنهادی جمع‌بندی می‌گردد.
[P244][Normal] این پایان‌نامه در شش فصل تنظیم شده است و مسیر پژوهش را از مبانی نظری تا جمع‌بندی و پیشنهادهای آتی به‌صورت منسجم دنبال می‌کند.
[P245][Normal] تکنیک‌هایی که برای تزریق به پایگاه‌داده‌های پایگاه‌داده رابطه‌ای  و پایگاه‌داده غیررابطه‌ای استفاده می‌شوند، تا حد زیادی مشابه هستند. در اینجا چهار نوع از تزریق‌های پایگاه‌داده غیررابطه‌ای توضیح داده شده‌اند:
[P249][Normal] براي نمونه در مدل‌هاي مبتني بر يادگيري عميق، بدون وابستگي به قواعد پايه پايگاه‌داده، از يک مدل پردازش زبان طبيعي و چارچوب يادگيري عميق استفاده مي‌کند. اين روش مي‌تواند دقت را افزايش داده و نرخ هشدارهاي غلط را کاهش دهد درحالي‌که به ماشين اجازه می‌دهد به طور خودکار ويژگي‌هاي مدل زبان حملات تزريق پرس‌وجو را ياد بگيرد، کاهش قابل‌توجهي نيز در دخالت انسان و ارائه دفاع در برابر حملات Zeroday که هرگز رخ نمي‌دهد، فراهم مي‌کند.
[P250][Normal] بررسي رويكردهاي يادگيري ماشين و يادگيري عميق
[P251][Normal] بررسي رويكردهاي سنتي مبتني بر امضا
[P252][Normal] با اينکه اين آسيب‌پذيري بيش از 20 سال است كه شناخته شده، حملات تزريق هنوز در رتبه سوم آسيب‌پذيري‌هاي وب قرار دارند. در سال 2022، 1162 آسيب‌پذيري با نوع تزريق‌ پرس‏وجو به‌عنوان CVE پذيرفته شده‌اند كه مي‏توان اين برداشت را داشت كه حملات تزريق پرس‏وجو هنوز موجود هستند .
[P254][Caption] شکل 1- 1: توزيع آسيب‌پذيري‌هاي بحراني برنامه‌هاي وب در سراسر جهان تا سال 2022
[P256][Normal] تزريق پایگاه‌داده رابطه‌ای  نوعي حمله سايبري است که برنامه‌هاي مبتني بر داده را هدف قرار می‌دهد. اين اقدام شامل درج عبارات پرس‌وجوي مخرب در فيلدهاي ورودي يا عامل‌هاي يک برنامه وب براي دست‌کاري يا استخراج داده‌هاي حساس از پايگاه‌داده بوده و يكي از آسيب‏پذيري‏هاي اساسي آن‏هاست. در بررسي انجام شده سال 2022 مشخص گرديد كه 33 درصد از آسيب‌پذيري‌هاي حياتي اينترنت، ناشي از اين حملات بوده است. اين امر نشان می‌دهد كه سازمان‌ها نياز فوري به انجام اقدامات پيشگيرانه در مقابله با حملات تزريق پرس‏وجو دارند.
[P257][Heading 3] 1-2-1 تشخيص حملات  تزريق پایگاه‌داده غیررابطه‌ای
[P258][Normal] [منتقل‌شده از فصل ۱]
[P259][Normal] ممکن است بتوان عملگرهاي پرس‏وجو را براي دست‌کاری آن‏ها در پایگاه‌داده غیررابطه‌ای تزريق كرد. براي انجام اين کار، اپراتورهاي مختلف را به طور سيستماتيک در طيفي از ورودی‌های کاربر ارسال کرده و سپس پاسخ‌ها را براي پیام‌های خطا و يا تغييرات ديگر بررسي بايد كرد.
[P260][Caption] جدول 1- 1: نمونه هايي از عملگرهاي پرس‌وجو MongoDB
[P261][Normal] در پایگاه‌داده غیررابطه‌ای اغلب از عملگرهاي پرس‌وجو استفاده مي‏شود که راه‏هايي را براي تعيين شرايطي که داده‌ها بايد داشته باشند تا در نتيجه پرس‌وجو قرار گيرند، ارائه می‌دهند. نمونه‌هایی از عملگرهاي پرس‌وجو MongoDB در جدول 1-1 آمده است.
[P262][Normal] راه‏هاي مختلف ديگري نيز براي ايجاد بار براي اين دست حملات وجود دارد كه مثال فوق يك نمونه از دست‌کاری در نگارش پرس‏وجو است
[P263][Normal] اگر اجرا اين آدرس باعث تغيير در پاسخ اصلي شود، ممکن است نشان‌دهنده اين باشد که ورودي کاربر به‌درستی فيلتر يا تصفيه نشده است.
[P264][Normal] از اين رشته fuzz براي ساخت حمله زير استفاده مي‏شود:
[P266][Normal] براي تست اينکه آيا ورودي ممکن است آسیب‌پذیر باشد، یک‌رشته fuzz را در مقدار پارامتر دسته‌بندی ارسال كرده كه یک‌رشته نمونه براي MongoDB به‌صورت زير است:
[P267][Normal] اين باعث مي‌شود که برنامه يک پرس‏وجو JSON براي بازيابي محصولات مربوطه از مجموعه محصولات در پایگاه‌داده MongoDB ارسال کند:
[P268][Normal] يک وبگاه خريد که محصولات را در دسته‌بندي‌هاي مختلف نمايش می‌دهد را در نظر گرفته. هنگامي که کاربر دسته‌بندي نوشيدني‌هاي گازدار را انتخاب مي‌کند، مرورگر آن‌ها URL زير را درخواست می‌دهد:
[P269][Normal] به‌عنوان‌مثال مي‏توان اين حملات را در پایگاه‌داده MongoDB مورد بررسي قرارداد تا اين دو نوع حمله بيشتر آشنا شد:
[P270][Normal] در اين پژوهش، نحوه آزمايش آسيب‌پذيري‌هاي پایگاه‌داده غیررابطه‌ای را به‌طورکلی بررسي كرده، سپس بر روي بهره‌برداري از حملات در يكي از انواع پایگاه‌داده غیررابطه‌ای تمرکز خواهد داشت.
[P271][Caption] شکل 1- 3: يك سناريو دور زدن احراز هويت
[P273][Normal] تزريق عملگر - زماني اتفاق می‌افتد که می‌توان از عملگرهاي پرس‏وجو پایگاه‌داده غیررابطه‌ای براي دست‌کاری پرس‏وجوها استفاده کرد.
[P274][Normal] تزريق با اشتباه نوشتاري: زماني اتفاق مي‌افتد که مي‌توان نوشتار پرس‌وجو پایگاه‌داده غیررابطه‌ای را تغيير داده و محموله خود را تزريق کرد. اين متدولوژي مشابه روشي است که در تزريق پایگاه‌داده رابطه‌ای  استفاده می‌شود. بااین‌حال ماهيت حمله به طور قابل‌توجهی متفاوت است، زيرا پايگاه‏هاي داده پایگاه‌داده غیررابطه‌ای از طيف وسيعي از زبان‏هاي پرس‏وجو، انواع نحو پرس‏وجو و ساختارهاي داده متفاوت استفاده مي‏کنند.
[P275][Normal] دو نوع مختلف تزريق پایگاه‌داده غیررابطه‌ای وجود دارد:
[P276][Normal] پایگاه‌داده غیررابطه‌ای داده‏ها را در قالبي غير از جداول سنتي پایگاه‌داده رابطه‌ای  ذخيره و بازيابي مي‏کنند. آن‏ها از طيف گسترده‌ای از زبان‌های پرس‌وجو به‌جای يک استاندارد جهاني مانند پایگاه‌داده رابطه‌ای  استفاده می‌کنند و محدودیت‌های رابطه‏اي کمتري دارند.
[P277][Normal] اجراکردن کد روی سرور
[P278][Normal] باعث انکار خدمات
[P279][Normal] استخراج يا ويرايش داده‏ها
[P280][Normal] دورزدن مکانیسم‌های احراز هويت يا حفاظت
[P281][Normal] تزريق پایگاه‌داده غیررابطه‌ای آسيب‌پذيري است که در آن يک مهاجم مي‌تواند با استفاده از پرس‏وجوهايي که يک برنامه کاربردي در پایگاه‌داده غیررابطه‌ای دارد تداخل‏هاي ايجاد كرده كه  اين تزريق پایگاه‌داده غیررابطه‌ای توانمندي‏هايي نظير زير را به او می‌دهد:
[P282][Heading 3] 1-2-4 ارائه نمونه‌ای حمله تزريق پایگاه‌داده غیررابطه‌ای
[P283][Normal] [منتقل‌شده از فصل ۱]
[P284][Normal] این پرس‌وجوها اطلاعاتی را نشان می‌دهند که در آن نام کاربری و رمز عبور NULL نیستند. هکرها می‌توانند از عملگر "$ne" (به معنای "نابرابر") استفاده کنند تا بدون واردکردن نام کاربری و رمز عبور صحیح به سیستم وارد شوند.
[P285][List Paragraph] پرس‌وجوهای Union: هکر از یک پارامتر آسیب‌پذیر برای تغییر داده‌هایی که قرار بود از یک پرس‌وجو بازگردانده شود، استفاده می‌کند. یک شرط OR برای اتصال یک عبارت خالی به ورودی استفاده می‌شود. ازآنجاکه یک عبارت خالی همیشه معتبر است، بررسی رمز عبور بی‌اثر می‌شود. به‌عنوان‌مثال:
[P288][Normal] در اینجا پرس‌وجوی خالی {} همیشه مقدار true دارد [
[P289][List Paragraph] تزریق جاوا اسکریپت : پایگاه‌های داده پایگاه‌داده غیررابطه‌ای اجازه اجرای کدهای جاوا اسکریپت را می‌دهند و می‌توانند پرس‌وجوها و تراکنش‌های پیچیده‌ای را روی موتور پایگاه‌داده اجرا کنند. اگر ورودی کاربر فیلتر یا اعتبارسنجی نشود، ممکن است خطر تزریق کدهای تصادفی جاوا اسکریپت وجود داشته باشد.
[P290][List Paragraph] پرس‌وجوهای زنجیره‌ای  : در این روش، هکر از توالی‌های فرار و کاراکترهای ویژه‌ای مانند بازگشت به خط ، خط جدید ، آکولادهای بسته، و علامت نقطه‌ویرگول برای پایان‌دادن به یک پرس‌وجو و سپس افزودن پرس‌وجوهای مخرب اضافی برای اجرا استفاده می‌کند. این عمل می‌تواند پایگاه‌داده را به‌شدت خراب کند. برای مثال:
[P291][Normal] پرس‌وجو:
[P293][Normal] در اینجا، پس از یک نقطه‌ویرگول (;)، هکر یک پرس‌وجوی مخرب اضافی را تزریق می‌کند.نقض مبدا : رابط برنامه‌نویسی REST در HTTP، نوع جدیدی از آسیب‌پذیری‌ها را به وجود آورده است که به مهاجم اجازه می‌دهد حتی از یک دامنه دیگر به پایگاه‌داده غیررابطه‌ای حمله کند. در حملات Cross-Origin، یک کاربر مجاز و مرورگر وب او مورد سوءاستفاده قرار می‌گیرند تا هکر بتواند عملیات نامطلوبی را اجرا کند. به شکل جعل درخواست بین‌سایتی ، این حمله زمانی رخ می‌دهد که اعتماد سایتی به مرورگر کاربر مورد سوءاستفاده قرار می‌گیرد تا یک عملیات غیرقانونی روی پایگاه‌داده غیررابطه‌ای اجرا شود. با تزریق یک فرم HTیادگیری ماشین در یک وب‌سایت آسیب‌پذیر یا فریب کاربر برای بازدید از وب‌سایت شخصی هکر، هکر می‌تواند یک عملیات پست  را روی پایگاه‌داده اجرا کند.
[P295][Heading 3] 2-1-3 یادگیری ماشین
[P296][Normal] یادگیری ماشین یکی از شاخه‌های برجسته هوش مصنوعی است که به ماشین‌ها امکان می‌دهد از داده‌ها یاد بگیرند و بدون نیاز به برنامه‌نویسی صریح، عملکرد خود را بهبود دهند. در حوزه امنیت سایبری، یادگیری ماشین نقش مهمی در شناسایی تهدیدات، پیشگیری از حملات، و تحلیل رفتارهای غیرعادی ایفا می‌کند. این بخش به‌مرور مفاهیم بنیادین یادگیری ماشین، بررسی الگوریتم‌های مرتبط، و کاربردهای آن‌ها در امنیت سایبری اختصاص دارد.
[P297][Normal] یادگیری ماشین فرایندی است که در آن سیستم‌های کامپیوتری توانایی یادگیری از داده‌ها و بهبود عملکرد خود در انجام وظایف خاص را پیدا می‌کنند. این فرایند شامل مراحل زیر است:
[P298][Normal] ورود داده‌ها: داده‌ها به‌عنوان ورودی به سیستم داده می‌شوند.
[P299][Normal] استخراج ویژگی‌ها: ویژگی‌های مرتبط با مسئله از داده‌ها استخراج می‌شوند.
[P300][Normal] مدل‌سازی: مدل‌های آماری یا الگوریتم‌های یادگیری برای شناسایی الگوها استفاده می‌شوند.
[P301][Normal] پیش‌بینی: مدل، داده‌های جدید را تحلیل کرده و خروجی پیش‌بینی می‌کند.
[P302][Normal] ارزیابی: عملکرد مدل بر اساس معیارهایی نظیر دقت، یادآوری و نرخ مثبت کاذب ارزیابی می‌شود.
[P303][Normal] یادگیری ماشین به سه دسته اصلی تقسیم می‌شود:
[P304][Normal] یادگیری نظارت شده :
[P305][Normal] در این روش، مدل‌ها از داده‌های برچسب‌گذاری شده آموزش می‌بینند. این رویکرد برای مسائل دسته‌بندی و پیش‌بینی مناسب است.
[P306][Normal] مثال: تشخیص حملات سایبری بر اساس الگوهای مشخص حملات پیشین.
[P307][Normal] یادگیری بدون نظارت:
[P308][Normal] مدل‌ها در این روش از داده‌های بدون برچسب استفاده می‌کنند و به کشف ساختارها و الگوهای مخفی در داده‌ها می‌پردازند.
[P309][Normal] مثال: شناسایی خوشه‌های مشکوک در ترافیک شبکه.
[P310][Normal] یادگیری تقویتی :
[P311][Normal] این روش مبتنی بر یادگیری از طریق تعامل با محیط است، به‌طوری‌که عامل هوشمند با دریافت پاداش یا تنبیه به یادگیری می‌پردازد.
[P312][Normal] مثال: طراحی سیستم‌های تطبیقی برای شناسایی حملات در زمان واقعی.
[P313][Heading 4] 2-1-3-1  الگوریتم‌های مرتبط در یادگیری ماشین
[P314][Normal] الگوریتم‌های پایه‌ای
[P315][Normal] رگرسیون لجستیک
[P316][Normal] این الگوریتم برای مسائل دسته‌بندی دودویی استفاده می‌شود و احتمال وقوع یک رویداد را مدل‌سازی می‌کند.
[P317][Normal] کاربرد: شناسایی بسته‌های شبکه‌ای مخرب.
[P318][Normal] درخت تصمیم
[P319][Normal] این مدل بر اساس گره‌هایی که معیارهای تصمیم‌گیری خاصی را بررسی می‌کنند، عمل می‌کند.
[P320][Normal] کاربرد: تحلیل رفتار کاربران و شناسایی دسترسی‌های غیرمجاز.
[P321][Normal] ماشین بردار پشتیبان
[P322][Normal] الگوریتمی است که داده‌ها را با استفاده از یک ابر صفحه به دودسته جدا می‌کند.
[P323][Normal] کاربرد: تشخیص بدافزار با تفکیک ویژگی‌های بدافزار از نرم‌افزارهای سالم.
[P324][List Paragraph] االگوریتم (KNN) یکی از ساده‌ترین و در عین حال قدرتمندترین الگوریتم‌های یادگیری ماشین است که در دسته‌ی یادگیری نظارت‌شده قرار می‌گیرد. این الگوریتم برای طبقه‌بندی  و رگرسیون  به کار می‌رود، اما عمدتاً در مسائل طبقه‌بندی مورد استفاده قرار می‌گیرد.
[P325][Normal] الگوریتم‌های پیشرفته
[P326][Normal] جنگل تصادفی
[P327][Normal] یک الگوریتم یادگیری گروهی که از ترکیب چندین درخت تصمیم برای افزایش دقت و کاهش بیش برازش استفاده می‌کند.
[P328][Normal] کاربرد: تحلیل داده‌های بزرگ امنیتی.
[P329][Normal] XGBoost:
[P330][Normal] یکی از قدرتمندترین الگوریتم‌های گروهی است که برای مسائل طبقه‌بندی و رگرسیون استفاده می‌شود.
[P331][Normal] کاربرد: شناسایی حملات پیچیده در ترافیک شبکه.
[P332][Normal] یادگیری عمیق:
[P333][Normal] این روش بر معماری‌های شبکه عصبی عمیق تکیه دارد و توانایی درک داده‌های پیچیده؛ مانند تصاویر، صدا، و متون را دارد.
[P334][Normal] کاربرد: شناسایی بدافزارهای ناشناخته.
[P335][NewParagraph] در جدول زیر، مقایسه‌ای دقیق از مدل‌های رگرسیون لجستیک، جنگل تصادفی و XGBoost بر اساس معیارهای مختلف ارائه شده است:
[P336][Caption] جدول3- 1: مقایسه‌ای دقیق از مدل‌ها
[P338][Normal] در ادامه کاربرد یادگیری ماشین در امنیت سایبری را شرح می‌دهیم:
[P339][List Paragraph] کاربردهای تشخیص نفوذ: یکی از مهم‌ترین کاربردهای یادگیری ماشین، شناسایی نفوذ و فعالیت‌های غیرمجاز در سیستم‌های کامپیوتری است. الگوریتم‌ها با تحلیل ترافیک شبکه می‌توانند رفتارهای مشکوک را شناسایی و اقدامات لازم را انجام دهند.
[P340][List Paragraph] شناسایی بدافزار: الگوریتم‌های یادگیری ماشینی می‌توانند با تحلیل ویژگی‌های فایل‌ها و کدها، بدافزارها را شناسایی کنند. به‌عنوان‌مثال، درخت تصادفی و XGBoost برای شناسایی بدافزارهای پیچیده بسیار مؤثر هستند.
[P341][List Paragraph] تحلیل لاگ‌ها: سیستم‌های امنیتی از یادگیری ماشینی برای تحلیل حجم عظیمی از لاگ‌های تولیدشده توسط شبکه‌ها و سیستم‌ها استفاده می‌کنند. این تحلیل به شناسایی الگوهای مخرب کمک می‌کند.
[P342][List Paragraph] تشخیص حملات تزریق: الگوریتم‌های نظارت شده نظیر رگرسیون خطی و SVM برای تشخیص حملات تزریق پایگاه‌داده رابطه‌ای  و پایگاه‌داده غیررابطه‌ای با تحلیل داده‌های ورودی و الگوهای مخرب استفاده می‌شوند.
[P343][List Paragraph] پیشگیری از حملات فیشینگ: با استفاده از یادگیری ماشینی، ایمیل‌ها و صفحات وب مشکوک بررسی و الگوهای حملات فیشینگ شناسایی می‌شوند. الگوریتم‌های نظارت شده برای این منظور بسیار کاربردی هستند.
[P344][List Paragraph] شناسایی رفتارهای مشکوک کاربران: الگوریتم‌های بدون نظارت، مانند خوشه‌بندی، می‌توانند رفتارهای کاربران را مدل‌سازی کرده و رفتارهای غیرعادی را شناسایی کنند.
[P345][List Paragraph] سیستم‌های توصیه‌گر امنیتی: با تحلیل الگوهای تهدید و آسیب‌پذیری، مدل‌های یادگیری ماشینی می‌توانند پیشنهادهایی برای ارتقا امنیت سیستم‌ها ارائه دهند.
[P346][Normal] چالش‌ها و محدودیت‌های یادگیری ماشین در امنیت سایبری عبارت‌اند از:
[P347][List Paragraph] کمبود مجموعه‌داده‌های جامع: بسیاری از مدل‌های یادگیری ماشینی برای عملکرد بهینه به داده‌های بزرگ و متنوع نیاز دارند. در حوزه امنیت سایبری، مجموعه‌داده‌های استاندارد و متنوع به‌سختی قابل‌دسترس هستند.
[P348][List Paragraph] حملات به مدل‌های یادگیری ماشینی: مهاجمان ممکن است مدل‌های یادگیری ماشینی را هدف حملات خود قرار دهند. برای مثال:
[P349][Normal] حملات تزریق داده مخرب: تزریق داده‌های جعلی برای تغییر عملکرد مدل.
[P350][Normal] حملات استنتاج مدل: شناسایی رفتارهای مدل برای استفاده از نقاط ضعف آن.
[P351][List Paragraph] تغییرات در الگوهای تهدید: الگوهای حملات سایبری به‌سرعت تغییر می‌کنند که باعث می‌شود مدل‌های یادگیری ماشینی نیاز به به‌روزرسانی مداوم داشته باشند.
[P352][Normal] یادگیری ماشینی به‌عنوان یکی از ابزارهای کلیدی در امنیت سایبری، توانایی تحلیل و شناسایی تهدیدات پیچیده را فراهم می‌کند. از تشخیص بدافزارها گرفته تا شناسایی رفتارهای مشکوک کاربران، این فناوری نقش مهمی در ایمن‌سازی سیستم‌ها ایفا می‌کند. بااین‌حال، چالش‌هایی نظیر کمبود داده‌های استاندارد و تغییرات سریع در الگوهای تهدیدات نشان می‌دهد که توسعه و پیاده‌سازی راهکارهای یادگیری ماشینی در امنیت سایبری نیازمند تحقیق و تلاش مداوم است.
[P353][Normal] در این پژوهش، تلاش می‌شود با استفاده از مدل‌های پیشرفته نظیر درخت تصادفی و XGBoost و تولید مجموعه‌داده‌های مصنوعی با مدل‌های زبان بزرگ، این چالش‌ها تاحدامکان مرتفع شوند و راهکاری جامع برای مقابله با حملات سایبری ارائه شود.
[P354][Heading 3] 2-1-3-2 معرفی مدل‌های زبان بزرگ و مقایسه آن‌ها با روش‌های سنتی درتولید داده‌های مصنوعی
[P355][Normal] مدل‌های زبان بزرگ و شبکه‌های مولد متخاصم هر دو به‌عنوان ابزارهای پیشرفته در تولید داده‌های مصنوعی مطرح هستند. این مدل‌ها، هرچند در اهداف و کاربردها مشترکاتی دارند، اما از لحاظ ساختار، روش کار و قابلیت‌ها تفاوت‌های چشمگیری نشان می‌دهند. در این بخش، ابتدا مدل‌های زبان بزرگ معرفی می‌شوند و سپس مقایسه‌ای جامع میان این مدل‌ها و روش‌های سنتی مانند شبکه‌های مولد متخاصم  ارائه می‌شود.
[P356][Normal] مدل‌های زبان بزرگ، معماری‌هایی مبتنی بر شبکه‌های عصبی ترانسفورمرهستند که برای پردازش زبان طبیعی  طراحی شده‌اند. این مدل‌ها به دلیل آموزش بر روی مقادیر عظیمی از داده‌های متنی، قابلیت درک و تولید متون پیچیده را دارا هستند. ویژگی‌های کلیدی مدل‌های زبان بزرگ عبارت‌اند از:
[P357][Normal] معماری ترانسفورمر:
[P358][List Paragraph] این مدل‌ها از معماری ترانسفورمر بهره می‌برند که امکان پردازش داده‌ها به‌صورت موازی و یادگیری روابط طولانی‌مدت میان کلمات و جملات را فراهم می‌کند.
[P359][Normal] مقیاس‌پذیری بالا
[P360][List Paragraph] مدل‌های زبان بزرگ‌ها بر روی مجموعه‌داده‌های عظیم و با استفاده از میلیاردها پارامتر آموزش‌دیده‌اند.
[P361][Normal] توانایی تولید داده‌های متنی واقعی:
[P362][List Paragraph] مدل‌های زبان بزرگ   می‌توانند متن‌هایی تولید کنند که از نظر ساختار و معنا به متون واقعی شباهت زیادی دارند.
[P363][List Paragraph] کاربردهای مدل‌های زبان بزرگ   در تولید داده‌های مصنوعی
[P364][Normal] شبیه‌سازی داده‌های متنی:
[P365][List Paragraph] مدل‌های زبان بزرگ‌ها قادرند داده‌های متنی مصنوعی تولید کنند که می‌تواند شامل پرس‌وجوهای پایگاه‌داده، پیام‌های کاربران، یا داده‌های امنیتی باشد.
[P366][Normal] تولید داده‌های متنوع برای امنیت سایبری:
[P367][List Paragraph] این مدل‌ها می‌توانند داده‌های مرتبط با حملات سایبری مانند تزریق پایگاه‌داده غیررابطه‌ای را باکیفیت بالا و تنوع زیاد تولید کنند.
[P368][Normal] ایجاد داده‌های ترکیبی:
[P369][Normal] مدل‌های زبان بزرگ‌ها می‌توانند داده‌هایی ترکیبی شامل متن و کد تولید کنند که برای آموزش مدل‌های یادگیری ماشینی در حوزه امنیت سایبری بسیار مفید است.
[P370][Normal] شبکه‌های مولد متخاصم  معماری‌هایی متشکل از دو شبکه عصبی هستند:
[P371][Normal] مولد: وظیفه تولید داده‌های مصنوعی را دارد.
[P372][Normal] تفکیک‌کننده : وظیفه تشخیص داده‌های مصنوعی از داده‌های واقعی را برعهده دارد.
[P373][Normal] این دو شبکه در رقابتی متقابل عمل می‌کنند، به‌طوری‌که مولد تلاش می‌کند داده‌هایی تولید کند که نتوانند توسط تفکیک‌کننده شناسایی شوند. ویژگی‌های کلیدی شبکه‌های مولد متخاصم  عبارت‌اند از:
[P374][List Paragraph] تخصص در داده‌های غیرمتنی:
[P375][Normal] شبکه‌های مولد متخاصم   در تولید داده‌های تصویری و سیگنال‌های پیچیده نظیر صدا یا ویدئو بسیار موفق عمل کرده‌اند.
[P376][Normal] عملکرد مبتنی بر رقابت:
[P377][Normal] مولد و تفکیک‌کننده در فرایندی رقابتی بهبود پیدا می‌کنند که باعث افزایش کیفیت داده‌های تولیدشده می‌شود.
[P378][Normal] محدودیت‌های شبکه‌های مولد متخاصم   را در ادامه بیان می‌کنیم:
[P379][Normal] محدودیت در تولید داده‌های متنی پیچیده:
[P380][Normal] معماری شبکه‌های مولد متخاصم  به طور خاص برای داده‌های متنی طراحی نشده است و در شبیه‌سازی داده‌های متنی که نیاز به درک زبان طبیعی دارد، محدودیت‌هایی دارد.
[P381][Normal] چالش در همگرایی:
[P382][Normal] فرایند آموزش شبکه‌های مولد متخاصم  گاهی دچار ناپایداری می‌شود و ممکن است مولد نتواند داده‌هایی باکیفیت تولید کند.
[P383][Normal] در ادامه این بخش مقایسه مدل‌های زبان بزرگ  و شبکه‌های مولد متخاصم   برای تولید داده‌های مصنوعی می‌پردازیم:
[P384][Normal] 1-تفاوت در ساختار
[P385][Normal] مدل‌های زبان بزرگ  بر معماری ترانسفورمر و پردازش زبان طبیعی تمرکز دارد و برای تولید داده‌های متنی بسیار مناسب است.
[P386][Normal] شبکه‌های مولد متخاصم  برای داده‌های غیرمتنی (تصاویر، سیگنال‌ها و غیره) طراحی شده و بر رقابت میان مولد و تفکیک‌کننده استوار است.
[P387][Normal] 2- توانایی در تولید داده‌های متنی
[P388][List Paragraph] مدل‌های زبان بزرگ: به‌دلیل تمرکز بر پردازش زبان، داده‌های متنی پیچیده و شبیه به واقعیت تولید می‌کند.
[P389][Normal] شبکه‌های مولد متخاصم: توانایی کمتری در تولید داده‌های متنی با ساختار پیچیده دارد.
[P390][Normal] 3- کاربرد در امنیت سایبری
[P391][Normal] مدل‌های زبان بزرگ   می‌تواند داده‌های مصنوعی مرتبط با حملات سایبری، پرس‌وجوهای تزریق پایگاه‌داده غیررابطه‌ای و متون مرتبط با امنیت را تولید کند.
[P392][Normal] شبکه‌های مولد متخاصم  بیشتر برای تولید داده‌های تصویری یا داده‌هایی که تحلیل بصری نیاز دارند (مانند تصاویر نقشه‌برداری بدافزارها) کاربرد دارد.
[P393][Normal] 4- سهولت پیاده‌سازی
[P394][Normal] مدل‌های زبان بزرگ  تنظیم و استفاده از مدل‌های زبان بزرگ‌ها برای تولید داده‌های متنی ساده‌تر است.
[P395][Normal] شبکه‌های مولد متخاصم  فرایند آموزش پیچیده‌تر و مستلزم تنظیمات دقیق برای رسیدن به داده‌های باکیفیت است.
[P396][Normal] 5- چالش‌های فنی
[P397][Normal] مدل‌های زبان بزرگ  نیازمند منابع محاسباتی قوی و داده‌های گسترده برای آموزش است.
[P398][Normal] شبکه‌های مولد متخاصم  مستعد مشکلاتی نظیر همگرایی ناپایدار یا تولید داده‌های بی‌کیفیت در صورت عدم تنظیم دقیق است.
[P399][Normal] مدل‌های زبان بزرگ به دلایل زیر برای تولید داده‌های مصنوعی مرتبط با حملات پایگاه‌داده غیررابطه‌ای نسبت به شبکه‌های مولد متخاصم  برتری دارند:
[P400][Normal] توانایی درک ساختار پرس‌وجوهای پایگاه‌داده:
[P401][Normal] مدل‌های زبان بزرگ‌ها می‌توانند پرس‌وجوهای پیچیده و شبه کدهای مرتبط با حملات پایگاه‌داده غیررابطه‌ای را تولید کنند.
[P402][Normal] تولید داده‌های متنی با تنوع بالا:
[P403][Normal] برخلاف شبکه‌های مولد متخاصم، مدل‌های زبان بزرگ   قادرند داده‌های متنی با ساختارها و الگوهای متنوع تولید کنند که برای امنیت سایبری حیاتی است.
[P404][Normal] سادگی در تولید داده‌های ترکیبی:
[P405][Normal] مدل‌های زبان بزرگ‌ها می‌توانند داده‌هایی ترکیبی از متن و کد تولید کنند که برای شبیه‌سازی حملات سایبری و آموزش مدل‌ها ایده‌آل است.
[P406][Normal] چالش‌ها و محدودیت‌های مدل‌های زبان بزرگ   و GAN
[P407][Normal] 1-چالش‌های مدل‌های زبان بزرگ
[P408][Normal] هزینه بالای محاسباتی برای آموزش.
[P409][Normal] نیاز به تنظیمات دقیق برای تولید داده‌های متناسب با اهداف خاص.
[P410][Normal] 2- چالش‌های GAN
[P411][Normal] ناپایداری در فرایند آموزش.
[P412][Normal] محدودیت در تولید داده‌های متنی.
[P413][Normal] مدل‌های زبان بزرگ به دلیل قابلیت درک زبان طبیعی، توانایی تولید داده‌های متنی پیچیده و انعطاف‌پذیری بالا، جایگزینی مناسب و پیشرفته برای روش‌های سنتی مانند GAN در تولید داده‌های مصنوعی هستند. در حوزه امنیت سایبری و به‌ویژه تولید داده‌های مرتبط با حملات پایگاه‌داده غیررابطه‌ای، استفاده از مدل‌های زبان بزرگ   می‌تواند بهبود قابل‌توجهی در کیفیت و تنوع داده‌ها ایجاد کند. این ویژگی‌ها باعث می‌شود که مدل‌های زبان بزرگ‌ها ابزاری ارزشمند در تحقیقات امنیت سایبری و آموزش مدل‌های یادگیری ماشینی باشند.
[P414][Heading 2] 2-4 پیشینه پژوهش
[P415][Heading 3] 2-4-1 تزریق پایگاه‌داده غیررابطه‌ای
[P416][NewParagraph] در ادامه چند پژوهش انجام شده مورد بررسی قرار میگیرند :
[P417][NewParagraph] نام مقالهSECURE-D: Framework For Detecting and Preventing Attacks in SQL and NoSQL Databases
[P418][NewParagraph] این مقاله یک چارچوب امنیتی تحت عنوان SECURE-D را معرفی می‌کند که برای شناسایی و جلوگیری از حملات به پایگاه داده‌های SQL و NoSQL طراحی شده است. این چارچوب از طریق یک پراکسی معکوس عمل می‌کند و تمامی درخواست‌های HTTP را قبل از رسیدن به سرور برنامه مورد بررسی قرار می‌دهد. این سیستم می‌تواند حملات SQL Injection و NoSQL Injection را شناسایی کند و در صورت شناسایی تهدید، از اجرای درخواست‌های مخرب جلوگیری نماید.
بررسی‌ها نشان می‌دهند که SECURE-D در برابر حملات مختلف مانند تزریق SQL (مثل Tautologies، Union Queries، Piggy-backed Queries، و Stored Procedures) و همچنین حملات NoSQL (مثل NoSQL JavaScript Injection و Cross-Origin Violations) مؤثر است.
[P420][NewParagraph] مهم‌ترین مشارکت‌های این مقاله عبارت‌اند از:
[P421][NewParagraph] ارائه یک چارچوب جدید برای محافظت هم‌زمان از پایگاه‌های داده SQL و NoSQL در برابر حملات تزریقی، که این امر در تحقیقات پیشین مورد بررسی قرار نگرفته بود.
[P422][NewParagraph] استفاده از پراکسی معکوس برای تجزیه و تحلیل درخواست‌های ورودی پیش از رسیدن به سرور، که باعث افزایش امنیت وب‌سایت‌ها در برابر تهدیدات اینترنتی می‌شود.
[P423][NewParagraph] شناسایی انواع مختلف حملات SQL و NoSQL و جلوگیری از اجرای درخواست‌های آلوده در سطح پایگاه داده.
[P424][NewParagraph] ثبت و نمایش گزارشات حملات برای مدیران امنیتی، همراه با قابلیت مسدودسازی دستی آدرس‌های IP مخرب.
[P425][NewParagraph] مقایسه با روش‌های موجود مانند SEA WAF و DNIARS، که نشان می‌دهد SECURE-D طیف وسیع‌تری از حملات را شناسایی و مسدود می‌کند.
[P426][NewParagraph] متدولوژی مقاله: محققان برای پیاده‌سازی و ارزیابی SECURE-D، سه ماژول اصلی را در معماری سیستم معرفی کرده‌اند:
[P427][NewParagraph] ماژول تجزیه‌گر
[P428][NewParagraph] درخواست‌های HTTP ورودی را تجزیه کرده و به URL، داده‌های GET و POST تبدیل می‌کند.
[P429][NewParagraph] داده‌های ورودی را از نظر وجود الگوهای مخرب بررسی می‌کند.
[P430][NewParagraph] ماژول تشخیص حمله
[P431][NewParagraph] شامل یک لیست از کلیدواژه‌های مخرب SQL و NoSQL مانند "SELECT"، "DROP"، "DELETE" برای SQL و "insertOne"، "create" برای NoSQL است.
[P432][NewParagraph] در صورت شناسایی هر یک از این کلمات کلیدی در ورودی، درخواست مسدود می‌شود.
[P433][NewParagraph] می‌تواند حملاتی مانند Tautologies، Logically Incorrect Queries، Union Queries، Piggy Backed Queries، و Stored Procedures در SQL و NoSQL Injection، NoSQL JavaScript Injection، و Cross-Origin Violations را شناسایی کند.
[P434][NewParagraph] ماژول ثبت لاگ
[P435][NewParagraph] تمامی حملات شناسایی‌شده را ثبت کرده و اطلاعاتی نظیر تعداد حملات، نوع حمله، و آدرس IP منبع حمله را نمایش می‌دهد.
[P436][NewParagraph] مدیران امنیتی می‌توانند به‌صورت دستی IPهای مشکوک را مسدود کنند.
[P437][NewParagraph] این سیستم در یک وب‌سایت آسیب‌پذیر تست شده است و نشان داده که می‌تواند به‌صورت لحظه‌ای حملات را شناسایی و متوقف کند.
[P438][NewParagraph] محدودیت‌های مقاله
[P439][NewParagraph] محدودیت در شناسایی حملات پیچیده: اگر حمله‌کننده از تکنیک‌های Obfuscation (مبهم‌سازی) برای پنهان کردن کد مخرب خود استفاده کند، ممکن است سیستم SECURE-D در شناسایی آن‌ها دچار مشکل شود.
[P440][NewParagraph] نیاز به تنظیمات دستی برای برخی از حملات: این سیستم به‌طور خودکار همه حملات را مسدود نمی‌کند و در برخی موارد نیاز به دخالت دستی مدیران امنیتی برای به‌روزرسانی لیست کلیدواژه‌های مخرب وجود دارد.
[P441][NewParagraph] عدم بررسی سایر حملات امنیتی: تمرکز این مقاله صرفاً بر روی حملات تزریقی (SQL و NoSQL) است و حملات دیگری مانند XSS (Cross-Site Scripting) یا CSRF (Cross-Site Request Forgery) را پوشش نمی‌دهد.
[P442][NewParagraph] وابستگی به معماری پراکسی معکوس: این سیستم فقط در صورتی کارایی دارد که در مسیر تمامی درخواست‌های ورودی به سرور قرار گیرد، که ممکن است در برخی از زیرساخت‌های ابری یا سیستم‌های توزیع‌شده چالش‌برانگیز باشد.
[P443][NewParagraph] نتیجه‌گیری مقاله
[P444][NewParagraph] SECURE-D یک چارچوب کارآمد برای شناسایی و جلوگیری از حملات پایگاه داده‌های SQL و NoSQL است.
[P445][NewParagraph] این سیستم درخواست‌های HTTP ورودی را پردازش کرده و حملات تزریقی را در زمان اجرا شناسایی و مسدود می‌کند.
[P446][NewParagraph] بررسی‌های عملی نشان دادند که این روش در مقایسه با روش‌های دیگر مانند SEA WAF و DNIARS عملکرد بهتری دارد و دامنه وسیع‌تری از حملات را پوشش می‌دهد.
[P447][NewParagraph] مزیت اصلی این چارچوب، ترکیب قابلیت‌های تشخیص حملات SQL و NoSQL در یک سیستم واحد است، که در روش‌های قبلی وجود نداشت.
[P448][NewParagraph] استفاده از ماژول‌های تجزیه و تحلیل، شناسایی و ثبت گزارشات باعث افزایش امنیت پایگاه داده‌های تحت وب می‌شود.
[P449][NewParagraph] مقاله(Basic NoSQL Injection Analysis and Detection on MongoDB)
[P450][NewParagraph] این مقاله به بررسی حملات تزریق NoSQL در پایگاه داده MongoDB می‌پردازد. با توجه به افزایش استفاده از پایگاه‌های داده NoSQL به دلیل ویژگی‌هایی مانند مقیاس‌پذیری بالا، انعطاف‌پذیری و دسترسی سریع به داده‌ها، این پایگاه‌ها نیز مانند SQL در معرض حملات تزریقی قرار دارند.
[P451][NewParagraph] این مطالعه به تحلیل آسیب‌پذیری‌های NoSQL و نحوه اجرای حملات تزریق در MongoDB می‌پردازد. برای مقابله با این تهدیدات، نویسندگان دو روش دفاعی را پیشنهاد می‌کنند:
[P452][NewParagraph] اعتبارسنجی ورودی کاربران
[P453][NewParagraph] استفاده از دستورات پارامتری
[P454][NewParagraph] نتایج نشان می‌دهند که MongoDB، با وجود مزایای خود، همچنان در برابر حملات تزریقی آسیب‌پذیر است و باید اقدامات امنیتی لازم برای مقابله با این تهدیدات انجام شود.
[P455][NewParagraph] مشارکت‌های کلیدی این تحقیق شامل موارد زیر است:
[P456][NewParagraph] تحلیل آسیب‌پذیری پایگاه داده‌های NoSQL در برابر حملات تزریقی، که نشان می‌دهد با وجود استفاده از JSON Queries، همچنان این پایگاه‌ها در معرض تهدید هستند.
[P457][NewParagraph] بررسی نحوه اجرای حملات تزریق در پایگاه داده MongoDB و شبیه‌سازی این حملات با استفاده از زبان‌های PHP و JavaScript.
[P458][NewParagraph] ارائه روش‌های مقابله با حملات تزریق NoSQL، شامل:
[P459][NewParagraph] محدود کردن ورودی کاربران با اعتبارسنجی مقادیر ورودی.
[P460][NewParagraph] استفاده از دستورات پارامتری به جای درج مستقیم داده‌های ورودی در دستورات پایگاه داده.
[P461][NewParagraph] ایجاد یک مدل برای تشخیص حملات تزریقی که به توسعه‌دهندگان کمک می‌کند تا آسیب‌پذیری‌های سیستم خود را شناسایی و برطرف کنند.
[P462][NewParagraph] این مقاله بر حملات تزریق NoSQL در MongoDB تمرکز دارد و روش‌های اجرای این حملات و همچنین روش‌های مقابله با آن‌ها را مورد بررسی قرار داده است.
[P463][NewParagraph] مراحل تحقیق و آزمایش:
[P464][NewParagraph] تحلیل آسیب‌پذیری‌های MongoDB:
[P465][NewParagraph] بررسی ساختار کلی پایگاه داده MongoDB و عملکرد آن.
[P466][NewParagraph] تجزیه و تحلیل نحوه اجرای حملات تزریقی در محیط NoSQL.
[P467][NewParagraph] اجرای حملات تزریقی در MongoDB:
[P468][NewParagraph] استفاده از PHP و JavaScript برای ارسال کدهای مخرب به پایگاه داده.
[P469][NewParagraph] بررسی آسیب‌پذیری‌های ورودی‌های کاربر، که ممکن است باعث اجرای کدهای مخرب شود.
[P470][NewParagraph] نمایش نمونه‌ای از یک حمله تزریق که از طریق فرم ورودی انجام شده و داده‌های غیرمجاز را از پایگاه داده استخراج می‌کند.
[P471][NewParagraph] پیشنهاد راهکارهای دفاعی:
[P472][NewParagraph] استفاده از اعتبارسنجی ورودی: جلوگیری از ورود مقادیر غیرمجاز در فیلدهای ورودی.
[P473][NewParagraph] استفاده از دستورات پارامتری: جدا کردن ورودی کاربر از دستورات پایگاه داده برای جلوگیری از اجرای کدهای مخرب.
[P474][NewParagraph] استفاده از فیلترهای خاص برای حذف کاراکترهای مخرب در درخواست‌های کاربر.
[P475][NewParagraph] با وجود ارائه راهکارهای مؤثر برای مقابله با حملات تزریقی NoSQL، این تحقیق دارای چند محدودیت است:
[P476][NewParagraph] محدود بودن مطالعه به MongoDB
[P477][NewParagraph] این مقاله تنها MongoDB را بررسی کرده و روش‌های تزریق NoSQL در سایر پایگاه‌های داده مانند Cassandra، Redis یا CouchDB بررسی نشده‌اند.
[P478][NewParagraph] عدم بررسی تکنیک‌های پیچیده‌تر تزریق NoSQL
[P479][NewParagraph] این مقاله بر حملات پایه‌ای NoSQL تمرکز دارد و روش‌های پیچیده‌تری مانند تزریق چند مرحله‌ای یا ترکیب حملات را پوشش نمی‌دهد.
[P480][NewParagraph] عدم ارائه آزمایش عملی در مقیاس وسیع:
[P481][NewParagraph] این مطالعه بر یک محیط آزمایشی کوچک انجام شده و تأثیر حملات در سیستم‌های واقعی و پیچیده سازمانی مورد بررسی قرار نگرفته است.
[P482][NewParagraph] عدم بررسی سایر تهدیدات امنیتی NoSQL
[P483][NewParagraph] مقاله تنها به حملات تزریقی تمرکز دارد و سایر تهدیدات امنیتی مانند حملات XSS، CSRF و حملات مبتنی بر رمزنگاری را پوشش نمی‌دهد.
[P484][NewParagraph] نتیجه‌گیری مقاله
[P485][NewParagraph] MongoDB و سایر پایگاه‌های داده NoSQL همچنان در معرض حملات تزریقی قرار دارند، اگرچه از SQL استفاده نمی‌کنند.
[P486][NewParagraph] روش‌های تزریق در NoSQL شباهت زیادی به SQL Injection دارد، اما به جای SQL، از JSON Query Language برای اجرا استفاده می‌شود.
[P487][NewParagraph] حملات تزریقی در NoSQL می‌توانند منجر به دسترسی غیرمجاز به اطلاعات، حذف داده‌ها و حتی تخریب کامل پایگاه داده شوند.
[P488][NewParagraph] برای افزایش امنیت، توسعه‌دهندگان باید از روش‌هایی مانند اعتبارسنجی ورودی، استفاده از دستورات پارامتری و فیلتر کردن مقادیر کاربر استفاده کنند.
[P489][NewParagraph] استفاده از یک مدل تشخیص حمله، می‌تواند به شناسایی فعالیت‌های مخرب کمک کند و امنیت پایگاه داده را افزایش دهد.
[P490][NewParagraph] مقاله NoSQL Racket: A Testing Tool for Detecting NoSQL Injection Attacks in Web Applications
[P491][NewParagraph] این مقاله یک ابزار جدید به نام NoSQL Racket را معرفی می‌کند که برای شناسایی حملات تزریق NoSQL در برنامه‌های وب طراحی شده است. حملات تزریق NoSQL به این دلیل رخ می‌دهند که برنامه‌های وب، ورودی‌های کاربر را بدون اعتبارسنجی به پرس‌وجوهای پایگاه داده وارد می‌کنند. این مسئله به مهاجمان اجازه می‌دهد که کدهای مخرب خود را به پایگاه داده ارسال کنند و از این طریق به اطلاعات حساس دسترسی پیدا کنند یا آن‌ها را تغییر دهند.
[P492][NewParagraph] ویژگی اصلی ابزار NoSQL Racket این است که ساختار کدهای پرس‌وجوی NoSQL را در دو سطح تحلیل استاتیک (در کد منبع) و تحلیل دینامیک (در زمان اجرا) بررسی و با یکدیگر مقایسه می‌کند. این ابزار روی چهار نوع پایگاه داده مختلف (MongoDB، Cassandra، CouchDB و Amazon DynamoDB) آزمایش شده و اثبات شده که توانایی شناسایی حملات تزریق NoSQL را دارد، در حالی که ابزارهای تست رایج مانند Netsparker، Vega و Skipfish در این زمینه ناکام بوده‌اند.
[P493][NewParagraph] در مقاله‌ی NoSQL Racket گزارش شده است که ابزارهای رایج آزمون نفوذ و اسکن آسیب‌پذیری مانند Netsparker، Vega و Skipfish در سناریوهای ارزیابی آن پژوهش، توانایی تشخیص تزریق NoSQL را نداشته‌اند. با این حال، در پژوهش حاضر مقایسه‌ی مستقیم روش پیشنهادی با این ابزارها انجام نشده است؛ زیرا (1) این ابزارها عمدتاً در رده‌ی DAST/اسکنرهای عمومی وب قرار می‌گیرند و رفتار آن‌ها به تنظیمات محیط، مسیرهای خزیدن (Crawling)، و سازگاری با فناوری‌های سمت سرور وابسته است، در حالی‌که روش پیشنهادی این پایان‌نامه یک رویکرد مبتنی بر یادگیری ماشین و طبقه‌بندی ورودی/درخواست است و خروجی آن بر پایه‌ی تحلیل ویژگی‌های داده و الگوهای تزریق تولید می‌شود؛ (2) بازتولید دقیق شرایط آزمون مقاله‌ی NoSQL Racket (شامل پیاده‌سازی وب‌اپلیکیشن‌های هدف، پیکربندی چهار پایگاه‌داده و سناریوهای اجرایی) برای اجرای منصفانه‌ی این ابزارها، خارج از دامنه‌ی اجرایی و منابع این پژوهش بوده است.
[P494][NewParagraph] با وجود این، به‌منظور جای‌دهی صحیح کار حاضر در ادبیات، از نتایج مقاله‌ی NoSQL Racket به‌عنوان شاهدی بر محدودیت ابزارهای اسکن رایج در تشخیص NoSQL Injection استفاده شده و روش پیشنهادی این پایان‌نامه به‌عنوان یک راهکار مکمل (نه الزاماً جایگزین مستقیم) برای افزایش قابلیت تشخیص، به‌ویژه در سطح داده/ورودی و الگوهای پرس‌وجو، معرفی می‌شود. همچنین، اجرای یک بنچمارک تجربی با Netsparker، Vega و Skipfish بر روی سناریوهای قابل بازتولید به‌عنوان پیشنهاد پژوهش آتی در نظر گرفته می‌شود.
[P495][NewParagraph] مهم‌ترین مشارکت‌های این تحقیق شامل موارد زیر است:
[P496][NewParagraph] ارائه یک ابزار جدید برای شناسایی حملات تزریق NoSQL که برخلاف ابزارهای رایج، بدون نیاز به زبان مشخص و مدل داده‌ای خاص، قادر به شناسایی حملات NoSQL در پایگاه‌های داده مختلف است.
[P497][NewParagraph] بررسی و تحلیل روش‌های مختلف تزریق NoSQL در پایگاه‌های داده MongoDB، Cassandra، CouchDB و Amazon DynamoDB.
[P498][NewParagraph] مقایسه ابزار NoSQL Racket با ابزارهای تست امنیت رایج (Netsparker، Vega و Skipfish) و نشان دادن برتری آن در تشخیص حملات تزریقی NoSQL.
[P499][NewParagraph] ارائه یک مدل ترکیبی برای شناسایی حملات NoSQL که ترکیبی از تحلیل استاتیک کد و تحلیل دینامیک اجرای پرس‌وجو را به کار می‌گیرد.
[P500][NewParagraph] اجرای آزمایش‌های عملکردی برای بررسی سرعت و کارایی NoSQL Racket در محیط‌هایی با بارگذاری‌های سنگین و کاربرهای هم‌زمان.
[P501][NewParagraph] مراحل اصلی متدولوژی تحقیق و پیاده‌سازی:
[P502][NewParagraph] تحلیل حملات تزریق NoSQL:
[P503][NewParagraph] بررسی انواع حملات تزریق NoSQL که از طریق فرم‌های ورودی، کوکی‌ها و درخواست‌های HTTP انجام می‌شوند.
[P504][NewParagraph] ارائه یک مثال عملی از نحوه‌ی تزریق NoSQL در MongoDB که به مهاجم اجازه می‌دهد بدون داشتن رمز عبور معتبر، وارد سیستم شود.
[P505][NewParagraph] طراحی و پیاده‌سازی ابزار NoSQL Racket:
[P506][NewParagraph] این ابزار از جدولی به نام "Driverstbl" استفاده می‌کند که شامل کلمات کلیدی، عملگرهای منطقی و عملگرهای رابطه‌ای NoSQL است.
[P507][NewParagraph] کدهای پرس‌وجوی NoSQL در دو حالت (تحلیل استاتیک و دینامیک) مورد بررسی قرار می‌گیرند و ساختار آن‌ها با یکدیگر مقایسه می‌شود.
[P508][NewParagraph] در صورتی که ساختار پرس‌وجو در زمان اجرا با ساختار اولیه مطابقت نداشته باشد، ابزار حمله را تشخیص داده و اجرای درخواست را متوقف می‌کند.
[P509][NewParagraph] مقایسه با سایر ابزارهای امنیتی:
[P510][NewParagraph] ابزار NoSQL Racket روی چهار پایگاه داده مختلف آزمایش شده است.
[P511][NewParagraph] ابزارهای تست امنیتی معروف Netsparker، Vega و Skipfish به کار گرفته شدند اما نتوانستند حملات NoSQL را شناسایی کنند.
[P512][NewParagraph] ابزار NoSQL Racket موفق شد حملات را در تمامی پایگاه‌های داده آزمایش‌شده تشخیص دهد.
[P513][NewParagraph] آزمایش‌های عملکردی:
[P514][NewParagraph] ابزار NoSQL Racket با استفاده از ابزار LoadComplete تحت بارگذاری سنگین قرار گرفت.
[P515][NewParagraph] نتایج نشان دادند که این ابزار می‌تواند ۵۰ کاربر هم‌زمان در هر ثانیه را مدیریت کند.
[P516][NewParagraph] میانگین زمان بارگذاری صفحات ۷۵ میلی‌ثانیه بود که نشان‌دهنده‌ی عملکرد مناسب ابزار است.
[P517][NewParagraph] با وجود اثربخشی ابزار NoSQL Racket، این تحقیق دارای برخی محدودیت‌ها است:
[P518][NewParagraph] عدم پوشش تمام پایگاه‌های داده NoSQL
[P519][NewParagraph] ابزار فقط روی MongoDB، Cassandra، CouchDB و Amazon DynamoDB آزمایش شده و سایر پایگاه‌های داده مانند Redis، Neo4j و Firebase بررسی نشده‌اند.
[P520][NewParagraph] محدودیت در شناسایی حملات پیچیده‌تر:
[P521][NewParagraph] ابزار فقط حملات تزریق مستقیم را شناسایی می‌کند و ممکن است در برابر تزریقات پیشرفته‌تر مانند حملات چندمرحله‌ای (Multi-step Injection) یا ترکیبی با XSS و CSRF دچار مشکل شود.
[P522][NewParagraph] وابستگی به تنظیمات اولیه:
[P523][NewParagraph] ابزار NoSQL Racket نیاز دارد که ابتدا جدول Driverstbl را به درستی تنظیم کند. در صورتی که یک پایگاه داده جدید معرفی شود، باید این جدول به‌روزرسانی شود.
[P524][NewParagraph] عدم بررسی سایر تهدیدات امنیتی:
[P525][NewParagraph] مقاله تنها به حملات تزریق NoSQL پرداخته و سایر حملات امنیتی مانند سرقت نشست‌ها، XSS و حملات مبتنی بر رمزنگاری را پوشش نداده است.
[P526][NewParagraph] نتیجه‌گیری مقاله
[P527][NewParagraph] NoSQL Injection یک تهدید جدی برای امنیت پایگاه‌های داده NoSQL است و بسیاری از برنامه‌های وب در برابر این نوع حملات آسیب‌پذیر هستند.
[P528][NewParagraph] ابزارهای تست امنیت رایج مانند Netsparker، Vega و Skipfish قادر به تشخیص حملات NoSQL نیستند.
[P529][NewParagraph] ابزار NoSQL Racket می‌تواند به طور دقیق حملات تزریقی NoSQL را شناسایی کند و مانع از اجرای پرس‌وجوهای مخرب شود.
[P530][NewParagraph] این ابزار بر روی چهار پایگاه داده‌ی NoSQL مختلف آزمایش شده و نتایج نشان داده‌اند که در تمامی موارد حملات را شناسایی کرده است.
[P531][NewParagraph] آزمایش‌های عملکردی نشان دادند که این ابزار تحت بارگذاری‌های سنگین عملکرد خوبی دارد و می‌تواند در محیط‌های واقعی مورد استفاده قرار گیرد.
[P532][NewParagraph] مقاله  (Analysis on Database Security Model Against NoSQL Injection)
[P533][NewParagraph] این مقاله به بررسی حملات تزریق NoSQL و راهکارهای امنیتی برای مقابله با این تهدیدات در پایگاه‌های داده NoSQL مانند MongoDB و Cassandra می‌پردازد. با توجه به افزایش استفاده از پایگاه‌های داده NoSQL به دلیل مقیاس‌پذیری بالا، انعطاف‌پذیری و دسترسی سریع به داده‌ها، این سیستم‌ها در برابر حملات مختلف از جمله تزریق NoSQL و حملات Cross-Site Request Forgery (CSRF) آسیب‌پذیر شده‌اند.
[P534][NewParagraph] مدل امنیتی پیشنهادی در این مقاله شامل استفاده از الگوی امنیتی متمرکز بر داده‌ها (Data-Centric Security Model) است که اطلاعات را قبل از ذخیره در پایگاه داده رمزگذاری می‌کند. علاوه بر این، احراز هویت کاربران در شبکه‌های غیرقابل اعتماد از طریق پروتکل Kerberos انجام می‌شود.
[P535][NewParagraph] نکات کلیدی مقاله:
[P536][NewParagraph] بررسی حملات تزریق NoSQL و نحوه سوءاستفاده مهاجمان از آن‌ها.
[P537][NewParagraph] بررسی آسیب‌پذیری‌های MongoDB و Cassandra در برابر حملات تزریقی.
[P538][NewParagraph] معرفی پروتکل امنیتی Kerberos برای احراز هویت کاربران و افزایش امنیت پایگاه داده.
[P539][NewParagraph] بررسی روش‌های جلوگیری از حملات، از جمله اعتبارسنجی ورودی کاربران و رمزگذاری داده‌ها.
[P540][NewParagraph] آزمایش حملات تزریق NoSQL با استفاده از JavaScript و PHP.
[P541][NewParagraph] مهم‌ترین مشارکت‌های این تحقیق شامل موارد زیر است:
[P542][NewParagraph] تحلیل حملات تزریق NoSQL و ارائه الگویی برای طبقه‌بندی آسیب‌پذیری‌های امنیتی در این پایگاه‌های داده.
[P543][NewParagraph] بررسی و مقایسه امنیت MongoDB و Cassandra در برابر حملات تزریقی، از جمله تحلیل مکانیزم‌های احراز هویت و رمزگذاری داده‌ها.
[P544][NewParagraph] ارائه یک مدل امنیتی مبتنی بر داده که داده‌ها را قبل از ذخیره شدن در پایگاه داده رمزگذاری می‌کند.
[P545][NewParagraph] استفاده از پروتکل Kerberos برای احراز هویت کاربران در پایگاه داده‌های NoSQL، که می‌تواند به جلوگیری از دسترسی‌های غیرمجاز کمک کند.
[P546][NewParagraph] ارائه راهکارهای امنیتی برای مقابله با حملات تزریق NoSQL، از جمله:
[P547][NewParagraph] اعتبارسنجی ورودی کاربران
[P548][NewParagraph] استفاده از احراز هویت
[P549][NewParagraph] فعال‌سازی ثبت گزارش‌های امنیتی
[P550][NewParagraph] رمزگذاری داده‌ها قبل از ذخیره‌سازی در پایگاه داده
[P551][NewParagraph] مراحل اصلی تحقیق و پیاده‌سازی:
[P552][NewParagraph] تحلیل حملات تزریق NoSQL:
[P553][NewParagraph] بررسی نحوه عملکرد پایگاه‌های داده NoSQL مانند MongoDB و Cassandra.
[P554][NewParagraph] شناسایی نقاط ضعف امنیتی و نحوه اجرای حملات تزریق NoSQL در این سیستم‌ها.
[P555][NewParagraph] ارائه مثال‌هایی از تزریق NoSQL در محیط MongoDB و Node.js.
[P556][NewParagraph] بررسی آسیب‌پذیری‌های NoSQL در برابر حملات تزریقی:
[P557][NewParagraph] تحلیل نمونه‌هایی از حملات تزریق در MongoDB که در آن‌ها از کوئری‌های مخرب استفاده شده است.
[P558][NewParagraph] بررسی تأثیر حملات تزریقی در Cassandra و راه‌های جلوگیری از آن.
[P559][NewParagraph] ارائه راهکارهای امنیتی برای مقابله با این حملات:
[P560][NewParagraph] معرفی پروتکل Kerberos برای احراز هویت و جلوگیری از دسترسی غیرمجاز.
[P561][NewParagraph] بررسی روش‌های رمزگذاری داده‌ها قبل از ذخیره در پایگاه داده.
[P562][NewParagraph] بررسی روش‌های جلوگیری از اجرای کوئری‌های مخرب در پایگاه داده.
[P563][NewParagraph] مقایسه امنیت MongoDB و Cassandra:
[P564][NewParagraph] بررسی مکانیزم‌های امنیتی هر دو پایگاه داده.
[P565][NewParagraph] مقایسه وضعیت احراز هویت، رمزگذاری و محافظت در برابر حملات تزریقی در MongoDB و Cassandra.
[P566][NewParagraph] ارائه یک مدل امنیتی ترکیبی:
[P567][NewParagraph] استفاده از Kerberos برای احراز هویت و مدیریت نشست‌های کاربری.
[P568][NewParagraph] رمزگذاری داده‌ها قبل از ذخیره‌سازی برای جلوگیری از حملات تزریقی.
[P569][NewParagraph] استفاده از ثبت گزارش‌های امنیتی (Auditing) برای پایش فعالیت‌های کاربران.
[P570][NewParagraph] با وجود ارائه راهکارهای امنیتی مؤثر، این تحقیق دارای برخی محدودیت‌ها است:
[P571][NewParagraph] تمرکز بر MongoDB و Cassandra
[P572][NewParagraph] این مطالعه فقط دو پایگاه داده NoSQL را بررسی کرده و سایر پایگاه‌های داده مانند CouchDB، Firebase و Redis پوشش داده نشده‌اند.
[P573][NewParagraph] عدم بررسی حملات ترکیبی
[P574][NewParagraph] تحقیق تنها به حملات تزریق NoSQL پرداخته و سایر تهدیدات مانند XSS، CSRF و حملات مهندسی اجتماعی بررسی نشده‌اند.
[P575][NewParagraph] وابستگی به Kerberos
[P576][NewParagraph] پیشنهاد اصلی مقاله استفاده از Kerberos برای احراز هویت کاربران است، اما این روش در برخی سیستم‌ها به دلیل پیچیدگی پیاده‌سازی دشواری‌هایی دارد.
[P577][NewParagraph] عدم آزمایش در محیط‌های واقعی و بزرگ:
[P578][NewParagraph] آزمایش‌های امنیتی انجام‌شده در یک محیط آزمایشی کوچک صورت گرفته‌اند و تأثیر روش‌های پیشنهادی در سیستم‌های مقیاس‌پذیر سازمانی بررسی نشده است.
[P579][NewParagraph] نتیجه‌گیری مقاله
[P580][NewParagraph] حملات تزریق NoSQL یک تهدید جدی برای امنیت پایگاه‌های داده NoSQL هستند، زیرا این سیستم‌ها به دلیل نداشتن ساختار ثابت، در برابر کوئری‌های مخرب آسیب‌پذیرتر هستند.
[P581][NewParagraph] MongoDB و Cassandra به دلیل انعطاف‌پذیری بالا، در برابر حملات تزریقی آسیب‌پذیر هستند.
[P582][NewParagraph] پروتکل Kerberos یک راهکار مؤثر برای احراز هویت کاربران و جلوگیری از دسترسی غیرمجاز به پایگاه داده است.
[P583][NewParagraph] رمزگذاری داده‌ها قبل از ذخیره در پایگاه داده، یک لایه امنیتی اضافی ایجاد می‌کند و مانع از افشای اطلاعات حساس در صورت وقوع حملات می‌شود.
[P584][NewParagraph] فعال‌سازی ثبت گزارش‌های امنیتی (Auditing) می‌تواند به شناسایی حملات و فعالیت‌های مخرب کمک کند.
[P585][NewParagraph] پایگاه‌های داده NoSQL نیاز به راهکارهای امنیتی قوی‌تری دارند تا بتوانند در برابر حملات پیچیده‌ای مانند تزریق NoSQL مقاومت کنند.
[P596][Normal] شبکه متخاصم مولد متشکل از مولدها و تمايز کنندگاني است که عليه يکديگر بازي مي‌کنند. داده‌هاي ورودي با نمونه‌گيري تصادفي در فضاي پنهان به‌دست‌آمده و به شبکه مولد منتقل مي‌شود. شبکه مولد، يک رويکرد مبتني بر سنتز شبکه، نمونه‌هاي متنوع‌تري را در مقايسه با تكنيك‌هاي سنتي افزايش داده توليد مي‌کند، اگرچه فرايند آن پيچيده‌تر است [12].
[P597][Normal] اما مجموعه‌داده‌ها با برچسب‌هاي دسته‌بندي خاص به‌سختي به دست مي‌آيند، در اين مقاله بر تقويت داده‌ها براي يادگيري نمايش ويژگي‌هاي مشابه از داده‌هاي اصلي براي بهبود دقت مدل‌هاي طبقه‌بندي تمرکز كرده و شبکه‌هاي متخاصم مولد کانولوشني عميق همراه با الگوريتم‌هاي ژن‌شناختي در زمينه حملات آسيب‌پذيري وب باهدف حل مشکل تعداد ناکافي نمونه‌هاي تزريق پرس‏وجو  اعمال شده است. همچنين انتظار مي‌رود اين روش براي توليد نمونه براي انواع ديگر حملات آسيب‌پذيري نيز اعمال شود .[12]
[P598][Normal] همچنين در تحقيق آقاي لودانگ‏ژو و همكاران، با دانش به اينكه، انتخاب مجموعه‏داده نمونه، عامل تعيين‌کننده‌اي است و پاسخ به سؤال: آيا الگوريتم‌هاي هوش مصنوعي مي‌توانند در آن به نتايج خوبي دست يابند؟ به سراغ توليد مجموعه‏داده تزريق با مدل مبتني بر GAN اقدام شد [12].
[P599][Normal] در اين مقاله، نمونه‌هاي حمله توسط مجموعه‌داده‌هاي BATADAL و مجموعه‌داده‌هاي تجاري يک انبار نفت توليد مي‌شوند و داده‌ها از طريق الگوريتم 100 برابر گسترش مي‌يابند [13].
[P600][Normal] در تحقيق آقاي ون‏ژو و محققين ديگر، مسئله کمبود داده‌هاي تجاري در سامانه واپايش صنعتي موردمطالعه قرار گرفت و الگوريتم توليد نمونه حمله ارائه شده، ابتدا، نتايج گروه‌بندي همبستگي به‌وسيله توزيع وزن و عضويت به دست مي‌آيد و سپس نتايج گروه‌بندي ارتباط قوي براي حمله به‌دست‌آوردن نمونه‌هاي حمله مورد حمله قرار مي‌گيرد. در نهايت، از GAN براي گسترش نمونه استفاده مي‌شود. اين مقاله از مجموعه‌داده‌هاي باز و يک مجموعه‌داده از نفتکش ساختمان نمونه‌هاي حمله، درجه تطابق و سازگاري را توليد مي‌کند [13].
[P601][Normal] توليد مجموعه‌داده مبتني بر GAN
[P602][Normal] آقاي رامشوار و ساير محققين در سال 2023، اذعان داشتند كه در خصوص پایگاه‌داده رابطه‌ای i كارهاي بسياري انجام شده است. اما آنچه در اين پژوهش به طور ويژه موردبحث است حملات تزريق پایگاه‌داده غیررابطه‌ای است كه مقاله فوق به توليد 400 نمونه داده آن هم صرفاً براي MongoDB پرداخته است. ازاين‌رو يک مجموعه‌داده جامع شامل 400 دستور تزريق پایگاه‌داده غیررابطه‌ای جمع‌آوري‌شده است. اين دستورات به دودسته تقسيم مي‌شوند: 221 فرمان مخرب و 179 فرمان خوش‌خيم. مجموعه‌داده به‌دقت با ترکيب دستورات نوشته شده به‌صورت دستي و دستورات به‌دست‌آمده از طريق وب از منابع معتبر مانند GitHub و ساير وبگاه‌هاي مشخص شده که در بخش منابع اين مقاله توضيح داده شده است، تنظيم شده است. مجموعه‌داده‌هاي جمع‌آوري‌شده به‌عنوان منبعي ارزشمند براي مطالعه و تحليل آسيب‌پذيري‌هاي تزريق پایگاه‌داده غیررابطه‌ای، ارائه بينش‌هايي در مورد تهديدات امنيتي بالقوه و کمک به توسعه سازوکارهاي حفاظتي قوي در برابر چندين حمله عمل مي‌کند. مجموعه‌داده شامل ترکيبي از دستورات پيچيده و ساده است که هنوز براي يادگيري ماشيني و تجزيه‌وتحليل داده‌ها، به‌ويژه براي علاقه‌مندان به امنيت، مناسب است [10].
[P603][Normal] توليد مجموعه‌داده براي حملات تزريق پایگاه‌داده غیررابطه‌ای
[P604][Normal] آقاي امين اقباليان و همكاران در سال 1401 در پژوهشي به نام توليد مجموعه‌داده استاندارد جهت تشخيص آسيب‌پذيري‌هايي منشأ پایگاه‌داده رابطه‌ای I براي استفاده در راهكارهاي مبتني بر يادگيري ماشيني مجموعه‌دادة براي اين منظور توليد كردند. اين مقاله براي نيل به اين منظور رفتار يك هكر واقعي و اطلاعاتي كه يك هكر جمع‏آوري می‌کند ملاك عمل براي توليد اين مجموعه‏داده قرار گرفته است. پس از ارزيابي، ميزان دقت كلي راهكار پيشنهادي توليد اين مجموعه‏داده براي تشخيص آسيب‏پذيري برنامه تحت آزمون %٩٨ درصد است.
[P605][Normal] توليد مجموعه‌داده براي پایگاه‌داده رابطه‌ای
[P606][Normal] مجموعه‌داده‌هاي بزرگ حاوي مواد خام براي درک دنياي اطراف ما هستند. تا کنون، محاسبات یادگیری ماشین در مقياس بزرگ در ديتاسنترهاي بزرگ حاوي انبوهي از GPUها که در اصل براي تسريع گرافيک طراحي شده بودند، انجام شده است. ما در حال گذار به عصري هستيم که در آن ديتاسنترها پر از رايانه‌هايي مي‌شوند که صرفاً براي محاسبات یادگیری ماشین طراحي شده‌اند. آن‏ها نه‌تنها از توليدکنندگان GPU، بلکه از استارتاپ‌ها، از خطوط توليد جديد عرضه‌کنندگان ريزپردازنده‌هاي سنتي، و از شرکت‌هاي اينترنتي معتبرتر که قبلاً پردازنده‌هاي خود را ساخته بودند، ارائه مي‌شوند.
[P607][Normal] منابع محاسباتي مورداستفاده براي تجزيه‌وتحليل آن‏ها.
[P608][Normal] در مجموعه‌داده‌هاي موجود
[P609][Normal] آقاي يانگ در سال 2019 به يك انقلاب در حوزه رايانه اشاره دارند كه با مجموعه‏داده ImageNet رخ داد، براي اين تعريف جهت‏گيري‏هايي نيز تعريف كرده‏اند كه انقلاب فعلي یادگیری ماشین به دو نوع مقياس نياز دارد:
[P610][Normal] تأثیر توليد مجموعه‌داده‏ها
[P611][Normal] در حوزه حملات تزريق پایگاه‌داده غیررابطه‌ای نيز مي‏توان به تلاش آقاي لاندايت و همكاران در سال 2024 اشاره داشت، در اين مقاله، نتايج يک بررسي عميق از خطرات مربوط به تزريق در پايگاه‌داده گراف Neo4j و اکوسيستم گسترده‌تر آن را ارائه شده كه بر اساس دو معيار تقسيم شده است. اول، بررسي اجراي توزيع شده پرس‌وجوهاي عاملي، از اتصال‌دهنده‌هاي زبان ويژه كاربران، تا ارتباطات (پروتکل Bolt) و اجرا در Neo4j (در طرح‌هاي پرس‌وجو)، و دوم شناسايي مشکلات تزريق باقيمانده در مواردي که پرس‌وجوهاي ثابت و عاملي شده کافي نيستند. اين مطالعه شامل بررسي جريان داده‌هاي کد محور با پايه کد Neo4j است و با مجموعه آزمايشي موارد آزمون تزريق تکميل مي‌شود.
[P612][Normal] آقاي داس و همكاران در سال 2019 نيز در خصوص آسيب‌پذيري از تزريق پرس‌وجو كار كردند، آن‏ها بر اين باور هستند كه هر زمان که برنامه وب دستورات پایگاه‌داده رابطه‌ای  پويا را اجرا مي‌کند ممکن است تحت حمله تزريق پرس‏وجو قرار گيرد. براي ارزيابي شيوه‌هاي موجود تشخيص آن، ما دو سناريو امنيتي مختلف را براي احراز هويت برنامه‌هاي وب در نظر مي‌گيريم که پرس‌وجوي پایگاه‌داده رابطه‌ای  پويا را با داده‌هاي ورودي کاربر ايجاد مي‌کند. براين‌اساس، دو مجموعه‌داده مختلف را با درنظرگرفتن تمام آسيب‌پذيري‌هاي احتمالي در فواصل زماني اجرا توليد نموده. رويکرد پيشنهادي مبتني بر فاصله ويرايش براي طبقه‌بندي يک پرس‌وجوي پایگاه‌داده رابطه‌ای  پويا به‌عنوان عادي يا مخرب با استفاده از نمايه وب آماده‌شده با پرس‌وجوهاي پایگاه‌داده رابطه‌ای  پويا در طول مرحله آموزش ارائه مي‌شود. مجموعه‌داده را با استفاده از رويکرد پيشنهادي و برخي از رويکردهاي طبقه‌بندي نظارت شده معروف، ارزيابي نموده كه در نتيجه روش آن‏ها در تشخيص حمله تزريق پرس‏وجو تحت هر دو سناريو امنيت احراز هويت مؤثرتر است .
[P613][Normal] در پايان‌نامه آقاي رومياني در سال  1402 با استفاده از مدل‏هاي يادگيري ماشين در خصوص نحوه پيشگيري از حملات تزريق راه‌حل‌هايي ارائه شده است. در جلسات دفاع نيز نسبت به کم‌بودن حجم مجموعه‌داده‏ و دشواري زيادي كه ايشان براي به‌دست‌آوردن مجموعه‏داده داشتند، اشاره شد .
[P614][Normal] تشخيص حملات تزريق پایگاه‌داده غیررابطه‌ای
[P615][Normal] با بررسي در مطالعات انجام شده متناسب با اين پژوهش به دسته‌بندي از مقالات اصلي خواهيم رسيد:
[P616][Heading 2] 1-4 سابقه تحقيقات و مطالعات انجام‌گرفته
[P617][Normal] [منتقل‌شده از فصل ۱]
[P619][Caption] جدول 2- 2: مقایسه مقالات
[P623][Caption] جدول 2- 3: مقایسه مقالات  از دیدگاه محتلف
[P625][Heading 3] 2-4-2 رویکرد یادگیری ماشین
[P626][Normal] شناسایی و پیشگیری از تزریق پایگاه‌داده غیررابطه‌ای با رویکرد یادگیری ماشین
[P627][Normal] یک مدل یادگیری ماشین برای شناسایی تزریق پایگاه‌داده غیررابطه‌ای با استفاده از یادگیری نظارت شده مبتنی بر ویژگی‌ها توسعه داده شد.
[P628][Normal] در این روش، آن‌ها مجموعه داده‌ای از پرس‌وجوهای سالم  و مخرب  مربوط به MongoDB ایجاد کردند، زیرا مجموعه داده‌ای برچسب‌گذاری شده برای تزریق پایگاه‌داده غیررابطه‌ای موجود نبود. آن‌ها از منابع مختلفی مانند OWASP، راهنمای MongoDB و غیره استفاده کردند.
[P629][Normal] برای انتخاب ویژگی‌های مدل، از ابزار WEKA با روش ClassifierSubsetEval و الگوریتم‌های طبقه‌بندی مانند J48  درخت تصمیم) و IBK (k-نزدیک‌ترین همسایگی  و جستجوی گام‌به‌گام حریصانه با حذف معکوس استفاده کردند. این روش‌ها به شناسایی 10 ویژگی برتر بر اساس اطلاعات به‌دست‌آمده و همبستگی کمک کردند. این ویژگی‌های انتخاب‌شده در جدول 2-1  ذکر شده‌اند.
[P630][Normal] در مجموعه‌داده آن‌ها، انواع مختلفی از حملات مورد بررسی قرار گرفتند، از جمله:
[P631][Normal] تزریق آرایه PHP
[P632][Normal] تزریق OR در پایگاه‌داده غیررابطه‌ای
[P633][Normal] تزریق مبتنی بر جاوا اسکریپت
[P634][Normal] پرس‌وجوهای زنجیره‌ای
[P635][Caption] جدول 2- 4: ویژگی‌های انتخاب‌شده
[P638][Caption] شکل2- 2: مدل مفهومی یادگیری ماشین
[P639][Normal] با استفاده از 10 ویژگی ذکر شده در جدول 1-2 در این مطالعه، آن‌ها بر روی دسته‌بندی دودویی کار کردند که شامل دو کلاس سالم  و تزریق  بود. برای این کار، از طبقه‌بندی‌کننده‌های یادگیری ماشین مانند الگوریتم مبتنی بر درخت تصمیم ID3، شبکه عصبی مصنوعی با پس‌انتشار خطا، جنگل تصادفی، AdaBoost، نزدیک‌ترین همسایه k، ماشین‌های بردار پشتیبان  و XGBoost استفاده کردند.
[P640][Normal] آن‌ها از اعتبارسنجی متقابل 10 قسمتی برای ارزیابی عملکرد طبقه‌بندی‌کننده‌ها استفاده کردند [25]. سپس از یک ابزار تولید تزریق پایگاه‌داده غیررابطه‌ای به نام پایگاه‌داده غیررابطه‌ای Map برای ایجاد مجموعه‌داده تست استفاده کردند [26].
[P641][Normal] پایگاه‌داده غیررابطه‌ای Map برای تولید مجموعه‌داده اصلی آن‌ها استفاده نشده بود. این مجموعه‌داده تست پر از تزریق پایگاه‌داده غیررابطه‌ای بود و آن‌ها مدل خود را با این مجموعه‌داده آزمایش کردند. روش آن‌ها در مقایسه باSqreen  عملکرد بهتری داشت و نرخ شناسایی به طور متوسط 36.25٪ بیشتر از Sqreen بود.
[P642][Heading 3] 2-4-3  رویکرد غیر یادگیری ماشین
[P643][Normal] برخی از روش‌های غیر یادگیری ماشین برای شناسایی و پیشگیری از حملات تزریق پایگاه‌داده غیررابطه‌ای عبارت‌اند از:
[P644][List Paragraph] خودکارساز: در این رویکرد، یک مدل شناسایی مبتنی بر خودکارساز  برای تزریق پایگاه‌داده غیررابطه‌ای ایجاد می‌شود . این مدل عمدتاً بر روی حملات تزریق زمان‌بندی‌شده و کور متمرکز است.
[P645][Normal] در تزریق مبتنی بر زمان، هکر تلاش می‌کند یک تابع جاوا اسکریپت را همراه با یک نشانه معتبر پایگاه‌داده غیررابطه‌ای اضافه کند. با این کار، مهاجم پایگاه‌داده را در حالت تعلیق قرار می‌دهد. برای مثال، پرس‌وجوی زیر، پایگاه‌داده MongoDB را برای 5 ثانیه در حالت تعلیق قرار می‌دهد اگر ورودی آن "John" باشد:
[P647][Normal] John’where: ‘function(){ sleep(5000); return this.name ==\John’" }
[P649][Normal] این رویکرد زمان و هزینه تولید داده‌های مصنوعی را به طور قابل‌توجهی کاهش داده و نیاز به داده‌های واقعی گسترده را به حداقل می‌رساند.
[P650][NewParagraph] تسهیل فرایند تولید داده‌ها:
[P651][NewParagraph] استفاده از داده‌های مصنوعی تولیدشده با مدل‌های زبان بزرگ، موجب بهبود فرایند آموزش مدل‌های یادگیری ماشینی و افزایش دقت آن‌ها در تشخیص حملات تزریق پایگاه‌داده غیررابطه‌ای می‌شود.
[P652][NewParagraph] افزایش دقت مدل‌های یادگیری ماشینی:
[P653][NewParagraph] مدل‌های زبان بزرگ‌داده‌هایی تولید می‌کنند که شباهت زیادی به داده‌های واقعی دارند و می‌توانند برای شبیه‌سازی حملات استفاده شوند.
[P654][NewParagraph] تولید داده‌های مصنوعی متناسب با حملات پایگاه‌داده غیررابطه‌ای:
[P655][NewParagraph] دستاوردهای کاربردی
[P656][NewParagraph] پشتیبانی بهتر از تولید داده‌های خاص نظیر پرس‌وجوهای پایگاه‌داده.
[P657][NewParagraph] انعطاف‌پذیری بالا در شبیه‌سازی سناریوهای پیچیده.
[P658][NewParagraph] کاهش پیچیدگی‌های پیاده‌سازی و تنظیم.
[P659][NewParagraph] تولید داده‌های متنی و ساختاریافته بادقت و کیفیت بالا.
[P660][NewParagraph] مزایای استفاده از مدل‌های زبان بزرگ   در برابر  شبکه‌های مولد متخاصم
[P661][NewParagraph] داده‌های تولیدشده به‌عنوان بخشی از مجموعه‌داده نهایی برای آموزش مدل‌های یادگیری ماشینی استفاده می‌شوند.
[P662][NewParagraph] استفاده از داده‌های تولیدشده در مدل‌های یادگیری ماشینی:
[P663][NewParagraph] داده‌های تولیدشده با استفاده از معیارهای مختلف نظیر شباهت به داده‌های واقعی، تنوع، و پوشش ویژگی‌های مهم ارزیابی می‌شوند.
[P664][NewParagraph] ارزیابی داده‌های تولیدشده:
[P665][NewParagraph] مدل مدل‌های زبان بزرگ با استفاده از داده‌های اولیه و برچسب‌گذاری شده، برای تولید داده‌هایی متناسب با سناریوهای حملات تزریق پایگاه‌داده غیررابطه‌ای آموزش داده می‌شود.
[P666][NewParagraph] آموزش و تنظیم مدل مدل‌های زبان بزرگ:
[P667][NewParagraph] ابتدا مجموعه ویژگی‌های مرتبط با حملات تزریق پایگاه‌داده غیررابطه‌ای، نظیر نوع پایگاه‌داده، نوع پرس‌وجو و رفتار مخرب، شناسایی و تعریف می‌شوند.
[P668][NewParagraph] بررسی و تعریف ویژگی‌های موردنیاز:
[P669][NewParagraph] در این پژوهش از مدل‌های زبان بزرگ   برای تولید داده‌های مصنوعی استفاده شده است. فرایند تولید داده‌ها شامل مراحل زیر است:
[P670][NewParagraph] رویکرد پیشنهادی برای تولید داده‌ها
[P672][NewParagraph] مهندسی ویژگی دستی و هدفمند نقش تعیین‌کننده‌تری نسبت به تقویت داده در بهبود عملکرد مدل‌ها داشت
[P673][NewParagraph] اختلاف ناچیز دیتاست‌های مصنوعی تولیدشده با دیتاست اولیه نشان می‌دهد که این داده‌های مصنوعی می‌توانند در آینده برای کاربردهای یادگیری عمیق (Deep Learning) مورد استفاده قرار گیرند
[P674][NewParagraph] دیتاست اولیه با مهندسی دقیق ویژگی‌ها از کیفیت مناسبی برخوردار است
[P675][NewParagraph] نتایج نشان داد که:
[P676][NewParagraph] سپس رویکرد به سمت مهندسی خودکار ویژگی‌ها تغییر کرد و مجدداً مدل‌های مختلف ارزیابی شدند. نتایج نشان داد که دیتاست اولیه صرفاً با مهندسی ویژگی‌های دستی به نتایج بهتری دست یافت. تولید دیتاست با روش‌های مختلف نشان داد که این روش‌ها نتوانستند دیتاست بهتری نسبت به دیتاست اولیه ارائه دهند.
[P677][NewParagraph] در مرحله بعد، مهندسی ویژگی انجام شد تا ویژگی‌های مناسب‌تری برای حملات NoSQL استخراج گردد. پس از این مرحله، تلاش شد با تقویت داده (Augmentation) و تولید نمونه‌های مصنوعی، عملکرد مدل‌ها بهبود یابد؛ اما نتایج قابل‌توجهی حاصل نشد.
[P678][NewParagraph] این پژوهش با بهره‌گیری از ویژگی‌های استخراج‌شده توسط رومیانی در زمینه حملات تزریق SQL آغاز شد. هدف اولیه، بررسی کارآمدی این ویژگی‌ها برای تشخیص حملات تزریق پایگاه‌داده غیررابطه‌ای (NoSQL) نظیر MongoDB بود. نتایج اولیه نشان داد که مدل‌های مبتنی بر این ویژگی‌ها برای پایگاه‌داده‌های غیررابطه‌ای ناکارآمد هستند.
[P679][NewParagraph] با پیشرفت فناوری هوش مصنوعی و یادگیری ماشین، استفاده از این فناوری‌ها برای شناسایی حملات تزریقی در پایگاه‌های داده به طور چشمگیری افزایش یافته است. یکی از چالش‌های اساسی در این حوزه، فراهم‌سازی مجموعه‌داده‌های کافی و مناسب برای آموزش و ارزیابی مدل‌های یادگیری ماشینی است.
[P680][Heading 3] 1-2-5 بررسي و تشريح مدل
[P681][Normal] [منتقل‌شده از فصل ۱]
[P682][Normal] در تزریق کور مبتنی بر بولی (Blind Based Boolean Injection)، مهاجمان از قابلیت‌های MongoDB استفاده می‌کنند تا به لیستی از مجموعه‌ها (Collections)، تعداد مجموعه‌ها و اطلاعات مشابه دسترسی پیدا کنند.
[P683][Normal] return (db.getCollectionNames().length == 1);
[P684][Normal] return(tojsononeline (db.collectionname.find() [0]).length == 1);
[P685][Normal] return(db.getCollectionNames() [0] [0] == ‘a’);
[P687][Normal] برای شناسایی و پیشگیری از تزریق پایگاه‌داده غیررابطه‌ای، ابتدا نقاطی در کد منبع که از آن‌ها فراخوانی پایگاه‌داده انجام می‌شود، شناسایی می‌کنند. به طور معمول، در MongoDB این نقاط شامل توابع find()، insert()، remove() و update() هستند. سپس برای پرس‌وجوهای معتبر یا ایمن که می‌توانند از این نقاط حساس (Hotspots) تولید شوند، مدل‌های NFA  ماشین‌های حالت محدود غیرقطعی) ایجاد می‌کنند و از کتابخانه JSA (تحلیلگر رشته جاوا  برای این کار استفاده می‌کنند.
[P689][Caption] شکل2- 3: نمونه کوئری در منگو دیبی
[P691][Caption] شکل2- 4: مدل نمونه برای ورودی کاربر مورد نظر حمله
[P692][Normal] سپس آن‌ها پرس‌وجوهای دینامیکی را هنگام دریافت ورودی از کاربر ایجاد می‌کنند. اگر این پرس‌وجوها با مدل‌های NFA  ازپیش‌ساخته‌شده مطابقت داشته باشند، پرس‌وجو به‌عنوان معتبر یا ایمن برای سیستم آن‌ها شناخته می‌شود. تنها پرس‌وجوهای معتبر مجاز هستند به پایگاه‌داده ارسال شوند. در شکل 5 می‌توانیم ببینیم که یک ورودی نامعتبر ارسال شده است. اگر شکل 4 و شکل 5 را مقایسه کنیم، متوجه خواهیم شد که مدل‌ها مطابقت ندارند. بنابراین، پرس‌وجوی شکل 4 اجازه ارسال به پایگاه‌داده را نخواهد داشت. به این ترتیب، راه‌حل آن‌ها برای شناسایی و پیشگیری از تزریق پایگاه‌داده غیررابطه‌ای مبتنی بر خودکارساز  کار می‌کند.
[P693][List Paragraph] اعتبارسنجی ورودی کاربر: توسعه‌دهندگان در هنگام ساخت سیستم برای شناسایی و پیشگیری از حملات تزریق پایگاه‌داده رابطه‌ای، اقدامات احتیاطی مختلفی انجام می‌دهند. به‌عنوان‌مثال، در MongoDB می‌توان با افزودن کد زیر، اندازه فیلدهای ورودی را محدود کرد :
[P694][Normal] این کد تنها اعداد را می‌پذیرد. نمادها، فاصله‌ها یا برخی کاراکترهای خاص دیگر نیز بررسی و فیلتر می‌شوند تا از تزریق کد مخرب جلوگیری شود.
[P695][List Paragraph] پارامتری‌سازی: متغیرهای ورودی کاربر نباید مستقیماً در عبارت شرطی درج شوند و باید فیلتر شوند. در پارامتری‌سازی، از دستورات پارامتری برای ارسال متغیرهای ورودی استفاده می‌شود. به‌جای درج مستقیم متغیرهای ورودی کاربر در عبارت شرطی، از پارامترها استفاده می‌شود. کد مربوطه در زیر نشان‌داده‌شده است:
[P696][Normal] if(is numeric(✩usearchtwo)=="true"){} else
[P697][Normal] echo "Incorrect.";
[P698][Normal] این قطعه کد بررسی می‌کند که آیا پرس‌وجو حاوی عدد است و در صورت وجود، مقدار را می‌پذیرد .
[P699][List Paragraph] شناسایی ویژگی‌های مخرب: شناسایی ویژگی‌های مخرب برای تشخیص این است که آیا سیستم یا نرم‌افزار دارای ویژگی‌هایی است که برای امنیت خطرناک هستند یا خیر. این شناسایی بر اساس کدها و ویژگی‌های مخرب انجام می‌شود. این فرایند می‌تواند به توسعه‌دهندگان کمک کند تا سطح ایمنی پروژه‌های خود را ارزیابی کنند. هرچه عدد سطح ایمنی بالاتر باشد، پایگاه‌داده غیررابطه‌ای امن‌تر است.
[P701][Caption] شکل2- 5: فلوچارت کد جاوا اسکریپت برای محدود کردن ورودی
[P703][Heading 1] فصل سوم روش پیشنهادی
[P731][NewParagraph] این فصل به معرفی و تشریح روش پیشنهادی پژوهش می‌پردازد که هدف آن ارائه راهکاری جامع برای تشخیص حملات تزریق پایگاه‌داده غیررابطه‌ای است. در این روش، از مدل‌های زبان بزرگ   برای تولید داده‌های مصنوعی باکیفیت و تنوع بالا استفاده می‌شود که می‌تواند محدودیت‌های موجود در دسترسی به مجموعه‌داده‌های واقعی را کاهش دهد. داده‌های تولیدشده در ادامه برای آموزش مدل‌های یادگیری ماشینی مانند رگرسیون خطی، درخت تصادفی، و XGBoost مورداستفاده قرار می‌گیرند. انتخاب این مدل‌ها بر اساس ویژگی‌های آن‌ها در شناسایی الگوهای پیچیده و قابلیت ترکیب در یک سیستم یادگیری گروهی انجام شده است.
[P732][NewParagraph] علاوه بر این، روش پیشنهادی شامل تنظیم دقیق پارامترهای مدل‌ها و بهینه‌سازی آن‌ها برای افزایش دقت و کاهش نرخ خطا است. معماری کلی سیستم پیشنهادی و مراحل مختلف پیاده‌سازی، از تولید داده‌های مصنوعی تا ارزیابی مدل‌های یادگیری ماشینی، در این فصل تشریح می‌شود. همچنین، چالش‌های مرتبط با اجرای این روش، از جمله پیچیدگی تولید داده‌ها و تنظیم مدل‌ها، موردبحث قرار گرفته و راه‌حل‌های ارائه‌شده برای غلبه بر آن‌ها بررسی می‌شود.
[P733][NewParagraph] هدف این فصل، ارائه یک نمای جامع از روش پیشنهادی و گام‌های لازم برای پیاده‌سازی آن است تا بتواند به‌عنوان یک ابزار مؤثر در شناسایی حملات تزریق پایگاه‌داده غیررابطه‌ای به کار گرفته شود.
[P734][Heading 2] 3-1 معرفی و توصیف رویکرد کلی پژوهش
[P736][NewParagraph] رویکرد کلی این پژوهش برای مقابله با حملات تزریق در پایگاه‌داده‌های غیررابطه‌ای، بر یک خط‌لوله یادگیری ماشین مبتنی است که (1) از داده واقعی به‌عنوان مبنای ارزیابی و (2) از داده مصنوعی تولیدشده توسط مدل زبانی بزرگ برای افزایش تنوع سناریوها و پوشش الگوهای حمله استفاده می‌کند. در این چارچوب، پس از تعریف/استخراج ویژگی‌های ورودی، داده‌ها وارد مرحله پیش‌پردازش و سپس وارد مرحله مدل‌سازی (آموزش، اعتبارسنجی و تجمیع مدل‌ها) می‌شوند و در نهایت با معیارهای استاندارد ارزیابی و گزارش‌دهی می‌گردند.
[P737][NewParagraph] اهداف اصلی پژوهش
[P738][NewParagraph] اهداف این پژوهش در چهار محور زیر خلاصه می‌شود:
[P739][NewParagraph] شناسایی حملات تزریق NoSQL با یادگیری ماشین: طراحی و ارزیابی مدل‌های طبقه‌بندی دودویی برای تشخیص  حمله/غیرحمله.
[P740][NewParagraph] رفع کمبود و محدودیت داده با تولید داده مصنوعی: تولید نمونه‌های مصنوعی با کیفیت و تنوع بالا برای تقویت یادگیری مدل‌ها و کاهش حساسیت به محدودیت‌های داده واقعی.
[P741][NewParagraph] بهبود دقت و تعمیم‌پذیری با سناریوهای ترکیبی داده: بررسی عملکرد مدل‌ها در حالت استفاده از داده واقعی، داده مصنوعی و ترکیب آن‌ها در سناریوهای مختلف.
[P742][NewParagraph] به‌کارگیری LLM برای گسترش فضای حملات: استفاده از مدل زبان بزرگ جهت تولید نمونه‌های جدید (با حفظ ساختار و ویژگی‌های کلیدی) برای پوشش بهتر انواع الگوهای تزریق و حالت‌های نزدیک به داده عملیاتی.
[P744][Caption] شکل 3- 1: مدل مفهومی جزییات دیتا ست ها
[P747][Caption] شکل 3- 2: مدل مفهومی جزییات پیاده سازی مدل پیشنهادی
[P748][Heading 3] 3-1-1 خط‌لوله کلی پژوهش
[P749][NewParagraph] مطابق مدل مفهومی، مسیر پردازش از ورودی تا خروجی شامل مراحل زیر است:
[P750][NewParagraph] تعریف/استخراج ویژگی‌ها (Input Features):
[P751][NewParagraph] ویژگی‌های ورودی در قالب مجموعه‌ای از متغیرهای عددی/دسته‌ای از داده‌های درخواست/پرس‌وجو (طبق طرح پژوهش) تعریف و آماده می‌شوند.
[P752][NewParagraph] بارگذاری داده واقعی:
[P753][NewParagraph] داده واقعی با حجم محدود (N=400 در سناریوهای نشان‌داده‌شده) به‌عنوان مرجع اصلی اعتبارسنجی به کار می‌رود.
[P754][NewParagraph] پیش‌پردازش و آماده‌سازی داده:
[P755][NewParagraph] پاک‌سازی، مدیریت داده‌های گمشده، کدگذاری ویژگی‌های دسته‌ای، نرمال‌سازی/ استانداردسازی و رعایت کنترل نشت اطلاعات (Train/Test Leakage) انجام می‌شود؛ به‌نحوی که هرگونه برازش تبدیل‌ها روی داده آموزشی انجام و سپس روی داده آزمون اعمال شود.
[P756][NewParagraph] مدل‌سازی و آموزش مدل‌های کاندید:
[P757][NewParagraph] مجموعه‌ای از مدل‌های طبقه‌بندی آموزش داده می‌شوند و سپس بهترین‌ها (یا بهترین تجمیع) انتخاب می‌گردند.
[P758][NewParagraph] ارزیابی و مقایسه:
[P759][NewParagraph] ارزیابی با معیارهایی نظیر Accuracy، Precision، Recall، F1 و ROC-AUC و همچنین ماتریس درهم‌ریختگی انجام می‌شود. علاوه بر این، اعتبارسنجی متقاطع با StratifiedKFold برای پایداری نتایج به کار می‌رود (تقسیم‌بندی طبقه‌بندی‌شده برای حفظ توزیع کلاس‌ها در فولدها).
[P760][NewParagraph] خروجی‌ها و گزارش نهایی:
[P761][NewParagraph] انتخاب بهترین مدل/بهترین تجمیع، تولید جداول/نمودارها، گزارش معیارها و درج خروجی‌ها در قالب فصل نتایج پایان‌نامه.
[P762][Heading 3] 3-1-2سناریوهای داده (سه شاخه اجرایی)
[P763][Normal] این پژوهش شامل طراحی و ارزیابی یک سیستم یادگیری گروهی است که از مدل‌های مختلف مانند رگرسیون لجستیک، جنگل تصادفی و XGBoost تشکیل شده است. این مدل‌ها با ترکیب قدرت یادگیری فردی خود، دقت شناسایی حملات را بهبود می‌بخشند. دستاوردهای مورد انتظار این پژوهش شامل ارائه روشی نوین برای شناسایی حملات تزریق پایگاه‌داده غیررابطه‌ای، ایجاد مجموعه‌دادگان جامع و متنوع، و بهبود دقت مدل‌های یادگیری ماشینی در محیط‌های واقعی است.
[P764][Normal] مفاهیم کلیدی این پژوهش شامل شناسایی و مقابله با حملات تزریق پایگاه‌داده غیررابطه‌ای است که از نقاط ضعف این نوع پایگاه‌ها سوءاستفاده می‌کنند. این حملات معمولاً از طریق ارسال درخواست‌های مخرب و دست‌کاری پرس‌وجوها انجام می‌گیرند. همچنین، تحلیل و طراحی مجموعه‌دادگان شامل داده‌های اولیه و داده‌های مصنوعی تولیدشده با مدل‌های زبان بزرگ، یکی از محورهای اصلی پژوهش است. در این راستا، به‌جای استفاده از شبکه‌های مولد متخاصم، از مدل‌های زبان بهره گرفته می‌شود که توانایی تولید داده‌های متنی و ساختاریافته باکیفیت بالا را دارند.
[P765][Normal] این پژوهش با هدف ارائه راهکاری جامع برای تشخیص حملات تزریق پایگاه‌داده غیررابطه‌ای طراحی شده است. برای دست‌یابی به این هدف، مجموعه‌داده‌های اولیه به‌صورت دستی تحلیل و برچسب‌گذاری می‌شوند تا کیفیت داده‌های پایه تضمین گردد. سپس از مدل‌های زبان بزرگ برای تولید داده‌های مصنوعی متنوع و واقعی‌تر استفاده می‌شود که به غنی‌سازی مجموعه‌دادگان کمک می‌کند. در مرحله بعد، تکنیک‌های مختلف یادگیری ماشینی برای ارزیابی و دسته‌بندی داده‌های موجود و مصنوعی به‌کار گرفته می‌شوند.
[P766][Heading 3] 3-1-3 مدل‌های یادگیری ماشین و منطق انتخاب
[P767][NewParagraph] در مرحله مدل‌سازی، یک سبد از مدل‌های کاندید (برای مقایسه جامع) و همچنین دو رویکرد تجمیعی استفاده می‌شود:
[P768][NewParagraph] الف) مدل‌های کاندید (Candidate Models)
[P769][NewParagraph] رگرسیون خطی
[P770][NewParagraph] درخت تصمیم
[P771][NewParagraph] Gradient Boosting
[P772][NewParagraph] نزدیکترین همسایه
[P773][NewParagraph] درخت تصادفی
[P774][NewParagraph] XGBoost
[P775][NewParagraph] LightGBM
[P776][NewParagraph] Extra Trees
[P777][NewParagraph] Support Vector Machine
[P778][NewParagraph] AdaBoost
[P779][NewParagraph] این تنوع باعث می‌شود هم مدل‌های ساده/تفسیرپذیر (مانند Logistic/Tree) و هم مدل‌های قوی در الگوهای غیرخطی (مانند خانواده Boosting و جنگل‌ها) و هم روش‌های مبتنی بر فاصله/حاشیه (KNN/SVM) پوشش داده شوند.
[P780][NewParagraph] ب) یادگیری گروهی (Ensembling)
[P781][NewParagraph] برای افزایش پایداری و کاهش خطای وابسته به یک مدل منفرد، دو نوع تجمیع استفاده می‌شود:
[P782][NewParagraph] VotingClassifier با رأی‌گیری نرم (Soft Voting) و وزن‌دهی
[P783][NewParagraph] در رأی‌گیری نرم، کلاس نهایی بر اساس بیشینه مجموع (یا مجموع وزن‌دار) احتمال‌های پیش‌بینی‌شده تعیین می‌شود؛ این روش برای ترکیب مدل‌هایی که خروجی احتمالاتی تولید می‌کنند توصیه می‌شود.
[P784][NewParagraph] StackingClassifier با stack_method='predict_proba'
[P785][NewParagraph] در Stacking، یک مدل نهایی (Meta-learner) بر پایه خروجی مدل‌های پایه آموزش می‌بیند؛ در حالت predict_proba برای طبقه‌بندی دودویی، ستون اول احتمال هر مدل حذف می‌شود تا هم‌خطی کامل رخ ندهد.
[P786][Heading 3] 3-1-4 راهبرد ارزیابی و گزارش‌دهی
[P787][NewParagraph] برای ارزیابی منصفانه و پایدار:
[P788][NewParagraph] از اعتبارسنجی متقاطع طبقه‌بندی‌شده (StratifiedKFold) جهت حفظ نسبت کلاس‌ها در هر فولد و کنترل تصادفی‌سازی استفاده می‌شود.
[P789][NewParagraph] برای هر مدل، علاوه بر گزارش معیارهای عملکرد، ماتریس درهم‌ریختگی و شاخص‌های تکمیلی ارائه می‌گردد.
[P790][NewParagraph] در نهایت، بهترین مدل منفرد یا بهترین مدل تجمیعی انتخاب و نتایج در قالب جداول/نمودارها و گزارش فصل نتایج مستندسازی می‌شود.
[P792][NewParagraph] بنابراین، رویکرد این پژوهش یک چارچوب داده‌محور و مدل‌محور است که با تعریف سناریوهای مختلف داده (واقعی/مصنوعی/ترکیبی)، اجرای مجموعه‌ای از مدل‌های کاندید و به‌کارگیری روش‌های تجمیعی (Soft Voting و Stacking)، تلاش می‌کند تشخیص حملات تزریق NoSQL را هم از نظر دقت و هم از نظر تعمیم‌پذیری تقویت کند.
[P793][Heading 2] 3-2روش جمع‌آوری داده
[P794][NewParagraph] در این بخش، فرایند تولید داده‌های مصنوعی برای حملات تزریق پایگاه‌داده غیررابطه‌ای با استفاده از مدل‌های زبان بزرگ (مدل‌های زبان بزرگ) نظیر GPT تشریح می‌شود. این فرایند شامل استخراج ویژگی‌های مهم از مجموعه‌داده اولیه و تولید داده‌های مصنوعی تصادفی و متنوع با استفاده از مدل‌های زبان بزرگ   است. در ادامه، مراحل این فرایند به طور علمی و گام‌به‌گام تشریح می‌شود.
[P796][NewParagraph] 3-3-1 استخراج ویژگی‌های کلیدی از مجموعه‌داده اولیه
[P797][NewParagraph] 1- مرحله آماده‌سازی مجموعه‌داده اولیه
[P798][NewParagraph] برای شروع تولید داده‌های مصنوعی، یک مجموعه‌داده اولیه شامل داده‌های مرتبط با پرس‌وجوهای پایگاه‌داده غیررابطه‌ای به مدل GPT ارائه شد. هدف این مرحله شناسایی ویژگی‌های کلیدی از داده‌های واقعی به‌منظور استفاده به‌عنوان مبنایی برای تولید داده‌های مصنوعی بود.
[P799][Caption] جدول 3- 2: نمونه ای از داده اولیه
[P801][NewParagraph] 2- درخواست استخراج ویژگی‌ها از مدل مدل‌های زبان بزرگ
[P802][NewParagraph] مدل GPT با استفاده از یک پرامپت مشخص، وظیفه استخراج ویژگی‌های مهم و معنادار از مجموعه‌داده اولیه را برعهده گرفت. این ویژگی‌ها شامل پارامترهایی بودند که ارتباط مستقیم با ساختار داده‌های پایگاه‌داده غیررابطه‌ای و امکان تشخیص الگوهای مخرب داشتند. نتیجه این مرحله منجر به شناسایی ویژگی‌های زیر شد:
[P803][Caption] جدول 3- 3: ویژگی های استخراج شده
[P804][NewParagraph] تحلیل ویژگی‌های استخراج‌شده: ویژگی‌های استخراج‌شده، به‌عنوان معیارهایی برای توصیف رفتار و ساختار داده‌ها به کار گرفته شدند. این ویژگی‌ها نقش کلیدی در تولید داده‌های مصنوعی داشتند، زیرا داده‌های تولیدشده باید این ویژگی‌ها را رعایت کنند تا بتوانند شباهت زیادی به داده‌های واقعی داشته باشند.
[P805][Heading 3] 3-2-1 تولید داده‌های مصنوعی با استفاده از مدل  ChatGPT (GPT-5.2)
[P806][NewParagraph] در این پژوهش، به‌منظور غلبه بر محدودیت حجم و تنوع داده‌های واقعی و افزایش پوشش سناریوهای حمله/غیرحمله، از مدل زبانی بزرگ GPT-5.2 در محیط ChatGPT برای تولید داده‌های مصنوعی ساختاریافته استفاده شد. GPT-5.2 به‌عنوان یکی از مدل‌های پیشرفته OpenAI با توانایی پردازش و تولید محتوای ساختاریافته و پشتیبانی از خروجی‌های دقیق و قابل‌کنترل انتخاب شد.
[P807][NewParagraph] الف) طراحی پرامپت برای تولید داده مصنوعی
[P808][NewParagraph] پس از استخراج ویژگی‌های کلیدی از داده واقعی، یک پرامپت هدفمند تدوین شد تا مدل GPT-5.2 بتواند نمونه‌های مصنوعی را با حفظ ساختار داده و رعایت قیود آماری/ساختاری تولید کند. اصول طراحی پرامپت با اتکا به راهنمای رسمی «Prompt engineering» و الگوهای پیشنهادشده برای «Synthetic Data Generation» تنظیم شد.
[P809][NewParagraph] اجزای اصلی پرامپت شامل موارد زیر بود:
[P810][NewParagraph] تعریف دقیق قالب خروجی (ساختار رکوردها، نوع هر ستون/فیلد، محدودیت‌ها و فرمت ثابت خروجی برای جلوگیری از تولید متن آزاد(
[P811][NewParagraph] توصیف ویژگی‌های استخراج‌شده از داده واقعی (برای نمونه: توزیع یا بازه‌های مقادیر، تعداد کلیدها، عمق تودرتویی، وجود/عدم وجود الگوهای مشخص و …)
[P812][NewParagraph] الزام به تولید نمونه‌های متنوع با حفظ قواعد ساختاری (تنوع در مقادیر در عین سازگاری با ساختار)
[P813][NewParagraph] تعیین حجم تولید (تولید تعداد موردنیاز نمونه‌های مصنوعی؛ در این پژوهش 20,000 رکورد)
[P814][NewParagraph] ب) فرآیند تولید و آماده‌سازی داده مصنوعی
[P815][NewParagraph] با اجرای پرامپت تدوین‌شده روی GPT-5.2، مجموعه‌ای از داده‌های مصنوعی تولید شد که:
[P816][NewParagraph] از نظر ساختار و قالب با داده واقعی هم‌راستا است،
[P817][NewParagraph] از نظر تنوع سناریو دامنه وسیع‌تری از حالت‌های حمله/غیرحمله را پوشش می‌دهد،
[P818][NewParagraph] و برای استفاده در مراحل آموزش/اعتبارسنجی مدل‌های یادگیری ماشین قابل بهره‌برداری است.
[P819][NewParagraph] سپس داده‌های مصنوعی تولیدشده، با توجه به سناریوی اجرایی پژوهش، به یکی از شکل‌های زیر مورد استفاده قرار گرفت:
[P820][NewParagraph] ترکیب با داده واقعی برای افزایش حجم/تنوع آموزش،
[P821][NewParagraph] یا آموزش روی مصنوعی و آزمون روی واقعی برای سنجش تعمیم‌پذیری،
[P822][NewParagraph] یا تقسیم داده مصنوعی به آموزش/آزمون برای تحلیل کیفیت داده تولیدی (مطابق سناریوهای تعریف‌شده در بخش رویکرد و دیاگرام‌ها).
[P823][NewParagraph] ج) دستاوردهای تولید داده مصنوعی با GPT-5.2
[P824][NewParagraph] فرآیند تولید داده مصنوعی با GPT-5.2 نتایج زیر را برای پژوهش به همراه داشت:
[P825][NewParagraph] افزایش تنوع و پوشش سناریوها: ایجاد نمونه‌های جدید که می‌تواند فضای حالت‌های تزریق و الگوهای غیرخطی را بهتر پوشش دهد.
[P826][NewParagraph] کاهش اثر کمبود داده واقعی: با تولید 20,000 نمونه مصنوعی، محدودیت حجم داده واقعی تا حد زیادی جبران شد و امکان آموزش/ارزیابی پایدارتر فراهم گردید.
[P827][NewParagraph] تقویت کیفیت آموزش مدل‌ها: داده متنوع‌تر معمولاً به بهبود یادگیری الگوها و کاهش حساسیت مدل به موارد خاص داده واقعی کمک می‌کند (به‌ویژه در مسائل کم‌داده).
[P828][NewParagraph] صرفه‌جویی در زمان و هزینه تولید داده: تولید داده با LLMها می‌تواند مسیر ساخت دیتاست را نسبت به جمع‌آوری و برچسب‌گذاری دستی سریع‌تر و مقرون‌به‌صرفه‌تر کند، مشروط به اعمال کنترل کیفیت.
[P830][Heading 2] 4-3 معرفی مدل‌های یادگیری ماشین و مدل‌های تجمیعی به‌کاررفته
[P831][NewParagraph] در این پژوهش، برای تشخیص دودویی حمله/غیرحمله در داده‌های مرتبط با تزریق NoSQL، مجموعه‌ای از الگوریتم‌های یادگیری ماشین شامل مدل‌های خطی، مبتنی بر فاصله، مبتنی بر درخت و روش‌های تقویتی (Boosting) به‌همراه دو رویکرد تجمیع مدل‌ها (Voting و Stacking) پیاده‌سازی و ارزیابی شده‌اند. هدف از به‌کارگیری این طیف متنوع از مدل‌ها، مقایسه عملکرد روش‌های پایه و پیشرفته و همچنین بررسی اثر تجمیع چند مدل بر بهبود دقت و پایداری تشخیص است.
[P832][Normal] رگرسیون لجستیک (رگرسیون خطی)
[P833][NewParagraph] رگرسیون لجستیک یک الگوریتم یادگیری نظارت‌شده برای مسائل طبقه‌بندی دودویی است که با استفاده از تابع سیگموئید، احتمال تعلق نمونه به کلاس مثبت (حمله) را در بازه [0,1]برآورد می‌کند. این مدل به‌عنوان یک روش پایه و تفسیرپذیر در پژوهش استفاده شده است.
در پیاده‌سازی انجام‌شده، رگرسیون لجستیک با تنظیمات penalty='l2'، مقدار منظم‌سازی C=10.0، حل‌گر liblinear و max_iter=2000 اجرا شده است تا هم پایداری همگرایی تضمین شود و هم عملکرد مناسب در طبقه‌بندی دودویی فراهم گردد.
[P834][NewParagraph] دلیل استفاده: مدل پایه برای مقایسه با سایر الگوریتم‌ها و ارائه یک معیار مرجع ساده و قابل تفسیر.
[P835][NewParagraph] درخت تصمیم (درخت تصمیم)
[P836][NewParagraph] درخت تصمیم یک مدل مبتنی بر قوانین تصمیم‌گیری است که فضای ویژگی‌ها را به‌صورت بازگشتی تقسیم می‌کند و در هر گره بر اساس معیارهایی مانند Gini بهترین تقسیم را انتخاب می‌کند.
در این پژوهش، این مدل با محدودیت عمق (max_depth=10) و تنظیم حداقل نمونه‌های تقسیم و برگ min_samples_split=5، min_samples_leaf=2 پیاده‌سازی شده است تا از بیش‌برازش شدید جلوگیری شود.
[P837][NewParagraph] دلیل استفاده: ارائه یک مدل قابل تفسیر و مقایسه عملکرد روش‌های تک‌درختی با روش‌های جنگلی و تقویتی.
[P839][NewParagraph] نزدیک‌ترین همسایه‌ها (نزدیکترین همسایه)
[P840][NewParagraph] KNN یک روش مبتنی بر شباهت است که بر اساس فاصله نمونه از همسایگان نزدیک، کلاس را تعیین می‌کند. در این پژوهش KNN با n_neighbors=3، وزن‌دهی فاصله‌ای (weights='distance') و معیار فاصله Manhattan metric='manhattan' با p=1استفاده شده است.
[P841][NewParagraph] دلیل استفاده: سنجش کارایی یک مدل مبتنی بر فاصله در تشخیص الگوهای حمله/غیرحمله، خصوصاً زمانی که مرز تصمیم غیرخطی و محلی باشد.
[P843][NewParagraph] ماشین بردار پشتیبان (Support Vector Machine)
[P844][NewParagraph] SVM با هدف یافتن مرز تصمیم بهینه بین کلاس‌ها به‌کار می‌رود و در مسائل غیرخطی می‌تواند از کرنل استفاده کند. در این پژوهش، SVM با کرنل RBF و پارامتر C=10.0 اجرا شده و گزینه probability=True فعال شده است تا امکان تولید احتمال و محاسبه معیارهایی مانند AUC و همچنین مشارکت در مدل رأی‌گیری نرم فراهم شود.
[P845][NewParagraph] دلیل استفاده: توانایی مدل‌سازی مرزهای تصمیم غیرخطی و مقایسه با مدل‌های درختی و تقویتی.
[P846][NewParagraph] جنگل تصادفی (درخت تصادفی)
[P847][NewParagraph] جنگل تصادفی یک روش یادگیری گروهی مبتنی بر Bagging است که با ساخت تعداد زیادی درخت تصمیم و ترکیب خروجی آن‌ها، پایداری و دقت را افزایش می‌دهد.
در این پژوهش، جنگل تصادفی با n_estimators=500، عمق max_depth=12، انتخاب ویژگی به روش max_features='sqrt'، و فعال‌سازی bootstrap=True اجرا شده است. همچنین گزینه oob_score=True برای برآورد خطای خارج از کیسه (Out-of-Bag) فعال شده است.
[P848][NewParagraph] دلیل استفاده: قدرت بالا در کشف روابط غیرخطی و مقاومت مناسب در برابر نویز و بیش‌برازش نسبت به درخت تصمیم منفرد.
[P850][NewParagraph] درخت‌های کاملاً تصادفی (Extra Trees)
[P851][NewParagraph] Extra Trees مشابه جنگل تصادفی است، اما در انتخاب نقاط تقسیم تصادفی‌تر عمل می‌کند و می‌تواند واریانس را کاهش دهد. در این پژوهش این مدل با تنظیمات هم‌راستا با جنگل تصادفی (n_estimators=500، max_depth=12، max_features='sqrt') اجرا شده است.
[P852][NewParagraph] دلیل استفاده: مقایسه با درخت تصادفی و بررسی اثر تصادفی‌سازی بیشتر در تقسیم‌ها بر عملکرد تشخیص.
[P853][NewParagraph] گرادیان بوستینگ (Gradient Boosting)
[P854][NewParagraph] Gradient Boosting یک روش تقویتی است که درخت‌ها را به‌صورت ترتیبی می‌سازد و هر مرحله خطای مرحله قبل را کاهش می‌دهد. در این پژوهش مدل گرادیان بوستینگ با n_estimators=300، learning_rate=0.15، subsample=0.9 و max_depth=6 پیاده‌سازی شده است. همچنین از سازوکار early stopping داخلی (n_iter_no_change=15, tol=1e-5) و validation_fraction=0.15 برای کنترل بیش‌برازش استفاده شده است.
[P855][NewParagraph] دلیل استفاده: ارائه یک مدل تقویتی کلاسیک برای مقایسه با روش‌های Boosting پیشرفته‌تر مانند XGBoost و LightGBM.
[P856][NewParagraph] آدابوست (AdaBoost)
[P857][NewParagraph] AdaBoost با تاکید بیشتر بر نمونه‌هایی که در مراحل قبل اشتباه طبقه‌بندی شده‌اند، مدل‌های ضعیف را به‌صورت ترتیبی تقویت می‌کند. در این پژوهش، AdaBoost با n_estimators=200 و learning_rate=1.2 و الگوریتم SAMME.R اجرا شده است.
[P858][NewParagraph] دلیل استفاده: بررسی توان یک روش Boosting ساده‌تر در مقایسه با Gradient Boosting و XGBoost/LightGBM.
[P859][NewParagraph] XGBoost
[P860][NewParagraph] XGBoost یک نسخه بهینه‌شده از Boosting مبتنی بر گرادیان است که با پیاده‌سازی کارآمد و منظم‌سازی، در مسائل طبقه‌بندی عملکرد بالایی دارد. در این پژوهش، XGBoost با n_estimators=400، learning_rate=0.15، max_depth=8، و پارامترهای منظم‌سازی reg_alpha=0.05 و reg_lambda=0.05 اجرا شده است. همچنین برای افزایش سرعت از tree_method='hist' استفاده شده و تابع هدف binary:logistic انتخاب شده است.
[P861][NewParagraph] دلیل استفاده: مدل پیشرفته برای تشخیص الگوهای پیچیده و غیرخطی با کنترل مناسب بیش‌برازش و سرعت اجرایی بالا.
[P862][NewParagraph] LightGBM
[P863][NewParagraph] LightGBM یک روش Boosting مبتنی بر درخت است که به‌دلیل طراحی کارآمد، برای داده‌های بزرگ و ویژگی‌های متعدد مناسب است. در این پژوهش مدل LightGBM با n_estimators=400، learning_rate=0.15، max_depth=8، num_leaves=63، و پارامترهای منظم‌سازی reg_alpha=0.05 و reg_lambda=0.05 اجرا شده است. همچنین از subsample=0.9 و colsample_bytree=0.9 برای کنترل بیش‌برازش بهره گرفته شده است.
[P864][NewParagraph] دلیل استفاده: مقایسه یک روش Boosting مدرن و سریع با XGBoost و سایر مدل‌ها در تشخیص حملات.
[P865][NewParagraph] مدل تجمیعی رأی‌گیری نرم (Soft Voting Ensemble)
[P866][NewParagraph] به‌منظور بهره‌گیری از نقاط قوت چند الگوریتم، یک مدل VotingClassifier با رأی‌گیری نرم (Soft Voting) پیاده‌سازی شده است. در این روش، به‌جای رأی‌گیری بر مبنای کلاس نهایی، میانگین وزن‌دار احتمال‌های پیش‌بینی‌شده توسط مدل‌ها محاسبه و کلاس نهایی بر اساس آن تعیین می‌شود.
در این پژوهش، اجزای مدل رأی‌گیری نرم شامل: KNN، درخت تصادفی، XGBoost، LightGBM و SVM هستند و برای ترکیب احتمال‌ها وزن‌ها به‌صورت [3, 2, 2, 2, 1] تنظیم شده است؛ به این ترتیب وزن بیشتری به KNN اختصاص یافته است.
[P867][NewParagraph] دلیل استفاده: افزایش پایداری و کاهش وابستگی به یک مدل منفرد از طریق ترکیب مدل‌های ناهمگون.
[P868][NewParagraph] مدل تجمیعی انباشته (Stacking Ensemble)
[P869][NewParagraph] در روش Stacking، چند مدل پایه (Base Learners) ابتدا آموزش داده می‌شوند و سپس خروجی‌های آن‌ها به‌عنوان ورودی به یک مدل نهایی (Meta-Learner) داده می‌شود تا تصمیم نهایی را اتخاذ کند.
[P870][NewParagraph] در این پژوهش، مدل Stacking با مدل‌های پایه KNN، درخت تصادفی، XGBoost، LightGBM و AdaBoost تعریف شده و مدل نهایی (Final Estimator) یک درخت تصادفی با n_estimators=100 و max_depth=8 است. همچنین برای تولید ورودی مدل نهایی از predict_proba استفاده شده و اعتبارسنجی داخلی Stacking با cv=3 تنظیم شده است.
[P872][NewParagraph] 3-5 ارائه جزئیات مربوط به تنظیم پارامترها
[P875][Caption] جدول 3- 1: پارامترهای رگرسیون خطی
[P877][Caption] جدول 3- 2: پارامترهای درخت تصمیم
[P879][Caption] جدول 3- 3: پارامترهای Gradient Boosting
[P881][Caption] جدول 3- 4: پارامترهای نزدیکترین همسایه
[P883][Caption] جدول 3- 5: پارامترهای درخت تصادفی
[P885][Caption] جدول 3- 6: پارامترهای XGBoost
[P887][Caption] جدول 3- 7:  پارامترهای LightGBM
[P889][Caption] جدول 3- 8:پارامترهای Extra Trees
[P891][Caption] جدول 3- 9: پارامترهای Support Vector Machine
[P893][Caption] جدول 3- 10: پارامترهای AdaBoost
[P895][NewParagraph] پارامترهای مدل‌های تجمیعی
[P896][Caption] جدول 3- 11: پارامترهای Voting Ensemble
[P898][Caption] جدول 3- 12: پارامترهای Estimators داخل Voting Ensemble
[P900][Caption] جدول 3- 13:پارامترهای Stacking Ensemble
[P902][Caption] جدول 3- 14:  پارامترهای Estimators داخل Stacking Ensemble
[P904][Heading 2] 3-6 پیاده‌سازی
[P905][Normal] سیستم پیشنهادی برای تشخیص حملات تزریق پایگاه‌داده‌های غیررابطه‌ای (NoSQL Injection) بر یک خط‌لوله یادگیری ماشین استوار است که شامل آماده‌سازی داده، ساخت سناریوهای داده واقعی/مصنوعی، آموزش و مقایسه چندین مدل کاندید، به‌کارگیری روش‌های تجمیعی (Ensemble) و در نهایت ارزیابی مبتنی بر اعتبارسنجی متقاطع طبقه‌بندی‌شده و آزمون نهایی است. همچنین، برای رفع محدودیت حجم و تنوع داده واقعی، داده‌های مصنوعی با استفاده از ChatGPT (GPT-5.2) تولید و در سناریوهای تعریف‌شده به کار گرفته شده‌اند.
[P906][Normal] در ادامه، مراحل پیاده‌سازی به‌صورت گام‌به‌گام ارائه می‌شود.
[P907][Normal] گام 1) بارگذاری داده و بررسی اولیه
[P908][Normal] ابتدا مجموعه‌داده(ها) از مسیرهای تعریف‌شده بارگذاری می‌شوند. در این مرحله، بررسی‌های مقدماتی زیر انجام می‌گیرد:
[P909][Normal] بررسی ساختار داده: تعداد رکوردها، تعداد ویژگی‌ها، نوع داده هر ستون و شناسایی ستون‌های عددی/دسته‌ای.
[P910][Normal] کنترل کیفیت اولیه: شناسایی مقادیر گمشده، مقادیر غیرمجاز و ناسازگاری‌های احتمالی در قالب داده.
[P911][Normal] بررسی توزیع برچسب‌ها: محاسبه توزیع کلاس‌ها (حمله/غیرحمله) به‌منظور تشخیص عدم‌توازن احتمالی در داده.
[P912][Normal] گام 2) تولید داده مصنوعی ChatGPT (GPT-5.2)
[P913][Normal] با توجه به محدودیت حجم و تنوع داده واقعی، در سناریوهای مشخص، داده مصنوعی با ChatGPT (GPT-5.2) تولید شد. تولید داده مصنوعی با پرامپت ساختارمند انجام گرفت تا:
[P914][Normal] قالب رکوردها، نوع متغیرها و قیود ساختاری رعایت شود؛
[P915][Normal] تنوع سناریوهای حمله/غیرحمله افزایش یابد؛
[P916][Normal] داده تولیدی با ویژگی‌های کلیدی داده واقعی هم‌راستا باقی بماند.
[P917][Normal] خروجی این مرحله، یک مجموعه‌داده مصنوعی (Synthetic) قابل استفاده در مرحله آموزش/ارزیابی است.
[P918][Normal] گام 3) پیش‌پردازش داده (Data Preprocessing)
[P919][Normal] پس از آماده شدن داده (واقعی/مصنوعی/ترکیبی)، عملیات پیش‌پردازش با تمرکز بر سازگاری داده و جلوگیری از نشت اطلاعات انجام می‌شود. مؤلفه‌های اصلی این مرحله عبارت‌اند از:
[P920][Normal] 3-1 ) مدیریت داده‌های گمشده
[P921][Normal] برای ویژگی‌های عددی، مقداردهی جایگزین به‌صورت روش‌های استاندارد (مانند میانگین/میانه) انجام می‌شود.
[P922][Normal] برای ویژگی‌های دسته‌ای، مقدار پرتکرار (Most Frequent) یا یک برچسب مشخص برای «نامشخص» لحاظ می‌شود.
[P923][Normal] 3-2) کدگذاری ویژگی‌های دسته‌ای
[P924][Normal] ویژگی‌های دسته‌ای به نمایش عددی قابل پردازش برای مدل‌های یادگیری ماشین تبدیل می‌شوند (از روش‌های رایج کدگذاری متناسب با نوع داده).
[P925][Normal] 3-3) مقیاس‌بندی/استانداردسازی
[P926][Normal] برای مدل‌هایی که نسبت به مقیاس ویژگی‌ها حساس‌اند (به‌ویژه روش‌های مبتنی بر فاصله و مدل‌های خطی)، ویژگی‌ها استانداردسازی می‌شوند. این کار باید با رعایت اصل عدم نشت اطلاعات انجام شود (برازش تنها روی داده آموزش و اعمال روی داده آزمون).
[P927][Normal] نکته روش‌شناسی: هرگونه تبدیل (Encoding/Scaling) باید روی داده آموزش برازش شود و سپس بر روی اعتبارسنجی/آزمون اعمال گردد تا برآورد عملکرد خوش‌بینانه نشود.
[P928][Normal] گام 4) تعریف سناریوهای داده برای آموزش و آزمون
[P929][Normal] به‌منظور سنجش اثر داده مصنوعی و بررسی تعمیم‌پذیری، سه سناریو اجرایی مطابق مدل مفهومی تعریف می‌شود:
[P930][Normal] سناریو 1 (Real-Only): تقسیم داده واقعی به آموزش/آزمون و اجرای کل فرآیند مدل‌سازی روی همین داده.
[P931][Normal] سناریو 2 (Half Real + Synthetic): بخشی از داده واقعی به‌عنوان «بذر تولید» و بخش دیگر به‌عنوان «آزمون واقعی» کنار گذاشته می‌شود؛ آموزش روی داده مصنوعی (یا ترکیب مشخص‌شده) و آزمون روی داده واقعی انجام می‌گردد.
[P932][Normal] سناریو 3 (All Real → Synthetic → Split): از کل داده واقعی برای تولید داده مصنوعی استفاده می‌شود؛ سپس داده مصنوعی به آموزش/آزمون تقسیم و ارزیابی انجام می‌گیرد.
[P933][Normal] گام 5) مدل‌سازی: آموزش مدل‌های کاندید و مدل‌های تجمیعی
[P934][Normal] در مرحله مدل‌سازی، دو دسته مدل پیاده‌سازی شده‌اند:
[P935][Normal] 5-1) مدل‌های کاندید (Candidate Models)
[P936][Normal] برای مقایسه جامع، مجموعه‌ای از الگوریتم‌ها شامل مدل‌های خطی، مبتنی بر درخت، مبتنی بر فاصله، و تقویتی انتخاب و اجرا شدند، از جمله:
[P937][Normal] رگرسیون خطی
[P938][Normal] درخت تصمیم
[P939][Normal] Gradient Boosting
[P940][Normal] نزدیکترین همسایه
[P941][Normal] درخت تصادفی
[P942][Normal] XGBoost
[P943][Normal] LightGBM
[P944][Normal] Extra Trees
[P945][Normal] Support Vector Machine
[P946][Normal] AdaBoost
[P947][Normal] هدف این مرحله، مقایسه عملکرد خانواده‌های مختلف مدل و انتخاب گزینه‌های مناسب برای تجمیع (Ensembling) است.
[P948][Normal] 5-2)مدل‌های تجمیعی (Ensemble Learning)
[P949][Normal] برای کاهش خطای مدل منفرد و افزایش پایداری، دو راهبرد تجمیعی پیاده‌سازی شد:
[P950][Normal] Soft Voting (VotingClassifier): ترکیب احتمالات خروجی چند مدل پایه با رأی‌گیری نرم و وزن‌دهی.
[P951][Normal] Stacking (StackingClassifier): استفاده از خروجی احتمالاتی چند مدل پایه به‌عنوان ورودی یک مدل نهایی (Meta-Learner) جهت تصمیم‌گیری نهایی.
[P952][Normal] گام 6) ارزیابی مدل‌ها
[P953][Normal] 6-1) اعتبارسنجی متقاطع طبقه‌بندی‌شده (Stratified K-Fold CV)
[P954][Normal] برای برآورد پایدار عملکرد و کاهش وابستگی به یک تقسیم‌بندی خاص، از StratifiedKFold با 10 فولد استفاده می‌شود تا نسبت کلاس‌ها در هر فولد حفظ گردد.
[P955][Normal] 6-2) ارزیابی روی مجموعه آزمون (Holdout Test)
[P956][Normal] پس از اعتبارسنجی، هر مدل روی کل داده آموزش آموزش داده شده و روی داده آزمون ارزیابی می‌شود. علاوه بر گزارش معیارها، ماتریس درهم‌ریختگی نیز برای تحلیل خطاها استخراج می‌گردد.
[P957][Normal] 6-3) معیارهای عملکرد
[P958][Normal] برای مقایسه مدل‌ها، مجموعه‌ای از معیارها محاسبه می‌شود:
[P959][Normal] Accuracy
[P960][Normal] ROC-AUC
[P961][Normal] Precision (macro)
[P962][Normal] Recall (macro)
[P963][Normal] F1-score (macro)
[P964][Normal] Cohen’s Kappa
[P965][Normal] Matthews Correlation Coefficient (MCC)
[P966][Normal] Confusion Matrix
[P967][Normal] این معیارها امکان تحلیل عملکرد مدل‌ها را هم از منظر دقت کلی و هم از منظر پایداری در شرایط عدم‌توازن یا خطاهای طبقه‌بندی فراهم می‌کنند.
[P968][Normal] 6-4) تحلیل زمان اجرا
[P969][Normal] به‌منظور بررسی کارایی محاسباتی، زمان آموزش و زمان پیش‌بینی مدل‌ها چندبار اندازه‌گیری و میانگین/انحراف معیار گزارش می‌شود. این مرحله به ویژه برای مقایسه مدل‌های سنگین‌تر (مانند Boostingها)با مدل‌های سبک‌تر اهمیت دارد.
[P970][Normal] گام 7) خروجی‌گیری و ذخیره نتایج
[P971][Normal] در پایان:
[P972][Normal] خلاصه نتایج اعتبارسنجی متقاطع،
[P973][Normal] نتایج آزمون نهایی،
[P974][Normal] و نتایج تحلیل زمان اجرا، در قالب فایل‌های خروجی (CSV) ذخیره شده و برای ارائه در قالب جدول/نمودار در فصل نتایج استفاده می‌شوند.
[P975][Normal] پیاده‌سازی سیستم پیشنهادی به‌صورت مرحله‌ای و با رعایت اصول پیش‌پردازش صحیح (کنترل نشت اطلاعات)، تعریف سناریوهای داده واقعی/مصنوعی و ارزیابی دقیق انجام شده است. این چارچوب با مقایسه طیف متنوعی از مدل‌ها و نیز استفاده از روش‌های تجمیعی (Soft Voting و Stacking)، امکان انتخاب بهترین راهکار از منظر دقت، پایداری و کارایی محاسباتی را فراهم می‌کند و در نهایت راهکاری داده‌محور برای تشخیص حملات تزریق NoSQL ارائه می‌دهد.
[P979][Heading 1] فصل چهارم- تجزیه‌وتحلیل داده‌ها (یافته‌ها)
[P1007][NewParagraph] این فصل به ارائه و تحلیل یافته‌های پژوهش اختصاص دارد. در راستای تحقق اهداف پژوهش، مجموعه‌داده‌های پردازش‌شده با استفاده از مدل‌های پیشنهادی مورد تجزیه‌وتحلیل قرار گرفته‌اند. این فصل شامل بررسی عملکرد مدل‌های یادگیری ماشینی، تحلیل نتایج به‌دست‌آمده، و مقایسه دقیق معیارهای ارزیابی است.
[P1008][NewParagraph] معیارهای کلیدی برای ارزیابی عملکرد مدل‌ها عبارت‌اند از صحت، نرخ بازیابی ، دقت پیش‌بینی، امتیاز F1 ، و مساحت زیر منحنی مشخصه عملکرد سیستم   این معیارها برای ارزیابی جامع توانایی مدل‌ها در شناسایی حملات تزریق پایگاه‌داده غیررابطه‌ای و تفکیک داده‌های مخرب از داده‌های قانونی استفاده می‌شوند.
[P1009][NewParagraph] علاوه بر این، تحلیل ماتریس درهم‌ریختگی و نمودارهای مربوط به عملکرد مدل‌ها به‌صورت دقیق موردبحث قرار می‌گیرد.
[P1010][NewParagraph] این فصل تلاش می‌کند تا با تحلیل دقیق نتایج و ارائه یافته‌های حاصل از مدل‌های پیشنهادی، شفافیت و جامعیت لازم را برای ارزیابی و درک عملکرد سیستم ارائه کند.
[P1011][Heading 2] 4-1 معیارهای ارزیابی عملکرد
[P1012][NewParagraph] ارزیابی عملکرد مدل‌های یادگیری ماشینی در پروژه‌های مرتبط با تشخیص حملات سایبری، به‌ویژه در سیستم‌های پیچیده‌ای؛ مانند حملات تزریق پایگاه‌داده غیررابطه‌ای، نقش بسیار مهمی در اطمینان از دقت و کارایی مدل‌ها ایفا می‌کند. در این پروژه، مجموعه‌ای از معیارهای کلیدی ارزیابی برای تحلیل عملکرد مدل‌های پیشنهادی و مقایسه آن‌ها با روش‌های موجود استفاده شده است. این معیارها به دودسته عددی  و طبقه‌بندی  تقسیم شده‌اند. در ادامه، این معیارها به همراه کاربردهای آن‌ها و دلایل اهمیت آن‌ها در پروژه توضیح داده شده‌اند.
[P1013][Normal] خطای میانگین مربعات
[P1014][Normal] MSE میانگین مجموع مربعات تفاوت بین مقادیر واقعی (ytrue) و پیش‌بینی‌شده (ypred) را محاسبه می‌کند.
[P1016][Normal] ویژگی‌ها:
[P1017][List Paragraph] نسبت به خطاهای بزرگ بسیار حساس است، زیرا اختلاف‌ها به توان دو می‌رسند.
[P1018][List Paragraph] برای تحلیل دقیق تأثیر خطاهای بزرگ مفید است.
[P1019][List Paragraph] هدف: کاهش MSE نشان‌دهنده بهبود دقت مدل است.
[P1020][Normal] میانگین خطای مطلق
[P1021][Normal] MAE میانگین قدرمطلق تفاوت بین مقادیر واقعی و پیش‌بینی‌شده را محاسبه می‌کند.
[P1023][Normal] ویژگی‌ها:
[P1024][List Paragraph] تفسیر آن ساده‌تر از MSE است؛ زیرا از توان دو استفاده نمی‌کند.
[P1025][List Paragraph] کمتر به خطاهای بزرگ حساس است.
[P1026][List Paragraph] هدف: کاهش MAE به معنی دقت بالاتر در پیش‌بینی‌ها است.
[P1027][Normal] میانگین درصد خطای مطلق
[P1028][Normal] MAPE میانگین درصد خطای پیش‌بینی را نسبت به مقادیر واقعی محاسبه می‌کند.
[P1030][Normal] ویژگی‌ها:
[P1031][List Paragraph] به واحد مقیاس داده‌ها وابسته نیست.
[P1032][List Paragraph] مناسب برای ارزیابی مدل‌هایی که خروجی آن‌ها در بازه‌های مختلف قرار دارد.
[P1033][List Paragraph] هدف: نشان‌دادن درصد خطای پیش‌بینی نسبت به مقدار واقعی.
[P1034][Normal] صحت
[P1035][Normal] تعریف: صحت نسبت تعداد پیش‌بینی‌های صحیح به تعداد کل نمونه‌ها است.
[P1037][Normal] ویژگی‌ها:
[P1038][List Paragraph] برای داده‌های متعادل مناسب است.
[P1039][List Paragraph] حساس به داده‌های نامتعادل نیست.
[P1040][List Paragraph] هدف: بالابردن صحت نشان‌دهنده تعداد بیشتری از پیش‌بینی‌های صحیح مدل است.
[P1041][Normal] ناحیه زیر منحنی
[P1042][Normal] AUC معیاری برای سنجش عملکرد مدل طبقه‌بندی است که حساسیت  و ویژگی    را در سطوح مختلف آستانه ارزیابی می‌کند.
[P1043][Normal] ویژگی‌ها:
[P1044][List Paragraph] مقدار AUC بین 0 و 1 است، هرچه مقدار به 1 نزدیک‌تر باشد، مدل قوی‌تر است.
[P1045][List Paragraph] مناسب برای داده‌های نامتعادل.
[P1046][List Paragraph] هدف: مقایسه عملکرد مدل‌های مختلف بر اساس توانایی آن‌ها در تمایز بین کلاس‌ها.
[P1047][Normal] حساسیت
[P1048][Normal] حساسیت نشان می‌دهد که چه درصدی از نمونه‌های مثبت واقعی به درستی توسط مدل شناسایی شده‌اند.
[P1050][Normal] ویژگی‌ها:
[P1051][List Paragraph] برای کاربردهایی که شناسایی نمونه‌های مثبت اهمیت دارد، بسیار حیاتی است.
[P1052][List Paragraph] هدف: افزایش حساسیت به معنای کاهش خطای ازدست‌دادن نمونه‌های مثبت است.
[P1053][Normal] ویژگی Specificity
[P1054][Normal] ویژگی Specificity نشان می‌دهد چه درصدی از نمونه‌های منفی واقعی به‌درستی توسط مدل شناسایی شده‌اند. ​
[P1055][Normal] در کاربردهایی که شناسایی نمونه‌های منفی مهم است، اهمیت دارد.
[P1056][Normal] دقت پیش‌بینی
[P1057][Normal] تعریف: دقت پیش‌بینی نشان می‌دهد که چه درصدی از نمونه‌های پیش‌بینی‌شده مثبت، واقعاً مثبت هستند. ​
[P1058][Normal] ویژگی‌ها:
[P1059][Normal] مناسب برای کاربردهایی که هزینه پیش‌بینی نادرست مثبت بالاست.
[P1060][Normal] تحلیل معیارها در پروژه ما
[P1061][Normal] جدول زیر مقایسه معیارهای استفاده‌شده در پروژه ما را ارائه می‌دهد:
[P1062][Caption] جدول 4- 1: معیارهای ارزیابی
[P1064][Heading 2] 4-2 بررسی دیتاست‌ها
[P1065][NewParagraph] در این بخش به تحلیل و بررسی دو مجموعه‌داده مورداستفاده در پروژه پرداخته می‌شود. این دو دیتاست شامل یک مجموعه اصلی و یک مجموعه مصنوعی تولیدشده با استفاده از مدل‌های زبان بزرگ (مدل‌های زبان بزرگ) هستند که به‌منظور جبران کمبود داده‌های واقعی و بهبود آموزش مدل‌های یادگیری ماشینی طراحی شده‌اند. هر یک از این مجموعه‌ها شامل ستون‌هایی با ویژگی‌های کلیدی است که مشخصات و ساختار داده‌های مرتبط با حملات تزریق پایگاه‌داده غیررابطه‌ای را توصیف می‌کنند.
[P1067][NewParagraph] دیتاست اصلی
[P1068][NewParagraph] 1.1 مشخصات دیتاست اصلی
[P1069][NewParagraph] تعداد رکوردها: 400 رکورد
[P1070][NewParagraph] نوع داده‌ها: داده‌های واقعی که به‌صورت دستی جمع‌آوری و برچسب‌گذاری شده‌اند.
[P1071][NewParagraph] ستون‌ها: شامل 18 ستون با مشخصات کلیدی برای توصیف داده‌ها، از جمله ویژگی‌های عددی و منطقی مرتبط با حملات پایگاه‌داده غیررابطه‌ای.
[P1072][NewParagraph] 1.2 تحلیل ویژگی‌ها
[P1073][NewParagraph] num_keys و num_operators: تعداد کلیدها و عملگرهای استفاده‌شده در هر پرس‌وجو.
[P1074][NewParagraph] length_user_value و length_password_value: طول مقادیر مرتبط با نام کاربری و رمز عبور.
[P1075][NewParagraph] contains_email_pattern و contains_ip_pattern: وجود الگوهای ایمیل و آدرس IP در داده‌ها.
[P1076][NewParagraph] nested_keys_exist و nested_depth: وجود و عمق کلیدهای تودرتو.
[P1077][NewParagraph] contains_numeric_values و contains_boolean_values: وجود مقادیر عددی و بولی در داده‌ها.
[P1078][NewParagraph] Label: برچسبی که نشان می‌دهد رکورد مربوط به حمله (1) است یا غیر حمله (0).
[P1079][NewParagraph] 1.3 تحلیل محدودیت‌ها
[P1080][NewParagraph] دیتاست اصلی، علی‌رغم اینکه داده‌های واقعی و برچسب‌گذاری شده را شامل می‌شود، دارای محدودیت‌هایی است:
[P1081][NewParagraph] تعداد کم رکوردها: تعداد رکوردها برای آموزش مدل‌های یادگیری ماشینی پیچیده ناکافی است.
[P1082][NewParagraph] تنوع محدود: تنوع سناریوهای حمله و داده‌های غیرمخرب در این مجموعه نسبتاً کم است.
[P1083][NewParagraph] عدم تعمیم‌پذیری: به دلیل حجم پایین داده، مدل‌های آموزش‌دیده ممکن است عملکرد ضعیفی روی داده‌های ناشناخته داشته باشند.
[P1084][NewParagraph] دیتاست مصنوعی
[P1085][NewParagraph] 1.4 مشخصات دیتاست مصنوعی
[P1086][NewParagraph] تعداد رکوردها: 2000 رکورد
[P1087][NewParagraph] نوع داده‌ها: داده‌های تولیدشده به‌صورت مصنوعی با استفاده از مدل‌های زبان بزرگ
[P1088][NewParagraph] ستون‌ها: شامل همان 18 ستون کلیدی که در دیتاست اصلی وجود دارند.
[P1089][NewParagraph] 1.5  فرایند تولید دیتاست
[P1090][NewParagraph] دیتاست مصنوعی با استفاده از مدل مدل‌های زبان بزرگ   و بر اساس تحلیل ویژگی‌های دیتاست اصلی تولید شده است. مراحل اصلی تولید عبارت‌اند از:
[P1091][NewParagraph] استخراج ویژگی‌های کلیدی از دیتاست اصلی: شناسایی ویژگی‌های مهم نظیر تعداد کلیدها، طول مقادیر، وجود مقادیر خاص (مانند ایمیل یا IP)، و برچسب‌ها.
[P1092][NewParagraph] تولید داده‌های مصنوعی توسط مدل‌های زبان بزرگ: مدل مدل‌های زبان بزرگ   با استفاده از پرامپت‌های طراحی‌شده داده‌هایی مشابه دیتاست اصلی تولید کرده است.
[P1093][NewParagraph] تنوع‌سازی: اطمینان از ایجاد تنوع در داده‌ها، شامل سناریوهای مختلف حملات و داده‌های غیرمخرب.
[P1094][NewParagraph] 1.6 تحلیل ویژگی‌ها
[P1095][NewParagraph] ویژگی‌های موجود در دیتاست مصنوعی مشابه دیتاست اصلی است، اما با تنوع و حجم بیشتری:
[P1096][NewParagraph] num_nested_keys و nested_depth: مقادیر تولیدشده شامل تنوع بیشتری در تعداد کلیدهای تودرتو و عمق آن‌ها است.
[P1097][NewParagraph] contains_email_pattern و contains_ip_pattern: داده‌های مصنوعی شامل الگوهای ایمیل و IP بیشتری برای شبیه‌سازی شرایط واقعی‌تر است.
[P1098][NewParagraph] Label: برچسب‌ها به‌صورت متوازن توزیع شده‌اند تا مدل بتواند تعمیم‌پذیری بهتری داشته باشد.
[P1099][Caption] جدول 4- 2: تحلیل مقایسه‌ای دیتاست ها
[P1101][NewParagraph] در ادامه تحلیل ماتریس همبستگی در دو دیتاست را بررسی می‌کنیم:
[P1104][Caption] شکل 4-  1: ماتریس همبستگی دیتا اصلی
[P1105][NewParagraph] تحلیل ماتریس همبستگی ویژگی‌ها
[P1106][NewParagraph] ماتریس همبستگی ارائه‌شده به‌صورت یک Heatmap، روابط میان ویژگی‌های مختلف در دیتاست مصنوعی را نشان می‌دهد. این ماتریس همبستگی خطی بین متغیرها را در بازه [−1,1]نمایش می‌دهد:
[P1107][NewParagraph] 1+  →  همبستگی مثبت کامل
[P1108][NewParagraph] 0  → عدم همبستگی
[P1109][NewParagraph] 1-  → همبستگی منفی کامل
[P1110][NewParagraph] رنگ‌های گرم‌تر نشان‌دهنده همبستگی مثبت قوی‌تر و رنگ‌های سردتر بیانگر همبستگی ضعیف یا منفی هستند. بر اساس شکل، تحلیل روابط به شرح زیر است.
[P1111][NewParagraph] 1. تحلیل روابط کلیدی
[P1112][NewParagraph] 1.1 ویژگی‌های با همبستگی مثبت بالا
[P1113][NewParagraph] ساختارهای تودرتو (Nested Structure Features)
[P1114][NewParagraph] nested_keys_exist ، num_nested_keys و nested_depth
[P1115][NewParagraph] این سه ویژگی همبستگی مثبت بسیار قوی با یکدیگر دارند.
[P1116][NewParagraph] این موضوع نشان می‌دهد که وجود کلیدهای تودرتو معمولاً با افزایش تعداد آن‌ها و افزایش عمق ساختار داده همراه است.
[P1117][NewParagraph] این رابطه منطقی بوده و نشان‌دهنده سازگاری ساختار داده‌های مصنوعی با ساختار واقعی پایگاه‌های داده NoSQL است.
[P1118][NewParagraph] ویژگی‌های ساختاری رکورد
[P1119][NewParagraph] unique_key_count ، data_type_diversity و special_characters_exist
[P1120][NewParagraph] بین این ویژگی‌ها همبستگی مثبت قابل توجهی مشاهده می‌شود.
[P1121][NewParagraph] رکوردهایی با تعداد کلیدهای بیشتر معمولاً دارای تنوع نوع داده و استفاده بیشتر از کاراکترهای خاص هستند.
[P1122][NewParagraph] این موضوع نشان‌دهنده افزایش پیچیدگی ساختار رکورد با افزایش تعداد ویژگی‌ها است.
[P1123][NewParagraph] ویژگی‌های طول فیلدها
[P1124][NewParagraph] length_user_value ، length_password_value و length_username_value
[P1125][NewParagraph] همبستگی مثبت متوسط بین این ویژگی‌ها نشان می‌دهد که طول فیلدهای متنی مرتبط معمولاً رفتار مشابهی دارند.
[P1126][NewParagraph] این امر بیانگر الگوی تولید داده یکنواخت در مقادیر متنی است.
[P1127][NewParagraph] 1.2 ویژگی‌های با همبستگی منفی یا ضعیف
[P1128][NewParagraph] contains_fixed_values با بیشتر ویژگی‌های پیچیدگی داده
[P1129][NewParagraph] این ویژگی همبستگی منفی یا بسیار ضعیف با تنوع داده و طول رکورد دارد.
[P1130][NewParagraph] وجود مقادیر ثابت معمولاً نشان‌دهنده ساختار ساده‌تر رکوردها است.
[P1131][NewParagraph] contains_numeric_values با برخی ویژگی‌های طول فیلد
[P1132][NewParagraph] در تصویر، همبستگی منفی یا بسیار کم با طول مقادیر متنی مشاهده می‌شود.
[P1133][NewParagraph] این نشان می‌دهد رکوردهای دارای مقادیر عددی الزاماً طول رشته بیشتری ندارند.
[P1134][NewParagraph] 2. ویژگی‌های تقریباً مستقل
[P1135][NewParagraph] برخی ویژگی‌ها تقریباً بدون ارتباط خطی با سایر متغیرها هستند:
[P1136][NewParagraph] contains_email_pattern
[P1137][NewParagraph] contains_ip_pattern
[P1138][NewParagraph] contains_boolean_values
[P1139][NewParagraph] contains_empty_strings
[P1140][NewParagraph] استقلال این ویژگی‌ها نشان می‌دهد که این الگوها به‌صورت مستقل در داده تولید شده‌اند و وابستگی ساختاری مستقیمی با پیچیدگی رکورد ندارند. این موضوع باعث افزایش تنوع داده و جلوگیری از وابستگی مصنوعی بین ویژگی‌ها می‌شود.
[P1141][NewParagraph] 3. خوشه‌بندی طبیعی ویژگی‌ها در ماتریس
[P1142][NewParagraph] بر اساس Heatmap می‌توان سه خوشه اصلی از ویژگی‌ها را مشاهده کرد:
[P1143][NewParagraph] ویژگی‌های ساختار کلیدها و پیچیدگی داده
[P1144][NewParagraph] (nested_keys، nested_depth، unique_key_count، data_type_diversity)
[P1145][NewParagraph] ویژگی‌های مربوط به طول مقادیر متنی
[P1146][NewParagraph] (length_user_value، length_password_value، length_username_value)
[P1147][NewParagraph] ویژگی‌های مربوط به الگوهای خاص داده
[P1148][NewParagraph] (email، ip، boolean، empty strings)
[P1149][NewParagraph] وجود این خوشه‌بندی نشان می‌دهد داده‌های مصنوعی ساختار منطقی و تفکیک‌پذیری مناسبی دارند.
[P1150][NewParagraph] 4.ارزیابی کیفیت داده‌های مصنوعی
[P1151][NewParagraph] نقاط قوت
[P1152][NewParagraph] روابط منطقی بین ویژگی‌های ساختاری (nested و depth) به‌خوبی بازتاب داده شده‌اند.
[P1153][NewParagraph] وجود خوشه‌های مشخص ویژگی‌ها نشان‌دهنده ساختار مناسب داده است.
[P1154][NewParagraph] توزیع متعادل همبستگی‌ها نشان‌دهنده تنوع مناسب ویژگی‌ها است.
[P1155][NewParagraph] نقاط قابل بهبود
[P1156][NewParagraph] برخی ویژگی‌ها تقریباً مستقل از سایر متغیرها هستند که ممکن است نشان‌دهنده ساده بودن فرآیند تولید داده برای این متغیرها باشد.
[P1157][NewParagraph] می‌توان وابستگی‌های واقعی‌تری بین ویژگی‌های الگو (email، ip و ...) ایجاد کرد.
[P1160][Caption] شکل 4-  2: ماتریس همبستگی دیتا مصنوعی
[P1161][NewParagraph] ماتریس همبستگی ارائه‌شده برای دیتاست مصنوعی، روابط خطی بین ویژگی‌های مختلف این مجموعه‌داده را نشان می‌دهد. این ماتریس به‌صورت گرافیکی در قالب Heatmap نمایش داده شده و میزان همبستگی قوی، متوسط و ضعیف میان ویژگی‌ها را مشخص می‌کند. مقادیر همبستگی در بازه [−1,1]قرار داشته و رنگ‌های گرم‌تر نشان‌دهنده همبستگی مثبت قوی‌تر و رنگ‌های سردتر نشان‌دهنده همبستگی ضعیف یا منفی هستند. در ادامه، روابط کلیدی میان ویژگی‌ها بررسی می‌شود.
[P1162][NewParagraph] 1. تحلیل روابط کلیدی
[P1163][NewParagraph] 1.1 ویژگی‌های با همبستگی مثبت بالا
[P1164][NewParagraph] ویژگی‌های ساختار تودرتو
[P1165][NewParagraph] nested_keys_exist و num_nested_keys
[P1166][NewParagraph] همبستگی مثبت بسیار قوی بین این دو ویژگی مشاهده می‌شود.
[P1167][NewParagraph] این رابطه نشان می‌دهد که وجود کلیدهای تودرتو مستقیماً با تعداد کلیدهای تودرتو مرتبط است.
[P1168][NewParagraph] این ارتباط منطقی بوده و نشان‌دهنده سازگاری داده‌های مصنوعی با ساختار واقعی داده‌های NoSQL است.
[P1169][NewParagraph] nested_depth با nested_keys_exist و num_nested_keys
[P1170][NewParagraph] عمق تودرتویی داده‌ها نیز همبستگی مثبت قوی با تعداد و وجود کلیدهای تودرتو دارد.
[P1171][NewParagraph] این نتیجه نشان می‌دهد که با افزایش پیچیدگی ساختار داده، عمق ساختار نیز افزایش می‌یابد.
[P1172][NewParagraph] ویژگی‌های پیچیدگی ساختار داده
[P1173][NewParagraph] unique_key_count و data_type_diversity
[P1174][NewParagraph] همبستگی مثبت بسیار قوی بین این دو ویژگی مشاهده می‌شود.
[P1175][NewParagraph] رکوردهایی با تعداد کلیدهای بیشتر معمولاً تنوع بیشتری در انواع داده دارند.
[P1176][NewParagraph] special_characters_exist با data_type_diversity و unique_key_count
[P1177][NewParagraph] همبستگی مثبت نسبتاً بالا نشان می‌دهد که رکوردهای پیچیده‌تر از کاراکترهای خاص بیشتری استفاده می‌کنند.
[P1178][NewParagraph] ویژگی‌های طول مقادیر متنی
[P1179][NewParagraph] length_user_value ، length_password_value و length_username_value
[P1180][NewParagraph] همبستگی مثبت متوسط بین این ویژگی‌ها مشاهده می‌شود.
[P1181][NewParagraph] این موضوع نشان‌دهنده الگوی مشابه در تولید داده‌های متنی در رکوردهای مصنوعی است.
[P1182][NewParagraph] 1.2 ویژگی‌های با همبستگی منفی یا ضعیف
[P1183][NewParagraph] contains_fixed_values با ویژگی‌های پیچیدگی داده
[P1184][NewParagraph] این ویژگی همبستگی ضعیف یا منفی با متغیرهایی مانند تنوع داده و طول رکورد دارد.
[P1185][NewParagraph] این موضوع نشان می‌دهد که وجود مقادیر ثابت معمولاً با کاهش پیچیدگی ساختار داده همراه است.
[P1186][NewParagraph] contains_numeric_values با برخی ویژگی‌های متنی
[P1187][NewParagraph] همبستگی ضعیف یا منفی نشان می‌دهد که وجود مقادیر عددی الزاماً با افزایش طول داده‌های متنی همراه نیست.
[P1188][NewParagraph] 1.3 ویژگی‌های مستقل
[P1189][NewParagraph] contains_email_pattern و contains_ip_pattern
[P1190][NewParagraph] این ویژگی‌ها تقریباً با سایر متغیرها همبستگی بسیار کمی دارند.
[P1191][NewParagraph] این استقلال نشان می‌دهد که این الگوها به‌صورت مستقل در داده‌های مصنوعی تولید شده‌اند.
[P1192][NewParagraph] contains_empty_strings و contains_boolean_values
[P1193][NewParagraph] همبستگی ضعیف با سایر ویژگی‌ها نشان می‌دهد که این مقادیر به‌صورت پراکنده و مستقل در رکوردها وجود دارند.
[P1194][NewParagraph] 2. جمع‌بندی ساختار داده مصنوعی
[P1195][NewParagraph] نتایج نشان می‌دهد که داده‌های مصنوعی دارای ساختار منطقی و خوشه‌بندی مشخصی از ویژگی‌ها هستند:
[P1196][NewParagraph] ویژگی‌های مرتبط با ساختار تودرتو دارای وابستگی قوی هستند.
[P1197][NewParagraph] ویژگی‌های مرتبط با پیچیدگی رکورد با یکدیگر همبستگی مثبت دارند.
[P1198][NewParagraph] ویژگی‌های مربوط به الگوهای خاص داده (email، ip، boolean و …) تقریباً مستقل از سایر ویژگی‌ها هستند.
[P1199][NewParagraph] این نتایج نشان می‌دهد که فرآیند تولید داده مصنوعی توانسته است روابط منطقی بین ویژگی‌ها را حفظ کرده و در عین حال تنوع مناسبی در ساختار داده ایجاد کند.
[P1201][NewParagraph] 4-3 مقایسه عملکرد مدل‌ها
[P1202][NewParagraph] 4-3-1 عملکرد مدل‌های مختلف یادگیری ماشینی روی دیتاست اصلی
[P1203][Normal] در این بخش، عملکرد مجموعه‌ای از مدل‌های یادگیری ماشین (شامل مدل‌های پایه و مدل‌های یادگیری گروهی) روی دیتاست اصلی ارزیابی و با یکدیگر مقایسه می‌شود. ارزیابی به‌صورت دو مرحله‌ای انجام شده است: (1) اعتبارسنجی متقاطع طبقه‌بندی‌شده برای برآورد پایدار عملکرد، و (2) آزمون نهایی روی مجموعه آزمون برای تحلیل رفتار واقعی مدل‌ها در شرایط تعمیم. در ادامه، نتایج آزمایش‌ها به‌صورت مرحله‌به‌مرحله گزارش و تفسیر می‌گردد.
[P1204][Normal] گام 1) روش ارزیابی و معیارهای سنجش
[P1205][Normal] اعتبارسنجی متقاطع Stratified K-Fold (با 10 فولد)
[P1206][Normal] به‌منظور کاهش وابستگی به یک تقسیم‌بندی خاص و حفظ نسبت کلاس‌ها در فولدهای آموزش/اعتبارسنجی، از StratifiedKFold استفاده شده است؛ این روش توزیع نسبی کلاس‌ها را در هر فولد حفظ می‌کند و برای مسائل طبقه‌بندی دودویی/چندکلاسه توصیه می‌شود.
[P1207][Normal] محاسبه معیارهای عملکرد:
[P1208][Normal] در هر فولد و همچنین در آزمون نهایی، معیارهای زیر محاسبه شده‌اند: Accuracy، ROC-AUC، Recall (macro)، Precision (macro)، F1 (macro)، Cohen’s Kappa و MCC
[P1209][Normal] ROC-AUC شاخصی برای سنجش توان تفکیک‌پذیری مدل بر اساس نمرات/احتمالات پیش‌بینی است و مستقل از یک آستانه ثابت تفسیر می‌شود.
[P1210][Normal] MCC معیار متوازن‌تری است که همزمان TP/TN/FP/FN را لحاظ می‌کند و حتی در شرایط عدم‌توازن نیز قابل اتکاست.
[P1211][Normal] Cohen’s Kappa میزان توافق مدل با برچسب‌های واقعی را با اصلاح توافق تصادفی می‌سنجد.
[P1212][Normal] گام 2) نتایج اعتبارسنجی متقاطع (10- Fold CV) روی دیتاست اصلی
[P1213][Normal] جدول 4-3 خلاصه نتایج آزمایش‌های CV را برای هر مدل نشان می‌دهد (میانگین و در صورت وجود انحراف معیار برای برخی شاخص‌ها). این جدول مبنای مقایسه “پایداری” و “میانگین عملکرد” مدل‌هاست.
[P1214][Caption] جدول 4- 3:  خلاصه نتایج اعتبارسنجی متقاطع 10-فولدی روی دیتاست اصلی
[P1215][Normal] تفسیر نتایج :
[P1216][Normal] در نتایج آزمایش‌های CV، مدل Soft Voting بالاترین Accuracy و ROC-AUC را ثبت کرده است. این امر نشان می‌دهد ترکیب چند مدل و تجمیع احتمال‌ها می‌تواند به بهبود پایداری و کاهش واریانس منجر شود (به‌ویژه در داده‌های محدود).
[P1217][Normal] مدل‌های درختی-تجمیعی مانند درخت تصادفی و Extra Trees نیز عملکرد نزدیک و پایدار ارائه کرده‌اند.
[P1218][Normal] مدل‌های ساده‌تر مانند رگرسیون خطی و SVM در این مسئله (با الگوهای احتمالاً غیرخطی) در سطح پایین‌تری قرار گرفته‌اند.
[P1219][Normal] انتخاب StratifiedKFold باعث می‌شود مقایسه مدل‌ها تحت حفظ نسبت کلاس‌ها منصفانه‌تر باشد.
[P1220][Normal] گام 3) نتایج آزمون نهایی روی Test Set (دیتاست اصلی)
[P1221][Normal] پس از اتمام اعتبارسنجی متقاطع، هر مدل روی داده‌های آموزشی آموزش داده شد و روی مجموعه آزمون ارزیابی گردید. جدول 4-4 نتایج آزمون نهایی را نشان می‌دهد.
[P1222][Caption] جدول 4- 4: نتایج آزمون نهایی مدل‌ها روی دیتاست اصلی
[P1223][Normal] تفسیر نتایج Test  با تکیه بر نتایج آزمایش:
[P1224][Normal] از منظر معیارهای “متعادل” (به‌ویژه MCC و Kappa) و نیز Accuracy/F1، درخت تصادفی بهترین نتیجه را روی آزمون نهایی ارائه کرده است. این معیارها به دلیل لحاظ کردن همه درایه‌های ماتریس درهم‌ریختگی، تصویر دقیق‌تری از کیفیت طبقه‌بندی ارائه می‌دهند.
[P1225][Normal] از نظر ROC-AUC، مدل Extra Trees بالاترین مقدار را دارد. تفاوت بین «AUC بالاتر» و «Accuracy پایین‌تر» می‌تواند ناشی از این باشد که AUC توان رتبه‌بندی/تفکیک را می‌سنجد و الزاماً بهترین عملکرد را در آستانه تصمیم ثابت (مثل 0.5) تضمین نمی‌کند.
[P1226][Normal] مشاهده اختلاف میان بهترین مدل در CV (Soft Voting) و بهترین مدل در Test (درخت تصادفی) نشان‌دهنده اهمیت گزارش هر دو سطح ارزیابی است؛ در داده‌های کوچک، نوسان نمونه‌ها و حساسیت به تقسیم Train/Test می‌تواند باعث تغییر رتبه مدل‌ها شود.
[P1227][Normal] گام 4) تحلیل رفتاری مدل‌ها با ماتریس درهم‌ریختگی (Confusion Matrix)
[P1228][Normal] برای تحلیل دقیق‌تر، ماتریس‌های درهم‌ریختگی مجموعه آزمون (مطابق شکل ارائه‌شده) نشان می‌دهد هر مدل چگونه بین False Positive و False Negative مبادله برقرار کرده است. این تحلیل برای مسئله امنیتی بسیار مهم است، زیرا FN (عدم تشخیص حمله) معمولاً هزینه بالاتری دارد.
[P1229][Normal] خلاصه چهار مؤلفه (TN, FP, FN, TP) برای هر مدل بر اساس نتایج آزمایش:
[P1230][Caption] جدول 4- 5: چهار مؤلفه (TN, FP, FN, TP) برای هر مدل
[P1233][Caption] شکل 4- 1: ماتریس درهم ریختگی مدلها
[P1234][Normal] جمع‌بندی تحلیلی Confusion Matrix:
[P1235][Normal] درخت تصمیم با FP≈0 (Specificity بالا) اما FN بسیار زیاد، عملاً بسیاری از حملات را از دست می‌دهد (ریسک عملیاتی بالا).
[P1236][Normal] SVM رفتار کاملاً معکوس دارد (تقریباً همه نمونه‌ها را حمله تشخیص می‌دهد) که FP بسیار بالا ایجاد می‌کند و برای بهره‌برداری عملی می‌تواند منجر به هشدارهای کاذب گسترده شود.
[P1237][Normal] درخت تصادفی در نتایج آزمایش، نسبتاً متعادل‌تر عمل کرده و همین امر با مقادیر بهتر MCC/Kappa هم‌راستا است (معیارهای متوازن بر پایه کل ماتریس)
[P1238][Normal] بر اساس نتایج آزمایش روی دیتاست اصلی:
[P1239][Normal] در سطح اعتبارسنجی متقاطع، مدل Soft Voting بهترین میانگین عملکرد را نشان داده است.
[P1240][Normal] در سطح آزمون نهایی، درخت تصادفی بهترین نتیجه را از منظر Accuracy/F1 و به‌ویژه معیارهای متوازن MCC/Kappa ارائه کرده است.
[P1241][Normal] تحلیل Confusion Matrix نشان داد برخی مدل‌ها به سمت کاهش FP با افزایش FN یا بالعکس متمایل هستند؛ در کاربرد امنیتی، این مبادله باید متناسب با هزینه خطاها مدیریت شود (مثلاً با تنظیم آستانه تصمیم یا راهبردهای هزینه‌محور).
[P1242][Heading 3] 4-3-2 عملکرد روی Syn-2000 (Seed = 50% Real)
[P1243][Normal] در این بخش، عملکرد مدل‌ها روی دیتاست Syn-2000 گزارش می‌شود؛ این دیتاست مصنوعی با استفاده از نیمی از داده واقعی (200 رکورد به‌عنوان Seed) تولید شده و سپس برای ارزیابی، مطابق رویه آزمایش، به دو بخش آموزش و آزمون تفکیک گردیده است (در خروجی آزمون، 400 نمونه به‌عنوان Test دیده می‌شود؛ یعنی سناریوی آزمون 20% از 2000 رکورد)
[P1244][Normal] ارزیابی مدل‌ها در این سناریو بر مبنای نتایج آزمایش روی مجموعه آزمون و با اتکا به ماتریس‌های درهم‌ریختگی (Confusion Matrices) انجام شده است. در یک مسئله امنیتی، تحلیل Confusion Matrix اهمیت ویژه‌ای دارد، زیرا:
[P1245][Normal] FN (False Negative) به معنی «حمله‌ای که تشخیص داده نشده» و از نظر ریسک، معمولاً پرهزینه‌ترین خطاست.
[P1246][Normal] FP (False Positive) به معنی «هشدار کاذب» است که هزینه عملیاتی و نویز هشدارها را افزایش می‌دهد.
[P1247][Normal] گام 1) استخراج مؤلفه‌های Confusion Matrix
[P1248][Normal] برای هر مدل، چهار مؤلفه زیر از نتایج آزمون استخراج شده است:
[P1249][Normal] TN: نمونه‌های غیرحمله که درست غیرحمله تشخیص داده شدند
[P1250][Normal] FP: غیرحمله‌هایی که اشتباهاً حمله تشخیص داده شدند
[P1251][Normal] FN: حمله‌هایی که اشتباهاً غیرحمله تشخیص داده شدند
[P1252][Normal] TP: حمله‌هایی که درست حمله تشخیص داده شدند
[P1253][Caption] جدول 4- 6: خلاصه ماتریس درهم‌ریختگی مدل‌ها روی Syn-2000 (Test = 400)
[P1256][Caption] شکل 4- 2: کنفیوژن ماتریس مدلها با 2000 دیتا مصنوعی
[P1258][Normal] گام 2) محاسبه معیارهای عملکرد (بر مبنای نتایج آزمون)
[P1259][Normal] برای مقایسه کمی مدل‌ها، معیارهای زیر از Confusion Matrix محاسبه و گزارش شده‌اند:
[P1260][Normal] Accuracy: نسبت کل پیش‌بینی‌های صحیح
[P1261][Normal] Precision (macro) و Recall (macro) و F1 (macro): میانگین عملکرد روی هر دو کلاس (حمله/غیرحمله)
[P1262][Normal] Precision_pos / Recall_pos / F1_pos: عملکرد روی کلاس «حمله» (کلاس مثبت)
[P1263][Normal] Specificity: توانایی مدل در شناسایی «غیرحمله» (کلاس منفی)
[P1264][Caption] جدول 4- 7: نتایج عملکرد مدل‌ها روی Syn-2000 (Test)
[P1266][Normal] گام 3) تحلیل و مقایسه آکادمیک نتایج (بر اساس آزمون)
[P1267][Normal] 1) بهترین مدل از نظر عملکرد کلی (Accuracy و F1 macro)
[P1268][Normal] KNN با Accuracy=0.9125 و F1(macro)=0.9112 بهترین عملکرد کلی را ثبت کرده است.
[P1269][Normal] این نتیجه همراه با FP بسیار پایین (17) و FN پایین (18) نشان می‌دهد KNN در این سناریو همزمان توانسته است هشدار کاذب را کنترل کند و حملات از دست‌رفته را نیز حداقل نگه دارد.
[P1270][Normal] 2) بهترین مدل‌ها از نظر تشخیص حمله (Recall روی کلاس Attack)
[P1271][Normal] KNN و Ensemble (Soft Voting) هر دو Recall(Attack)=0.92 دارند؛ یعنی در نتایج آزمایش، حدود 92% حملات در آزمون شناسایی شده‌اند.
[P1272][Normal] با این حال، Soft Voting در مقایسه با KNN FP بیشتری تولید کرده است (25 در برابر 17). بنابراین KNN از نظر عملیاتی (کاهش نویز هشدار) گزینه مناسب‌تری است.
[P1273][Normal] 3) عملکرد مدل‌های تقویتی/درختی پیشرفته (LightGBM و XGBoost)
[P1274][Normal] LightGBM با Accuracy=0.855 و F1(Attack)=0.8734 عملکرد قابل توجهی داشته است و نسبت به XGBoost، هم FP و هم FN را کمتر نگه داشته است (FP=33, FN=25).
[P1275][Normal] XGBoost نیز قوی است (Accuracy=0.8275)، اما FP بیشتری نسبت به LightGBM دارد (42).
[P1276][Normal] 4)علت افت مدل‌های ساده‌تر در این سناریو:
[P1277][Normal] رگرسیون خطی در آزمون دارای FP بسیار بالا (110) و Specificity پایین (0.3714) است؛ یعنی تمایل به برچسب‌زدن «حمله» برای تعداد زیادی از نمونه‌های غیرحمله دارد.
[P1278][Normal] SVM نیز FP و FN بالایی ثبت کرده (FP=92, FN=60) که نشان می‌دهد در این تنظیمات، مرز تصمیم مناسبی برای داده‌های این سناریو شکل نگرفته است.
[P1279][Normal] جمع‌بندی
[P1280][Normal] بر اساس نتایج آزمایش روی Syn-2000 (Seed=50% Real)
[P1281][Normal] KNN بهترین مدل از نظر توازن کلی خطاها و بیشترین دقت بوده است (هم FP و هم FN پایین)
[P1282][Normal] Ensemble (Soft Voting) و Stacking نیز عملکرد رقابتی دارند، اما در این آزمون، یا FP بالاتری نسبت به KNN داشته‌اند یا FN بیشتری ایجاد کرده‌اند.
[P1283][Normal] در تحلیل امنیتی، مدلی مطلوب‌تر است که FN را پایین نگه دارد و در عین حال FP را کنترل کند؛ در این سناریو، KNN بهترین trade-off را نشان داده است.
[P1284][Heading 3] 4-3-3 عملکرد روی Syn-2000 (Seed = All Real-400)
[P1285][Normal] در این سناریو، مجموعه‌داده مصنوعی Syn-2000 با استفاده از کل دیتاست واقعی (400 رکورد) به‌عنوان Seed تولید شده است. سپس مطابق طراحی آزمایش، داده‌ها به آموزش/آزمون تفکیک شده‌اند؛ با توجه به مجموع مقادیر هر ماتریس درهم‌ریختگی، اندازه مجموعه آزمون در این سناریو 320 نمونه است. ارزیابی عملکرد مدل‌ها بر پایه نتایج آزمون و تحلیل دقیق Confusion Matrix انجام می‌شود، زیرا در مسائل امنیتی، توازن بین False Negative (حملهِ کشف‌نشده) و False Positive (هشدار کاذب) تعیین‌کننده کیفیت عملیاتی سامانه است.
[P1286][Normal] گام 1) استخراج مؤلفه‌های ماتریس درهم‌ریختگی
[P1287][Normal] چهار مؤلفه استاندارد عبارت‌اند از:
[P1288][Normal] TN (غیرحمله درست)، FP (هشدار کاذب)، FN (حمله از دست‌رفته)، TP (حمله درست).
[P1289][Caption] جدول 4- 8: خلاصه ماتریس‌های درهم‌ریختگی مدل‌ها روی Syn-2000 (Seed=All Real-400) در مجموعه آزمون
[P1290][Normal] گام 2) محاسبه شاخص‌های عملکرد روی مجموعه آزمون
[P1291][Normal] برای مقایسه کمی، شاخص‌های زیر از Confusion Matrix استخراج شده‌اند:
[P1292][Normal] Accuracy: سهم پیش‌بینی‌های صحیح از کل نمونه‌ها
[P1293][Normal] Precision/Recall/F1 (macro): میانگین عملکرد روی هر دو کلاس (حمله و غیرحمله)
[P1294][Normal] Precision/Recall/F1 برای کلاس حمله (Attack): شاخص‌های حساس برای ارزیابی توان تشخیص حمله
[P1295][Normal] Specificity: توان مدل در شناسایی صحیح «غیرحمله» (کنترل هشدار کاذب)
این نوع تحلیل با چارچوب متریک‌های طبقه‌بندی در scikit-learn هم‌راستا است.
[P1296][Caption] جدول 4- 9: نتایج عملکرد مدل‌ها روی Syn-2000 (Seed=All Real-400) در مجموعه آزمون
[P1297][Normal] گام 3) تحلیل آکادمیک نتایج (مبتنی بر آزمون)
[P1298][List Paragraph] بهترین عملکرد کلی (Accuracy و F1 macro)
[P1299][Normal] بر اساس نتایج آزمون، LightGBM بالاترین Accuracy و F1(macro) را ثبت کرده است. این موضوع نشان می‌دهد داده مصنوعی تولیدشده با Seed کاملِ واقعی، برای LightGBM ساختاری ایجاد کرده که هم در تشخیص حمله و هم در کنترل خطاهای کلاس غیرحمله، تعادل مناسبی برقرار می‌شود.
[P1300][Normal] 2) حساسیت به حمله (Recall برای کلاس Attack) و کنترل حمله‌های از دست‌رفته (FN)
[P1301][Normal] کمترین FN مربوط به Stacking Ensemble است (FN=14) و در نتیجه بالاترین Recall(Attack)=0.9186 را دارد. از منظر امنیتی، کاهش FN اهمیت ویژه‌ای دارد چون «حمله‌ای که تشخیص داده نشود» مستقیماً ریسک نفوذ را افزایش می‌دهد.
[P1302][Normal] با این حال، Stacking در مقایسه با LightGBM/XGBoost، FP بالاتری دارد (38 در برابر 32) و این به معنی افزایش هشدارهای کاذب و هزینه عملیاتی بالاتر است.
[P1303][Normal] 3)بهترین توازن عملیاتی بین FP و FN
[P1304][Normal] LightGBM توازن بسیار خوبی ایجاد کرده است: FN پایین (17) در کنار FP کنترل‌شده (32).
[P1305][Normal] Soft Voting نیز Specificity بالاتری دارد (0.7973) و FP کمتری ثبت کرده (30) اما FN آن از LightGBM بیشتر است (26). در سامانه‌های امنیتی، ترجیح بین این دو به سیاست سازمان وابسته است: اگر هزینه FN بالاتر باشد، LightGBM ارجح است؛ اگر کنترل FP اولویت داشته باشد، Soft Voting می‌تواند گزینه قابل دفاعی باشد.
[P1306][Normal] 4) رفتار مدل‌های ساده‌تر
[P1307][Normal] رگرسیون خطی در این سناریو ضعیف‌ترین عملکرد کلی را دارد (Accuracy≈0.569) و همزمان FP و FN نسبتاً بالا ثبت کرده است. این الگو نشان می‌دهد مرز تصمیم خطی برای داده‌های این مسئله کافی نبوده و مدل در جداسازی الگوهای حمله/غیرحمله محدودیت دارد.
[P1308][Normal] جمع‌بندی
[P1309][Normal] بر اساس نتایج آزمایش روی Syn-2000 (Seed = All Real-400):
[P1310][Normal] LightGBM بهترین عملکرد کلی را ارائه کرده (بالاترین Accuracy و F1 macro) و در عین حال FN و FP را در سطح متعادل نگه داشته است.
[P1311][Normal] Stacking Ensemble کمترین FN را دارد و برای سناریوهایی که «عدم کشف حمله» پرهزینه‌ترین خطا است، گزینه بسیار جدی محسوب می‌شود؛ هرچند با افزایش FP همراه است.
[P1312][Normal] Soft Voting FP کمتری دارد و از منظر کنترل هشدار کاذب بهتر است، اما با افزایش FN نسبت به LightGBM همراه می‌شود.
[P1314][Heading 3] 4-3-4 مقایسه نهایی سه سناریو (Real-400 vs Syn-2000(50%) vs Syn-2000(100%))
[P1315][Normal] در این بخش، نتایج سه سناریوی اصلی آزمایش به‌صورت یکپارچه مقایسه می‌شوند تا مشخص شود تغییر منبع/کیفیت داده (واقعی محدود در برابر داده مصنوعی با Seed متفاوت) چگونه باعث جابجایی رتبه مدل‌ها و تغییر الگوی خطا (FP/FN) می‌شود. از آنجا که ارزیابی نهایی در هر سناریو بر پایه مجموعه آزمون مستقل انجام شده است، این مقایسه تصویر روشن‌تری از توان تعمیم و ریسک عملیاتی (به‌ویژه FN در امنیت) ارائه می‌دهد. همچنین در تفسیر نتایج باید توجه داشت که در داده‌های کوچک، نوسان ناشی از نمونه‌گیری و تقسیم‌بندی می‌تواند محسوس باشد؛ به همین دلیل استفاده از Cross-Validation در مرحله ارزیابی میانی رایج و توصیه‌شده است.
[P1316][Caption] جدول 4- 10: جدول تجمیعی «بهترین مدل هر سناریو» بر اساس نتایج آزمون - معیار انتخاب  بهترین مدل : Accuracy و F1(macro) به‌عنوان شاخص عملکرد کلی، و FN/FP به‌عنوان شاخص‌های ریسک امنیتی/هشدار کاذب.
[P1317][Normal] نکته امنیتی تکمیلی: اگر معیار تصمیم‌گیری سازمان «حداقل‌سازی FN» باشد (یعنی از دست نرفتن حمله حتی به قیمت افزایش FP)، در سناریوی Syn-2000(100%) مدل Stacking کمترین FN را نشان داده است (FN=14)؛ ولی FP بالاتری نسبت به LightGBM دارد. (این انتخاب، تصمیم سیاستی/عملیاتی است.)
[P1318][Normal] تحلیل علت تغییر رتبه‌ها (چرا بهترین مدل‌ها بین سناریوها عوض می‌شوند؟)
[P1319][Normal] 1) اثر اندازه نمونه و کاهش واریانس ارزیابی
[P1320][Normal] در سناریوی Real-400 تعداد داده محدود است؛ در چنین شرایطی، نوسان نمونه‌گیری و حساسیت به تقسیم Train/Test زیاد می‌شود و مدل‌هایی که واریانس کمتر دارند یا به‌طور طبیعی Robust هستند (مثل درخت تصادفی) معمولاً پایدارتر ظاهر می‌شوند. استفاده از Cross-Validation دقیقاً برای کاهش همین وابستگی به یک تقسیم‌بندی و بهبود برآورد عملکرد توصیه می‌شود.
[P1321][Normal] با بزرگ شدن داده (Syn-2000)، ارزیابی روی آزمون بزرگ‌تر انجام می‌شود و مقایسه مدل‌ها «کم‌نوسان‌تر» و قابل اتکاتر می‌شود.
[P1322][Normal] 2) نقش «فیدلیتی» و «Utility» داده مصنوعی در تغییر رفتار مدل‌ها
[P1323][Normal] کیفیت داده مصنوعی فقط به تعداد رکورد وابسته نیست؛ میزان شباهت توزیعی/ساختاری به داده واقعی (Fidelity) تعیین می‌کند که داده مصنوعی چقدر برای آموزش و ارزیابی مفید است (Utility). پژوهش‌های اخیر نشان می‌دهند Utility می‌تواند حتی با فاصله توزیعی مشخص تغییر کند و باید آن را به‌صورت task-based (یعنی با عملکرد مدل روی وظیفه) سنجید.
[P1324][Normal] در Syn-2000(50%) داده مصنوعی با Seed نصف داده واقعی ساخته شده است. اگر این تولید باعث تراکم مناسب نمونه‌ها و پوشش بهتر نواحی تصمیم شده باشد، مدل‌های «نمونه‌محور» مثل KNN می‌توانند جهش عملکردی داشته باشند.
[P1325][Normal] 3) چرا KNN در Syn-2000(50%) بهترین شد؟
[P1326][Normal] KNN یک روش instance-based / lazy learning است و کیفیت آن شدیداً به تراکم نمونه‌ها و «قابل تفکیک بودن» نواحی محلی داده وابسته است. وقتی داده بیشتر و متوازن‌تر می‌شود، KNN معمولاً تصمیم‌گیری محلی دقیق‌تری دارد و خطا کاهش می‌یابد.
[P1327][Normal] در نتایج شما، KNN همزمان FP پایین و FN پایین دارد؛ این الگو معمولاً زمانی رخ می‌دهد که داده آموزشی، هم پوشش کافی از نمونه‌های حمله و هم از غیرحمله فراهم کرده باشد (یعنی مرزهای محلی بهتر شکل گرفته‌اند).
[P1328][Normal] 4) چرا LightGBM در Syn-2000(100%) بهترین شد؟
[P1329][Normal] LightGBM از خانواده Gradient Boosting Tree است و به‌طور خاص برای مدل‌سازی روابط غیرخطی و تعامل ویژگی‌ها بسیار توانمند است؛ با افزایش داده (و در بسیاری مسائل، با افزایش کیفیت/تنوع داده)، مدل‌های boosting معمولاً بهتر می‌توانند «ساختار واقعی مسئله» را یاد بگیرند و تعمیم دهند. نسخه LightGBM نیز به دلیل طراحی کارا (از جمله روش‌های بهینه‌سازی خاص) در مقیاس بزرگ/متوسط عملکرد خوبی دارد.
[P1330][Normal] تفاوت Syn-2000(100%) با Syn-2000(50%) این است که Seed کامل واقعی می‌تواند باعث شود داده مصنوعی از نظر الگوهای حمله/غیرحمله نماینده‌تر باشد (Fidelity بالاتر) و در نتیجه مدل‌های boosting بهتر از «نویز مصنوعی» عبور کنند و مرز تصمیم پایدارتر بسازند.
[P1331][Normal] 5) چرا مدل‌های Ensemble (Soft Voting / Stacking) همیشه بهترین نیستند؟
[P1332][Normal] Ensembleها معمولاً وقتی بهترین می‌شوند که (الف) مدل‌های پایه متنوع باشند و (ب) داده کافی برای جلوگیری از «یادگیری الگوهای تصادفی/ناپایدار» وجود داشته باشد. در داده کوچک (Real-400)، ممکن است مزیت ensemble روی آزمون کوچک پایدار نماند؛ در داده بزرگ‌تر، بهبود مشاهده می‌شود اما همچنان «هزینه FP/FN» می‌تواند به‌صورت سیاستی انتخاب را تغییر دهد. (این منطق با مبانی ارزیابی و پایداری مدل‌ها سازگار است.)
[P1333][Normal] جمع‌بندی نهایی
[P1334][Normal] Real-400: بهترین عملکرد کلی به درخت تصادفی رسید؛ تفسیر محتمل آن، پایداری بیشتر مدل‌های bagging در داده‌های محدود و کاهش ریسک بیش‌برازش است.
[P1335][Normal] Syn-2000(50%): بهترین عملکرد کلی به KNN رسید؛ افزایش تراکم/توازن داده باعث تقویت تصمیم‌گیری محلی شده است.
[P1336][Normal] Syn-2000(100%): بهترین عملکرد کلی به LightGBM رسید؛ با Seed واقعی کامل، Fidelity داده مصنوعی احتمالاً بالاتر بوده و boosting توانسته الگوهای غیرخطی را دقیق‌تر یاد بگیرد.
[P1337][Normal] اگر مرحله بعدی را می‌خواهی، من یک جدول مقایسه‌ای رتبه‌بندی Top-3 برای هر سناریو هم می‌گذارم (با ستون‌های FN/FP/Accuracy/F1) و بعد یک پاراگراف «راهنمای انتخاب مدل بر اساس سیاست امنیتی» (FN محور vs FP محور) اضافه می‌کنم.
[P1355][NewParagraph] فصل 5: بحث، نتیجه گیري و پیشنهادات
[P1383][NewParagraph] 5-1 مرور اجمالی نتایج تحقیق
[P1384][NewParagraph] این پژوهش با هدف افزایش دقت تشخیص حملات تزریق در پایگاه‌داده‌های غیررابطه‌ای و هم‌زمان کنترل هشدارهای کاذب طراحی و اجرا شد. راهبرد کلی پژوهش بر دو محور استوار بود: (1) استفاده از الگوریتم‌های یادگیری ماشین و مقایسه نظام‌مند چندین مدل، و (2) تقویت داده‌های آموزشی از طریق تولید داده مصنوعی با مدل‌های زبانی بزرگ (نسخه GPT-5.2) به‌منظور جبران محدودیت اندازه و تنوع داده واقعی. ادبیات اخیر نیز تأکید می‌کند که تولید داده مصنوعی توسط LLMها می‌تواند در شرایط کمبود داده برچسب‌دار، «افزایش پوشش داده» و «بهبود کارایی مدل» را ممکن کند، مشروط به اینکه کیفیت داده مصنوعی با معیارهای وظیفه‌محور سنجیده شود.
[P1385][NewParagraph] 1) جمع‌بندی سناریوهای آزمایشی و شاخص‌های ارزیابی
[P1386][NewParagraph] برای ارزیابی دقیق، آزمایش‌ها در سه سناریوی داده‌ای اجرا شدند:
[P1387][NewParagraph] سناریوی 1: Real-400 (داده واقعی با حجم محدود)
[P1388][NewParagraph] سناریوی 2: Syn-2000 (Seed=50% Real) (تولید 2000 نمونه مصنوعی با اتکا به 50% داده واقعی به‌عنوان Seed)
[P1389][NewParagraph] سناریوی 3: Syn-2000 (Seed=All Real-400) (تولید 2000 نمونه مصنوعی با اتکا به کل داده واقعی به‌عنوان Seed)
[P1390][NewParagraph] ارزیابی عملکرد بر مبنای خروجی آزمون و مجموعه‌ای از معیارهای استاندارد انجام شد؛ به‌ویژه Accuracy، Precision، Recall و F1 و همچنین تحلیل Confusion Matrix برای کنترل دو خطای کلیدی در امنیت یعنی FP (هشدار کاذب) و FN (حمله کشف‌نشده). در چارچوب‌های ارزیابی یادگیری ماشین، Confusion Matrix مبنای اصلی استخراج این شاخص‌هاست.
[P1391][NewParagraph] 2) یافته‌های کلیدی پژوهش بر اساس نتایج آزمایش
[P1392][NewParagraph] نتایج نشان داد که نوع داده (واقعی محدود در برابر مصنوعی تقویت‌شده با Seed متفاوت) می‌تواند رتبه‌بندی مدل‌ها را به‌طور معنادار تغییر دهد:
[P1393][NewParagraph] الف) عملکرد روی Real-400:
[P1394][NewParagraph] در سناریوی داده واقعی محدود، مدل درخت تصادفی بهترین عملکرد کلی را ارائه داد. این نتیجه با رفتار شناخته‌شده روش‌های bagging سازگار است؛ زیرا چنین مدل‌هایی معمولاً در نمونه‌های کوچک پایدارتر عمل کرده و حساسیت کمتری به نوسانات داده دارند.
[P1395][NewParagraph] ب) عملکرد روی Syn-2000 (Seed=50% Real)
[P1396][NewParagraph] در این سناریو، KNN بهترین عملکرد کلی را ثبت کرد و هم‌زمان توانست مقدار FP و FN را در سطح پایین نگه دارد. این الگو نشان می‌دهد افزایش تراکم نمونه‌ها و متنوع‌تر شدن فضای ویژگی‌ها (در نتیجه تولید داده مصنوعی) می‌تواند به نفع مدل‌های نمونه‌محور (instance-based) تمام شود.
[P1397][NewParagraph] ج) عملکرد روی Syn-2000 (Seed=All Real-400)
[P1398][NewParagraph] در این سناریو، LightGBM بهترین عملکرد کلی را ارائه داد و از نظر توازن خطاها نیز وضعیت مطلوبی داشت. از منظر نظری، LightGBM به‌عنوان یک پیاده‌سازی کارا از Gradient Boosting درخت تصمیمs، برای یادگیری روابط غیرخطی و تعامل ویژگی‌ها مناسب است و در داده‌های بزرگ‌تر/غنی‌تر می‌تواند مزیت بیشتری نشان دهد.
[P1399][NewParagraph] همچنین مشاهده شد که در برخی سناریوها، مدل‌های ترکیبی مانند Stacking می‌توانند FN را به حداقل برسانند (یعنی ریسک «از دست رفتن حمله» را کمتر کنند)، اما گاهی با افزایش FP همراه می‌شوند. بنابراین «بهترین مدل» به سیاست عملیاتی نیز وابسته است: اگر اولویت سازمان کاهش FN باشد، انتخاب ممکن است متفاوت از حالتی باشد که کاهش FP اولویت دارد.
[P1400][NewParagraph] 3) نقش داده مصنوعی تولیدشده با GPT-5.2 در بهبود نتایج
[P1401][NewParagraph] یکی از خروجی‌های مهم پژوهش، تولید داده‌های مصنوعی هدفمند برای سناریوهای حمله/غیرحمله بود که عملاً باعث شد مدل‌ها در سناریوهای Syn-2000 عملکرد بهتری نسبت به حالت داده واقعی محدود داشته باشند. این نتیجه با گزارش‌های پژوهشی هم‌راستا است که نشان می‌دهند LLMها می‌توانند داده‌های مصنوعی «وظیفه‌محور» تولید کنند و در شرایط کمبود داده واقعی، به بهبود آموزش مدل‌ها کمک نمایند.
[P1402][NewParagraph] 4) جمع‌بندی نهایی این بخش
[P1403][NewParagraph] در مجموع، نتایج آزمایش‌ها نشان داد:
[P1404][NewParagraph] تقویت داده با تولید مصنوعی می‌تواند عملکرد مدل‌ها را به شکل محسوسی بهبود دهد، به‌خصوص وقتی داده واقعی محدود است.
[P1405][NewParagraph] بهترین مدل در هر سناریو ثابت نیست و با تغییر کیفیت/منبع داده، مدل‌های متفاوتی در رتبه اول قرار می‌گیرند (Real-400 → درخت تصادفی، Syn-2000(50%) → KNN، Syn-2000(100%) → LightGBM).
[P1406][NewParagraph] در ارزیابی امنیتی، تحلیل همزمان FP و FN ضروری است، زیرا FN به معنی عبور حمله و FP به معنی افزایش هشدار کاذب و هزینه عملیاتی است.
[P1407][NewParagraph] استفاده از مدل‌های تقویتی پیشرفته (به‌ویژه LightGBM) در داده مصنوعیِ Seed کامل، با انتظار نظری از GBDTهای کارا و توانمند در روابط غیرخطی سازگار است.
[P1408][Heading 2] 5-2 تحلیل نتایج در چارچوب پیشینه پژوهش
[P1409][NewParagraph] نتایج این پژوهش در امتداد مسیر تحقیقات پیشینِ مقابله با تزریق (Injection) قرار می‌گیرد، اما از چند جهت «گام جلوتر» است: (1) تمرکز مستقیم بر تزریق در پایگاه‌داده‌های غیررابطه‌ای (NoSQL Injection) که در مقایسه با SQL Injection کمتر پوشش داده شده، و (2) استفاده از تولید داده مصنوعی مبتنی بر مدل‌های زبانی بزرگ برای رفع محدودیت جدی داده‌های برچسب‌دار در این حوزه. در ادبیات موضوع، هم‌زمانیِ ماهیت نوظهور NoSQL و تنوع بالای الگوهای حمله، باعث شده بسیاری از مطالعات به مجموعه‌داده‌های کوچک یا سناریوهای محدود متکی باشند و قابلیت تعمیم در محیط واقعی با چالش مواجه شود.
[P1410][Heading 3] 5-2-1 جایگاه پژوهش حاضر نسبت به رویکردهای رایج (ابزارمحور/تحلیل‌کد/یادگیری ماشین)
[P1411][NewParagraph] در کارهای پیشین، بخش قابل توجهی از راهکارها برای کشف NoSQL Injection ماهیت ابزارمحور یا تحلیل ایستا/پویا داشته‌اند. برای نمونه، ابزار NoSQL Racket ایده اصلی خود را بر مقایسه ساختار کوئری NoSQL در سطح کد (تحلیل ایستا) و سطح زمان اجرا (تحلیل پویا) بنا می‌کند و با همین مکانیزم، انحراف ساختاری ناشی از تزریق را شناسایی می‌کند. این نوع رویکردها از منظر مهندسی امنیت، ارزشمندند زیرا به جای یادگیری از داده، مستقیماً رفتار اجرای کوئری را پایش می‌کنند.
[P1412][NewParagraph] با این حال، یافته‌های پژوهش حاضر نشان داد که یک چارچوب داده‌محور و مدل‌محور می‌تواند مکمل/جایگزین موثری برای رویکردهای ابزارمحور باشد؛ به‌ویژه وقتی مسئله با کمبود داده‌های واقعی و تنوع پایین مواجه است. در واقع، در این پژوهش، مدل‌های مختلف یادگیری ماشین روی سه سناریوی داده‌ای ارزیابی شدند و مشاهده شد که با تغییر کیفیت و ترکیب داده (واقعی محدود در برابر مصنوعی تقویت‌شده)، رتبه‌بندی مدل‌ها تغییر می‌کند؛ این موضوع نشان می‌دهد «ماهیت داده» در NoSQL Injection یک عامل تعیین‌کننده است و صرفاً تکیه بر یک مدل منفرد یا یک سناریوی ثابت، می‌تواند نتیجه‌گیری را شکننده کند.
[P1413][Heading 3] 5-2-2 چرایی تفاوت نتایج نسبت به برخی مطالعات قبلی
[P1414][NewParagraph] الف) استفاده از داده مصنوعی مبتنی بر LLM به جای تولیدکننده‌های کلاسیک
[P1415][NewParagraph] در بخشی از ادبیات امنیت، تولید داده مصنوعی با روش‌های کلاسیک (از جمله خانواده GANها) مطرح بوده است؛ اما داده‌های امنیتی متنی/ساختاریافته (مانند payloadها، query fragmentها و الگوهای تزریق) اغلب به تولیدکننده‌ای نیاز دارند که «ساختار و معنا» را همزمان حفظ کند. در این پژوهش از GPT-5.2 برای تولید داده مصنوعی استفاده شد؛ رویکردی که با روندهای جدید تحقیقاتی در امنیت همسو است، زیرا مطالعات نشان می‌دهند LLMها می‌توانند برای تولید داده مصنوعی در کاربردهای امنیتی (از جمله تشخیص ناهنجاری و شبیه‌سازی تهدید) مفید باشند به شرط کنترل کیفیت و ارزیابی وظیفه‌محور.
[P1416][NewParagraph] ب) تمرکز مسئله بر NoSQL Injection و شکاف داده/ارزیابی
[P1417][NewParagraph] بر اساس مرورهای حوزه، هرچند SQL Injection بسیار مطالعه شده، اما NoSQL Injection هم به دلیل تفاوت در نحو کوئری‌ها و هم به دلیل تنوع پایگاه‌ها و APIها، به داده‌های متنوع‌تر و ارزیابی دقیق‌تری نیاز دارد. پژوهش حاضر دقیقاً روی این شکاف تمرکز کرده و نشان می‌دهد تقویت داده می‌تواند به «بهبود تعمیم» کمک کند.
[P1418][NewParagraph] ج) اثر داده بر انتخاب مدل و تغییر رتبه‌ها
[P1419][NewParagraph] یافته‌های تجربی شما نشان دادند که بهترین مدل در سناریوی داده واقعیِ محدود با بهترین مدل در سناریوهای مصنوعی یکسان نیست. این موضوع از منظر روش‌شناسی مهم است، چون نشان می‌دهد برخی نتایج مطالعات قبلی ممکن است «وابسته به داده» باشند و با تغییر سناریو داده، نتیجه تغییر کند. از منظر فنی نیز این رفتار قابل انتظار است: مدل‌های مبتنی بر boosting (مثل LightGBM) معمولاً در داده‌های بزرگ‌تر/غنی‌تر فرصت بیشتری برای یادگیری الگوهای غیرخطی و تعامل ویژگی‌ها پیدا می‌کنند؛ و LightGBM نیز به‌عنوان یک پیاده‌سازی کارا از GBDT برای همین هدف طراحی شده است.
[P1420][Heading 3] 5-2-3 نقاط قوت و محدودیت‌ها
[P1421][NewParagraph] نقاط قوت
[P1422][NewParagraph] بهبود عملکرد و تعمیم‌پذیری از طریق سناریوهای داده‌ای متنوع: طراحی سه سناریو باعث شد پایداری انتخاب مدل و حساسیت آن به داده، شفاف شود.
[P1423][NewParagraph] تولید داده مصنوعی با LLM و افزایش پوشش سناریوهای حمله/غیرحمله: مطابق ادبیات، استفاده از LLM برای تولید داده امنیتی می‌تواند هزینه و زمان تولید داده را کاهش دهد و تنوع را افزایش دهد.
[P1424][NewParagraph] ارزیابی دقیق خطاهای امنیتی (FP/FN) و نه صرفاً Accuracy: این رویکرد باعث می‌شود نتایج برای استقرار عملی قابل اتکاتر باشند.
[P1425][NewParagraph] محدودیت‌ها
[P1426][NewParagraph] وابستگی عملکرد به کیفیت داده مصنوعی و ریسک سوگیری/آرتیفکت‌های تولیدی: اگر داده مصنوعی الگوهای غیرواقعی یا سرنخ‌های ساده ایجاد کند، برخی مدل‌ها ممکن است به‌صورت ناپایدار «بیش‌برازش» کنند.
[P1427][NewParagraph] پیچیدگی عملیاتی مدل‌های قوی‌تر/ترکیبی: برخی مدل‌ها و ensembleها ممکن است هزینه محاسباتی و هزینه نگهداشت بیشتری داشته باشند (به‌خصوص در محیط‌های عملیاتی محدود).
[P1428][NewParagraph] نیاز به ارزیابی میدانی روی جریان واقعی ترافیک/کوئری در مقیاس سازمانی: ادبیات نیز بر چالش تعمیم از آزمایشگاه به محیط واقعی تأکید دارد.
[P1429][Heading 2] 5-3 بررسی کاربردهای عملی نتایج در دنیای واقعی (بازنویسی‌شده و همسو با نتایج شما)
[P1430][NewParagraph] یافته‌های این پژوهش چند مسیر کاربردی مشخص برای صنعت و سازمان‌ها ایجاد می‌کند؛ به‌ویژه برای سامانه‌هایی که بر پایگاه‌داده‌های NoSQL و APIهای مبتنی بر JSON/Document تکیه دارند.
[P1431][Heading 3] 5-3-1 کاربردهای مستقیم در سامانه‌های امنیتی
[P1432][NewParagraph] افزودن لایه تشخیص مبتنی بر یادگیری ماشین به کنار کنترل‌های کلاسیک
[P1433][NewParagraph] خروجی پژوهش نشان داد مدل‌ها بسته به سناریوی داده، توانایی متفاوتی در کنترل FN (حمله‌های از دست‌رفته) و FP (هشدارهای کاذب) دارند. بنابراین سازمان می‌تواند یک سیاست عملیاتی تعریف کند:
[P1434][NewParagraph] محیط‌های حساس (بانکی/سلامت): انتخاب مدل/پیکربندی با اولویت کاهش FN
[P1435][NewParagraph] محیط‌های پرحجم (سرویس‌های ابری/پلتفرم‌ها): موازنه FP برای کاهش هزینه عملیاتی
این منطق انتخاب بر پایه تحلیل Confusion Matrix در ارزیابی‌های استاندارد توصیه می‌شود.
[P1436][NewParagraph] بهبود WAF/IDS برای سرویس‌های NoSQL محور
[P1437][NewParagraph] خروجی مدل می‌تواند به‌صورت یک ماژول تشخیصی در کنار WAF یا IDS قرار گیرد و درخواست‌های مشکوک را با احتمال حمله برچسب‌گذاری کند. ادبیات LLM در امنیت نیز نشان می‌دهد سیستم‌های جدید در حال حرکت به سمت روش‌های ترکیبی (یادگیری ماشین + تحلیل معنایی/متنی) هستند.
[P1438][NewParagraph] کمک به تیم‌های SecOps در اولویت‌بندی رخدادها
[P1439][NewParagraph] با داشتن یک طبقه‌بند که ریسک را امتیازدهی می‌کند، رخدادهای امنیتی به جای صف‌های طولانی هشدار، قابلیت رتبه‌بندی و تریاژ پیدا می‌کنند. این موضوع به‌صورت مستقیم هزینه FP را کاهش می‌دهد.
[P1440][Heading 3] 5-3-2 کاربردهای غیرمستقیم: تولید داده و تمرین/آموزش امنیتی
[P1441][NewParagraph] ساخت مجموعه‌داده آموزشی برای تیم امنیت و تست نفوذ
[P1442][NewParagraph] داده مصنوعی تولید شده با GPT-5.2 می‌تواند برای آموزش نیروها، ساخت سناریوهای تست و حتی طراحی تمرین‌های قرمز/آبی (Red/Blue Team) به‌کار رود؛ ادبیات جدید نیز کاربرد LLMها در تولید داده‌های امنیتی و شبیه‌سازی تهدید را گزارش کرده است.
[P1443][NewParagraph] پشتیبانی از پژوهش‌های آینده در نبود دیتاست استاندارد NoSQL Injection
[P1444][NewParagraph] یکی از چالش‌های شناخته‌شده، کمبود داده‌های جامع در NoSQL Injection است. خروجی این پژوهش می‌تواند مبنایی برای مقایسه روش‌ها، تست الگوریتم‌های جدید، و استانداردسازی ارزیابی‌ها باشد.
[P1445][Heading 3] 5-3-3 پیامدها برای صنعت، جامعه و مسیر تحقیقات آینده
[P1446][NewParagraph] افزایش امنیت داده‌های حساس و کاهش سطح ریسک نفوذ
[P1447][NewParagraph] کاهش FN یعنی احتمال عبور حمله کمتر می‌شود و این موضوع برای سامانه‌های حاوی داده حساس، اثر مستقیم دارد.
[P1448][NewParagraph] شتاب‌دهی به نوآوری در سامانه‌های NoSQL محور
[P1449][NewParagraph] سازمان‌ها با اطمینان بیشتر می‌توانند از معماری‌های مبتنی بر NoSQL استفاده کنند؛ چون یک راهکار داده‌محور برای کنترل تزریق در اختیار دارند.
[P1450][NewParagraph] گسترش پژوهش روی «کیفیت داده مصنوعی» و کنترل سوگیری
[P1451][NewParagraph] ادبیات جدید همزمان هشدار می‌دهد که LLMها ابزار قدرتمندی هستند اما کیفیت داده مصنوعی باید با معیارهای دقیق کنترل شود؛ لذا مسیر آینده پژوهش می‌تواند شامل سنجش fidelity/utility داده و ارزیابی میدانی باشد.
[P1452][Heading 2] 5-4 محدودیت‌های پژوهش
[P1453][NewParagraph] در اجرای این پژوهش، مجموعه‌ای از محدودیت‌های عملی و فنی وجود داشت که می‌تواند مسیر بهبود در مطالعات آینده را روشن‌تر کند:
[P1454][NewParagraph] محدودیت دسترسی به داده‌های واقعی و برچسب‌دار NoSQL Injection
[P1455][NewParagraph] کمبود دیتاست‌های استاندارد و در دسترس عمومی برای حملات تزریق NoSQL یکی از موانع شناخته‌شده این حوزه است و بسیاری از کارهای داده‌محور نیز به این شکاف اشاره کرده‌اند. این مسئله باعث شد بخش قابل توجهی از تقویت داده از طریق داده مصنوعی انجام شود.
[P1456][NewParagraph] وابستگی نتایج به کیفیت و «فیدلیتی/یوتیلیتی» داده مصنوعی
[P1457][NewParagraph] هرچند تولید داده با LLM (در این پژوهش GPT-5.2) توانست پوشش سناریوهای حمله/غیرحمله را افزایش دهد، اما داده مصنوعی ذاتاً با خطر «ایجاد آرتیفکت»، «سوگیری» یا «فاصله توزیعی» همراه است. ادبیات synthetic data نیز روی ضرورت سنجش همزمان فیدلیتی، یوتیلیتی و ریسک تأکید دارد.
[P1458][NewParagraph] محدودیت ارزیابی میدانی و استقرار در محیط واقعی
[P1459][NewParagraph] ارزیابی‌ها در چارچوب آزمایشگاهی/شبیه‌سازی انجام شده است. در عمل، رفتار کاربران، تغییر الگوهای ترافیک و تنوع پیاده‌سازی‌های NoSQL می‌تواند الگوی خطاها (FP/FN) را تغییر دهد؛ لذا تعمیم نتایج به محیط عملیاتی نیازمند آزمایش میدانی و پایش مستمر است.
[P1460][NewParagraph] هزینه محاسباتی و پیچیدگی عملیاتی مدل‌ها
[P1461][NewParagraph] آموزش چند مدل و انجام ارزیابی چندمرحله‌ای (از جمله مدل‌های boosting و ensemble) نیازمند منابع محاسباتی بیشتر است. هرچند مدل‌هایی مانند LightGBM برای کارایی طراحی شده‌اند، اما همچنان اجرای چندمدلی و تکرار آزمایش‌ها در محیط‌های محدود می‌تواند چالش ایجاد کند.
[P1462][NewParagraph] محدودیت دامنه تهدید و پوشش انواع پایگاه‌داده/پیاده‌سازی
[P1463][NewParagraph] NoSQL Injection صرفاً به MongoDB محدود نیست و رفتار حمله در اکوسیستم‌های مختلف (مانند Cassandra یا DynamoDB) می‌تواند متفاوت باشد. حتی پژوهش NoSQL Racket نیز چالش «نبود زبان استاندارد کوئری» در NoSQL و تنوع بسترها را مطرح می‌کند که تعمیم‌پذیری ابزارها/مدل‌ها را پیچیده‌تر می‌سازد.
[P1464][Heading 2] 5-5 محدودیت‌های ذاتی روش تحقیق یا داده‌های استفاده‌شده
[P1465][NewParagraph] حساسیت رتبه‌بندی مدل‌ها به سناریوی داده
[P1466][NewParagraph] نتایج شما نشان داد «بهترین مدل» میان سناریوهای Real-400، Syn-2000(50%) و Syn-2000(100%) ثابت نمی‌ماند. این موضوع بیانگر آن است که برآورد عملکرد، به کیفیت/ساختار داده و نحوه تقویت آن وابسته است و نتیجه‌گیری باید در قالب چند سناریو گزارش شود (کاری که در این پژوهش انجام شده است). (این نکته با توصیه‌های ارزیابی وظیفه‌محور در تولید داده مصنوعی هم‌راستاست.)
[P1467][NewParagraph] پوشش محدود الگوهای حمله نسبت به فضای تهدید واقعی
[P1468][NewParagraph] حملات تزریق NoSQL در عمل طیف گسترده‌ای از payloadها و مسیرهای اکسپلویت (مانند bypass احراز هویت، دستکاری شرط‌ها، و انواع تزریق در JSON/query operators) دارند. بنابراین حتی با تولید داده مصنوعی، احتمال باقی‌ماندن شکاف نسبت به تهدیدات «کاملاً نوظهور» وجود دارد.
[P1469][NewParagraph] عدم ارزیابی طولانی‌مدت و Drift مفهومی (Concept Drift)
[P1470][NewParagraph] الگوهای حمله و رفتار سامانه‌ها در طول زمان تغییر می‌کند؛ در نتیجه مدل‌ها بدون پایش و بازآموزی دوره‌ای ممکن است افت عملکرد داشته باشند. این محدودیت در بسیاری از سامانه‌های امنیتی داده‌محور وجود دارد و در پژوهش حاضر نیز به‌عنوان محدودیت ذاتی مطرح است.
[P1471][Heading 2] 5-6 پیشنهادها برای تحقیقات آینده
[P1472][NewParagraph] استانداردسازی و توسعه دیتاست ترکیبی چندسناریویی
[P1473][NewParagraph] پیشنهاد می‌شود دیتاست‌های آینده به‌صورت رسمی با سناریوهای مشخص (واقعی محدود، مصنوعی با Seed جزئی، مصنوعی با Seed کامل، و ترکیبی) منتشر شوند تا مقایسه روش‌ها پایدارتر گردد. وجود دیتاست‌های تخصصی MongoDB Injection نیز نشان می‌دهد مسیر استانداردسازی در حال شکل‌گیری است و می‌تواند گسترش یابد.
[P1474][NewParagraph] کنترل کیفیت داده مصنوعی با چارچوب‌های ارزیابی Fidelity/Utility/Privacy
برای کاهش ریسک آرتیفکت و افزایش اتکا، پیشنهاد می‌شود تولید داده با LLM همراه با سنجش‌های سیستماتیک باشد (Utility وظیفه‌محور، Fidelity آماری/ساختاری و در صورت لزوم ارزیابی ریسک).
[P1475][NewParagraph] ارزیابی میدانی در مقیاس واقعی و تحلیل هزینه خطا (Cost-Sensitive)
در محیط واقعی، هزینه FN (از دست رفتن حمله) معمولاً بسیار بیشتر از هزینه FP (هشدار کاذب) است. پیشنهاد می‌شود ارزیابی آینده علاوه بر معیارهای کلاسیک، با معیارهای هزینه‌محور و سیاست‌های عملیاتی (FN-محور/FP-محور) انجام شود.
[P1476][NewParagraph] گسترش دامنه به چند پایگاه‌داده و چند API/چارچوب وب
[P1477][NewParagraph] با توجه به تنوع NoSQL و نبود زبان استاندارد مشترک (چالشی که NoSQL Racket نیز برجسته می‌کند)، پیشنهاد می‌شود آزمایش‌ها روی چند DBMS و چند چارچوب توسعه (Node/Python/Java) تکرار شود.
[P1478][NewParagraph] ادغام رویکرد داده‌محور با روش‌های ابزارمحور/تحلیل ایستا-پویا
[P1479][NewParagraph] یک مسیر آینده‌دار، ترکیب طبقه‌بندی یادگیری ماشین با سیگنال‌های ابزارمحور (مانند تحلیل ساختار query در runtime) است تا هم قدرت تعمیم داده‌محور حفظ شود و هم کشف‌های ساختاری دقیق‌تر گردد.
[P1480][Heading 2] 5-7 جمع‌بندی نهایی
[P1481][NewParagraph] این پژوهش یک چارچوب داده‌محور برای تشخیص حملات تزریق در پایگاه‌داده‌های غیررابطه‌ای ارائه کرد که دو مؤلفه کلیدی داشت: (1) ارزیابی مقایسه‌ای چند مدل یادگیری ماشین و مدل‌های ترکیبی، و (2) تقویت داده از طریق تولید نمونه‌های مصنوعی با GPT-5.2 در دو سطح Seed (۵۰٪ و ۱۰۰٪ داده واقعی). نتایج آزمایش‌ها نشان دادند که با تغییر سناریوی داده، «بهترین مدل» ثابت نمی‌ماند و این امر اهمیت طراحی چندسناریویی و تحلیل همزمان FP/FN را برجسته می‌کند. همچنین، استفاده از داده مصنوعی به‌عنوان راهکار جبران کمبود داده واقعی، با ادبیات جدیدِ تولید داده توسط LLMها هم‌سو است؛ مشروط به اینکه کیفیت داده مصنوعی به‌صورت چارچوب‌مند ارزیابی شود.
[P1482][NewParagraph] در نهایت، با وجود محدودیت‌هایی مانند نیاز به ارزیابی میدانی و کنترل کیفی دقیق داده مصنوعی، پژوهش حاضر یک گام عملی در جهت پر کردن شکاف داده و تقویت تشخیص NoSQL Injection محسوب می‌شود و می‌تواند به‌عنوان مبنایی برای توسعه ابزارهای امنیتی داده‌محور و مطالعات آینده در این حوزه به کار رود.
[P1484][Heading_Ref] فهرست مراجع
[P1491][Normal] Abstract
[P1492][Normal] NoSQL injection is a critical web-application vulnerability that typically emerges from insufficient input validation and unsafe construction of dynamic database queries, enabling attackers to manipulate NoSQL queries to bypass authentication, exfiltrate data, or alter sensitive records. With the increasing adoption of NoSQL databases in modern applications, the need for robust, data-driven detection mechanisms has become more pressing—especially given the limited availability of reliable, labeled datasets for NoSQL injection research.
[P1493][Normal] This thesis proposes a data-centric approach to improving NoSQL injection detection accuracy while reducing false alarms. A key contribution is addressing the data scarcity challenge through dataset augmentation using a large language model. In addition to a real dataset (Real-400), two synthetic datasets (Syn-2000) were generated using GPT-5.2 under two seeding strategies: (i) Seed=50% Real and (ii) Seed=All Real-400. Recent literature highlights that LLM-driven synthetic data generation can provide task-relevant augmentation when real labeled data is scarce, provided that the generated data is evaluated in a task-based manner.
[P1494][Normal] Multiple machine learning models were trained and evaluated, including رگرسیون خطی, درخت تصادفی, XGBoost, LightGBM, نزدیکترین همسایه (KNN), and ensemble configurations based on soft voting and stacking. Model assessment followed systematic evaluation procedures that preserve class distributions (e.g., Stratified K-Fold validation) to mitigate biased estimates under class imbalance. Experimental results demonstrate that the best-performing model is scenario-dependent: درخت تصادفی achieved the strongest overall performance on Real-400; KNN performed best on Syn-2000 (Seed=50% Real); and LightGBM provided the best overall balance on Syn-2000 (Seed=All Real-400). Moreover, ensemble methods were observed to reduce false negatives in certain settings, sometimes at the cost of increased false positives—indicating that operational deployment should be guided by the organization’s risk preference (FN-sensitive vs. FP-sensitive).
[P1495][Normal] Overall, the findings confirm that GPT-5.2–based synthetic data augmentation can materially enhance NoSQL injection detection and improve generalization, while joint analysis of FP and FN yields a more operationally meaningful view of security risk. The results also suggest that tree-based boosting methods such as LightGBM—designed for efficient learning of complex non-linear patterns—are particularly effective under richer, more representative datasets.
[P1496][Normal] Keywords: NoSQL injection, NoSQL databases, synthetic data, large language models (GPT-5.2), machine learning, ensemble learning, attack detection, false positive reduction.
[P1521][Title Page] In the Name of God
[P1523][Title Page] دانشگاه صنعتی مالک‌اشتر
[P1524][Title Page Names] Malek Ashtar University of Technology
[P1525][Title Page] Faculty of Electrical and Computer Engineering
[P1527][Title Page] M.Sc. Thesis
[P1531][Title Page] Title
[P1532][Normal] Improving the Detection of پایگاه‌داده غیررابطه‌ای Injection Attacks Based on Machine Learning
[P1534][Title Page] By
[P1535][Title Page Names] Amirhossein Ghasemi
[P1538][Title Page] Supervised by
[P1539][Title Page Names] [Supervisor's name(s)]
[P1541][Title Page] Advised by
[P1542][Title Page Names] [Advisor's name(s)]
[P1546][Title Page] Dec. 23, 2024
